{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP assignment 1 Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Done By:\n",
        "* Rasha Jabbour\n",
        "* Ramez Nafeh\n",
        "* Jasmine El Afyouni\n"
      ],
      "metadata": {
        "id": "2imsydZjx9Sk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Pre-processing"
      ],
      "metadata": {
        "id": "9Sp5UYQClFm8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8aVUWrD3LeW"
      },
      "source": [
        "## Preliminary Steps\n",
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of3D92OeWV8_"
      },
      "source": [
        "# The libraries we will use are imported here, in case of runtime problems\n",
        "import os, shutil  #  file management\n",
        "import sys \n",
        "import pandas as pd  #  dataframe management\n",
        "import numpy as np  #  data manipulation\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tqdm import tqdm # debugging (progress bars)\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import copy\n",
        "\n",
        "# typing\n",
        "from typing import List, Callable, Dict"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgXmCToDOAbQ"
      },
      "source": [
        "dataset_name = \"dependency_treebank\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCjPTD4a6uTb"
      },
      "source": [
        "If it is necessary, clean all the data that are in the DATASETS directory and wipe out all the subdirectories.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdGME3PR7--W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30cc810-c3b3-42d6-f0a2-4b3e1a066450"
      },
      "source": [
        "folder = os.getcwd()\n",
        "\n",
        "print(\"Current work directory: \" + str(folder))\n",
        "\n",
        "dataset_folder = os.path.join(os.getcwd(), \"Datasets\")\n",
        "print(dataset_folder)\n",
        "# create Datasets dir if it doesnt exist\n",
        "if not os.path.exists(dataset_folder): \n",
        "    os.makedirs(dataset_folder)\n",
        "\n",
        "for filename in os.listdir(dataset_folder):\n",
        "    file_path = os.path.join(dataset_folder, filename)\n",
        "    try:\n",
        "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "            os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            shutil.rmtree(file_path)\n",
        "    except Exception as e:\n",
        "        print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "\n",
        "print(\"Cleaned\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current work directory: C:\\Users\\rasha\n",
            "C:\\Users\\rasha\\Datasets\n",
            "Cleaned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d--rS8W95i62"
      },
      "source": [
        "## Dataset Download\n",
        "Dowload & extract the treebank\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLNJIfZg4_d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c833c5e9-fd0b-4887-fe47-ed3b301aa1fb"
      },
      "source": [
        "import urllib.request  #  download files\n",
        "import tarfile  #  unzip files\n",
        "from zipfile import ZipFile\n",
        "\n",
        "dataset_folder = os.path.join(os.getcwd(), \"Datasets\", \"Original\")\n",
        "\n",
        "if not os.path.exists(dataset_folder):\n",
        "    os.makedirs(dataset_folder)\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip'\n",
        "\n",
        "dataset_path = os.path.join(dataset_folder, \"dependency_treebank.zip\")\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    urllib.request.urlretrieve(url, dataset_path)\n",
        "    print(\"Successful download\")\n",
        "\n",
        "with ZipFile(dataset_path, 'r') as zip:\n",
        "    zip.extractall(dataset_folder)\n",
        "\n",
        "print(\"Successful extraction\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful download\n",
            "Successful extraction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FexYdgu87Q3"
      },
      "source": [
        "## Create the dataframe\n",
        "Now the dataset is loaded into a dataframe to be more accessible.\n",
        "During the creation some data will be printed as an example.\n",
        "\n",
        "row format: file_id, text, tags, split\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf-BpjDK7c4u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "94ab54c7-62bf-44de-8865-a38c1966d631"
      },
      "source": [
        "debug = True\n",
        "\n",
        "dataframe_rows = []\n",
        "\n",
        "folder = os.path.join(os.getcwd(), \"Datasets\", \"Original\", dataset_name)\n",
        "filenames = sorted(os.listdir(folder))\n",
        "split = \" \"\n",
        "for i in range(199):\n",
        "    if i < 99:\n",
        "        split = \"train\"\n",
        "    elif i > 99 and i < 149:\n",
        "        split = \"validation\"\n",
        "    elif i > 149 and i < 199:\n",
        "        split = \"test\"\n",
        "\n",
        "    file_path = os.path.join(folder, filenames[i])\n",
        "    try:\n",
        "        if os.path.isfile(file_path):\n",
        "            # open the file\n",
        "            with open(file_path, mode='r', encoding='utf-8') as text_file:\n",
        "                # read it\n",
        "                text = text_file.read()\n",
        "                \n",
        "                words = []\n",
        "                tags = []\n",
        "\n",
        "                # split document between words and tags\n",
        "                lines = text.splitlines()\n",
        "                for line in lines:\n",
        "                    l = line.split(\"\\t\")\n",
        "                    if l[0] == '': continue #   skip this annoying char\n",
        "                    words.append(l[0].lower())\n",
        "                    tags.append(l[1])\n",
        "\n",
        "                #create single dataframe row\n",
        "                dataframe_row = { \n",
        "                    \"file_id\": filenames[i],\n",
        "                    \"text\": words ,\n",
        "                    \"tags\": tags ,\n",
        "                    \"split\": split\n",
        "                }    \n",
        "                dataframe_rows.append(dataframe_row)\n",
        "\n",
        "    except Exception as e:\n",
        "        print('Failed to process %s. Reason: %s' % (file_path, e))\n",
        "        sys.exit(0)\n",
        "\n",
        "folder = os.path.join(os.getcwd(), \"Datasets\", \"Dataframes\", dataset_name)\n",
        "if not os.path.exists(folder):\n",
        "    os.makedirs(folder)\n",
        "\n",
        "# transform the list of rows in a proper dataframe\n",
        "df = pd.DataFrame(dataframe_rows)\n",
        "df = df[[\"file_id\",\n",
        "            \"text\",\n",
        "            \"tags\",\n",
        "            \"split\"]]\n",
        "dataframe_path = os.path.join(folder, dataset_name + \".pkl\")\n",
        "df.to_pickle(dataframe_path)\n",
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         file_id                                               text  \\\n",
              "0    wsj_0001.dp  [pierre, vinken, ,, 61, years, old, ,, will, j...   \n",
              "1    wsj_0002.dp  [rudolph, agnew, ,, 55, years, old, and, forme...   \n",
              "2    wsj_0003.dp  [a, form, of, asbestos, once, used, to, make, ...   \n",
              "3    wsj_0004.dp  [yields, on, money-market, mutual, funds, cont...   \n",
              "4    wsj_0005.dp  [j.p., bolduc, ,, vice, chairman, of, w.r., gr...   \n",
              "..           ...                                                ...   \n",
              "194  wsj_0195.dp  [john, f., barrett, ,, 40, ,, formerly, execut...   \n",
              "195  wsj_0196.dp  [leon, j., level, ,, vice, president, and, chi...   \n",
              "196  wsj_0197.dp  [david, a., diloreto, ,, president, of, metal,...   \n",
              "197  wsj_0198.dp  [two, leading, constitutional-law, experts, sa...   \n",
              "198  wsj_0199.dp  [trinity, industries, inc., said, it, reached,...   \n",
              "\n",
              "                                                  tags  split  \n",
              "0    [NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...  train  \n",
              "1    [NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...  train  \n",
              "2    [DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...  train  \n",
              "3    [NNS, IN, JJ, JJ, NNS, VBD, TO, VB, ,, IN, NNS...  train  \n",
              "4    [NNP, NNP, ,, NN, NN, IN, NNP, NNP, CC, NNP, ,...  train  \n",
              "..                                                 ...    ...  \n",
              "194  [NNP, NNP, NNP, ,, CD, ,, RB, JJ, NN, NN, CC, ...   test  \n",
              "195  [NNP, NNP, NNP, ,, NN, NN, CC, NN, JJ, NN, IN,...   test  \n",
              "196  [NNP, NNP, NNP, ,, NN, IN, NN, NN, NN, ,, VBD,...   test  \n",
              "197  [CD, VBG, NN, NNS, VBD, NNP, NNP, VBZ, RB, VB,...   test  \n",
              "198  [NNP, NNPS, NNP, VBD, PRP, VBD, DT, JJ, NN, TO...   test  \n",
              "\n",
              "[199 rows x 4 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>text</th>\n",
              "      <th>tags</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wsj_0001.dp</td>\n",
              "      <td>[pierre, vinken, ,, 61, years, old, ,, will, j...</td>\n",
              "      <td>[NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wsj_0002.dp</td>\n",
              "      <td>[rudolph, agnew, ,, 55, years, old, and, forme...</td>\n",
              "      <td>[NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wsj_0003.dp</td>\n",
              "      <td>[a, form, of, asbestos, once, used, to, make, ...</td>\n",
              "      <td>[DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wsj_0004.dp</td>\n",
              "      <td>[yields, on, money-market, mutual, funds, cont...</td>\n",
              "      <td>[NNS, IN, JJ, JJ, NNS, VBD, TO, VB, ,, IN, NNS...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wsj_0005.dp</td>\n",
              "      <td>[j.p., bolduc, ,, vice, chairman, of, w.r., gr...</td>\n",
              "      <td>[NNP, NNP, ,, NN, NN, IN, NNP, NNP, CC, NNP, ,...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>wsj_0195.dp</td>\n",
              "      <td>[john, f., barrett, ,, 40, ,, formerly, execut...</td>\n",
              "      <td>[NNP, NNP, NNP, ,, CD, ,, RB, JJ, NN, NN, CC, ...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>wsj_0196.dp</td>\n",
              "      <td>[leon, j., level, ,, vice, president, and, chi...</td>\n",
              "      <td>[NNP, NNP, NNP, ,, NN, NN, CC, NN, JJ, NN, IN,...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>wsj_0197.dp</td>\n",
              "      <td>[david, a., diloreto, ,, president, of, metal,...</td>\n",
              "      <td>[NNP, NNP, NNP, ,, NN, IN, NN, NN, NN, ,, VBD,...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>wsj_0198.dp</td>\n",
              "      <td>[two, leading, constitutional-law, experts, sa...</td>\n",
              "      <td>[CD, VBG, NN, NNS, VBD, NNP, NNP, VBZ, RB, VB,...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>wsj_0199.dp</td>\n",
              "      <td>[trinity, industries, inc., said, it, reached,...</td>\n",
              "      <td>[NNP, NNPS, NNP, VBD, PRP, VBD, DT, JJ, NN, TO...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>199 rows × 4 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEz6JajGhutJ"
      },
      "source": [
        "##PRE-PROCESSING FUNCTIONS DEFINITON"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define the functions that will be used for the pre-processing"
      ],
      "metadata": {
        "id": "VMUK9ImanPIg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpk2U5IW6tUk"
      },
      "source": [
        "### Load pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKqME6qJ6s8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b1a4f3a-db30-468a-8142-e8bb232298a3"
      },
      "source": [
        "import gensim\n",
        "import gensim.downloader as gloader\n",
        "\n",
        "def load_embedding_model(model_type: str,\n",
        "                         embedding_dimension: int = 50) -> gensim.models.keyedvectors.KeyedVectors:\n",
        "    \"\"\"\n",
        "    Loads a pre-trained word embedding model via gensim library.\n",
        "\n",
        "    :param model_type: name of the word embedding model to load.\n",
        "    :param embedding_dimension: size of the embedding space to consider\n",
        "\n",
        "    :return\n",
        "        - pre-trained word embedding model (gensim KeyedVectors object)\n",
        "    \"\"\"\n",
        "\n",
        "    download_path = \"\"\n",
        "\n",
        "    # Find the correct embedding model name\n",
        "    if model_type.strip().lower() == 'word2vec':\n",
        "        download_path = \"word2vec-google-news-300\"\n",
        "\n",
        "    elif model_type.strip().lower() == 'glove':\n",
        "        download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\n",
        "    elif model_type.strip().lower() == 'fasttext':\n",
        "        download_path = \"fasttext-wiki-news-subwords-300\"\n",
        "    else:\n",
        "        raise AttributeError(\"Unsupported embedding model type! Available ones:\\\n",
        "         word2vec, glove, fasttext\")\n",
        "\n",
        "    # Check download\n",
        "    try:\n",
        "        emb_model = gloader.load(download_path)\n",
        "    except ValueError as e:\n",
        "        print(\"Invalid embedding model name! Check the embedding dimension:\")\n",
        "        print(\"Word2Vec: 300\")\n",
        "        print(\"Glove: 50, 100, 200, 300\")\n",
        "        raise e\n",
        "\n",
        "    return emb_model"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "c:\\users\\rasha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
            "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCsxb5g6Fnc_"
      },
      "source": [
        "###Check out of vocabulary (OOV) words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s86gnQmFp-q"
      },
      "source": [
        "# Function definition\n",
        "\n",
        "def check_OOV_terms(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n",
        "                    word_listing: List[str]):\n",
        "    \"\"\"\n",
        "    Checks differences between pre-trained embedding model vocabulary\n",
        "    and dataset specific vocabulary in order to highlight out-of-vocabulary terms.\n",
        "\n",
        "    :param embedding_model: pre-trained word embedding model (gensim wrapper)\n",
        "    :param word_listing: dataset specific vocabulary (list)\n",
        "\n",
        "    :return\n",
        "        - list of OOV terms\n",
        "    \"\"\"\n",
        "\n",
        "    embedding_vocabulary = set(embedding_model.vocab.keys())\n",
        "    oov = set(word_listing).difference(embedding_vocabulary)\n",
        "    return list(oov)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrCrkTdiFsYp"
      },
      "source": [
        "###Build embedding matrix and Handle OOV words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks3PUZeyFuYB"
      },
      "source": [
        "# Function definition\n",
        "def build_embedding_matrix(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n",
        "                           embedding_dimension: int,\n",
        "                           word_to_idx: Dict[str, int],\n",
        "                           oov_terms,\n",
        "                           vocab_size=50) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Builds the embedding matrix of a specific dataset given a pre-trained word embedding model\n",
        "\n",
        "    :param embedding_model: pre-trained word embedding model (gensim wrapper)\n",
        "    :param word_to_idx: vocabulary map (word -> index) (dict)\n",
        "    :param vocab_size: size of the vocabulary\n",
        "    :param oov_terms: list of OOV terms (list)\n",
        "\n",
        "    :return\n",
        "        - embedding matrix that assigns a high dimensional vector to each word in the dataset specific vocabulary (shape |V| x d)\n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    for word, idx in tqdm(word_to_idx.items()):\n",
        "        try:\n",
        "            embedding_vector = embedding_model[word]\n",
        "        except (KeyError, TypeError): #if OOV\n",
        "            embedding_vector = np.random.uniform(low=-0.05, high=0.05, size=embedding_dimension)\n",
        "\n",
        "        embedding_matrix[idx] = embedding_vector"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D3LiIxci8xR"
      },
      "source": [
        "###Create the Tokenizer class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Puu2Fxp4MZcu"
      },
      "source": [
        "class KerasTokenizer(object):\n",
        "    \"\"\"\n",
        "    A simple high-level wrapper for the Keras tokenizer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, tokenizer_args=None):\n",
        "        self.vocab = None\n",
        "        tokenizer_args = {} if tokenizer_args is None else tokenizer_args\n",
        "        assert isinstance(tokenizer_args, dict) or isinstance(tokenizer_args, collections.OrderedDict)\n",
        "\n",
        "        self.tokenizer_args = tokenizer_args\n",
        "        self.tokenizer = tf.keras.preprocessing.text.Tokenizer(**self.tokenizer_args)\n",
        "\n",
        "    def build_vocab(self, data, **kwargs):\n",
        "        print('Fitting tokenizer...')\n",
        "        self.tokenizer.fit_on_texts(data)\n",
        "        print('Fit completed!')\n",
        "        self.vocab = self.tokenizer.word_index\n",
        "\n",
        "    def get_info(self):\n",
        "        return {\n",
        "            'vocab_size': len(self.vocab) + 1,\n",
        "        }\n",
        "    \n",
        "    def tokenize(self, text):\n",
        "        return text\n",
        "\n",
        "    def convert_tokens_to_ids(self, tokens):\n",
        "        if type(tokens) == str:\n",
        "            return self.tokenizer.texts_to_sequences([tokens])[0]\n",
        "        else:\n",
        "            return self.tokenizer.texts_to_sequences(tokens)\n",
        "\n",
        "    def convert_ids_to_tokens(self, ids):\n",
        "        return self.tokenizer.sequences_to_texts(ids)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQUvRkvwJI1p"
      },
      "source": [
        "### Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Global splits variables\n",
        "x_train, y_train, x_val, y_val, x_test, y_test = 0,0,0,0,0,0"
      ],
      "metadata": {
        "id": "2wrj3HkAhlzk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(n1,n2): \n",
        "    \"\"\"\n",
        "    splits data into train, validation and test sets\n",
        "\n",
        "    :param n1: size of train split\n",
        "    :param n2: size of validation split\n",
        "    \n",
        "    \"\"\"\n",
        "    global x_train, y_train, x_val, y_val, x_test, y_test\n",
        "    TRAIN_SPLIT = n1\n",
        "    VAL_SPLIT = n2\n",
        "\n",
        "    train_data = df[df['split'] == 'train']\n",
        "    validation_data = df[df['split'] == 'validation']\n",
        "    test_data = df[df['split'] == 'test']\n",
        "\n",
        "    x_train = train_data['text'].values[:TRAIN_SPLIT]\n",
        "    y_train = train_data['tags'].values[:TRAIN_SPLIT]\n",
        "\n",
        "    x_val = validation_data['text'].values[:VAL_SPLIT]\n",
        "    y_val = validation_data['tags'].values[:VAL_SPLIT]\n",
        "\n",
        "    x_test = test_data['text'].values\n",
        "    y_test = test_data['tags'].values\n",
        "\n",
        "    print('Dataset splits statistics: ')\n",
        "    print('Train data: ', x_train.shape)\n",
        "    print('Validation data: ', x_val.shape)\n",
        "    print('Test data: ', x_test.shape)"
      ],
      "metadata": {
        "id": "-JkSAy2gOf1S"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_SaeAQNjFmy"
      },
      "source": [
        "###Buid vocabulary and embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_embedding_matrix(embedding_dimension=200):\n",
        "    \"\"\"\n",
        "    declares and initializes embedding matrix \n",
        "\n",
        "    :param embedding_dimension: embedding dimension\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    global x_train,x_val,x_test\n",
        "    a=np.concatenate([x_train,\n",
        "                      x_val\n",
        "                     , x_test\n",
        "                      ])\n",
        "    total=[]\n",
        "    for l in a:\n",
        "        total = np.concatenate([total,l])\n",
        "    unique_words=set(total)\n",
        "    \n",
        "    global embedding_matrix\n",
        "    embedding_matrix = np.zeros((len(unique_words)+2,\n",
        "                                 embedding_dimension),\n",
        "                                 dtype=np.float32) "
      ],
      "metadata": {
        "id": "zC8Q_lUgPQhI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this rather long function below, we initalize a **tokenizer** for all the words of the dataset and similarily a **tags_tokenizer** for all the tags. We also call init_embedding_matrix() to initialize the embedding matrix that will store all of the embeddings. Then for each of the train, validation and test splits we:\n",
        "\n",
        "1.   Build the vocab for words\n",
        "2.   Build the vocab for tags\n",
        "3.   Add the embeddings to the single cumulative embedding matrix\n",
        "\n",
        "**Note**: we assigned random embeddings for OOV terms thus they are naturally independent from the data, however we still computed them independently for each split in build_embedding_matrix() in case an improved method of OOV handling is adopted."
      ],
      "metadata": {
        "id": "xi4mx9FdEBOs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbXbBqEDMlKK"
      },
      "source": [
        "def build_vocabulary(embedding_dimension):\n",
        "    \"\"\"\n",
        "    Builds the vocabulary and populates the embedding matrix\n",
        "\n",
        "    :param embedding_dimension: dimension of embedding matrix \n",
        "    \n",
        "    :return\n",
        "        - word tokenizer and tags tokenizer\n",
        "    \"\"\"\n",
        "    global x_train, y_train, x_val, y_val, x_test, y_test\n",
        "\n",
        "    tokenizer_args = {\n",
        "        'filters': '', # dont filter out punctuation\n",
        "        'oov_token': 1 # The vocabulary id for unknown terms during text conversion\n",
        "    }\n",
        "\n",
        "    # word tokenizer\n",
        "    tokenizer = KerasTokenizer(tokenizer_args=tokenizer_args)\n",
        "    \n",
        "    # tags tokenizer\n",
        "    tags_tokenizer = KerasTokenizer()\n",
        "\n",
        "    init_embedding_matrix(embedding_dimension)\n",
        "\n",
        "    ''' \n",
        "    In the next part, \n",
        "\n",
        "    V1:     train vocabulary\n",
        "    V2:     validation vocabulary\n",
        "    V3:     test vocabulary\n",
        "    V12:    V1+V2\n",
        "    V123:   V1+V2+V3\n",
        "\n",
        "    since build_vocab() will add the words to the same dictionary, V1 and V1+V2 \n",
        "    are saved as intermediary values needed to compute the vocabulary and \n",
        "    embeddings of the next split independently from the other splits\n",
        "    '''\n",
        "\n",
        "    # TRAIN\n",
        "    tokenizer.build_vocab(x_train) # build train set vocab V1\n",
        "    tags_tokenizer.build_vocab(y_train) # build vocab for train tags\n",
        "\n",
        "    # save V1 in order to later get V2 = V12 - V1\n",
        "    V1 = tokenizer.vocab\n",
        "    \n",
        "    # compute embeddings for train set\n",
        "    OOV1 = check_OOV_terms(embedding_model, tokenizer.vocab.keys())\n",
        "    build_embedding_matrix(embedding_model,\n",
        "                            word_to_idx=V1,\n",
        "                            embedding_dimension=embedding_dimension,\n",
        "                            oov_terms=OOV1)\n",
        "    \n",
        "\n",
        "    # VAL\n",
        "    tokenizer.build_vocab(x_val) # build val set vocab V2\n",
        "    tags_tokenizer.build_vocab(y_val) # build vocab for val tags\n",
        "\n",
        "    # compute V2 = V12 - V1. We subtract V1 from the current vocab of \n",
        "    # the tokenizer\n",
        "    V2 = {k:v for k,v in tokenizer.vocab.items() if k not in V1} \n",
        "\n",
        "    # save V1+V2 in order to later get V3 = V123 - V12\n",
        "    V12 = tokenizer.vocab\n",
        "\n",
        "    # compute embeddings for val set\n",
        "    OOV2 = check_OOV_terms(embedding_model, tokenizer.vocab.keys())\n",
        "    build_embedding_matrix(embedding_model,\n",
        "                            word_to_idx=V2,\n",
        "                            embedding_dimension=embedding_dimension,\n",
        "                            oov_terms=OOV2)\n",
        "    \n",
        "\n",
        "    # TEST\n",
        "    tokenizer.build_vocab(x_test) # build test set vocab V3\n",
        "    tags_tokenizer.build_vocab(y_test) # build vocab for test tags\n",
        "\n",
        "    # V3 = V123 - V12. We subtract V12 from the current vocab of \n",
        "    # the tokenizer\n",
        "    V3 = {k:v for k,v in tokenizer.vocab.items() if k not in V12} \n",
        "\n",
        "    # compute embeddings for test set\n",
        "    OOV3 = check_OOV_terms(embedding_model, tokenizer.vocab.keys())\n",
        "    build_embedding_matrix(embedding_model,\n",
        "                            word_to_idx=V3,\n",
        "                            embedding_dimension=embedding_dimension,\n",
        "                            oov_terms = OOV3)\n",
        "\n",
        "\n",
        "    tokenizer_info = tokenizer.get_info()\n",
        "    tags_tokenizer_info = tags_tokenizer.get_info()\n",
        "    print('\\nWord Tokenizer info: ', tokenizer_info)\n",
        "    print('\\nTags Tokenizer info: ', tags_tokenizer_info)\n",
        "\n",
        "    return tokenizer, tags_tokenizer"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_h0fU-m9vpz"
      },
      "source": [
        "###Convert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RxmrJOiomT3"
      },
      "source": [
        "def convert_text(texts, tokenizer, is_training=False, max_seq_length=None):\n",
        "    \"\"\"\n",
        "    Converts input text sequences using a given tokenizer\n",
        "\n",
        "    :param texts: either a list or numpy ndarray of strings\n",
        "    :tokenizer: an instantiated tokenizer\n",
        "    :is_training: whether input texts are from the training split or not\n",
        "    :max_seq_length: the max token sequence previously computed with\n",
        "    training texts.\n",
        "\n",
        "    :return\n",
        "        text_ids: a nested list on token indices\n",
        "        max_seq_length: the max token sequence previously computed with\n",
        "        training texts.\n",
        "    \"\"\"\n",
        "\n",
        "    text_ids = tokenizer.convert_tokens_to_ids(texts)\n",
        "\n",
        "    # Padding\n",
        "    if is_training:\n",
        "        max_seq_length = int(np.quantile([len(seq) for seq in text_ids], 0.99))\n",
        "    else:\n",
        "        assert max_seq_length is not None\n",
        "\n",
        "    text_ids = [seq + [0] * (max_seq_length - len(seq)) for seq in text_ids]\n",
        "    text_ids = np.array([seq[:max_seq_length] for seq in text_ids])\n",
        "\n",
        "    if is_training:\n",
        "        return text_ids, max_seq_length\n",
        "    else:\n",
        "        return text_ids"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(tokenizer, tags_tokenizer):\n",
        "    \"\"\"\n",
        "    Converts input text sequences using a given tokenizer\n",
        "\n",
        "    :tokenizer: an instantiated tokenizer for words\n",
        "    :tags_tokenizer: an instantiated tokenizer for words\n",
        "\n",
        "    :return\n",
        "        max_seq_length: the max token sequence previously computed with\n",
        "        training texts.\n",
        "    \"\"\"\n",
        "    global x_train, y_train, x_val, y_val, x_test, y_test\n",
        "\n",
        "    # Train\n",
        "    x_train, max_seq_length = convert_text(x_train, tokenizer, True)\n",
        "    y_train = convert_text(y_train, tags_tokenizer, False, max_seq_length)\n",
        "\n",
        "    # Val\n",
        "    x_val = convert_text(x_val, tokenizer, False, max_seq_length)\n",
        "    y_val = convert_text(y_val, tags_tokenizer, False, max_seq_length)\n",
        "\n",
        "    # Test\n",
        "    x_test = convert_text(x_test, tokenizer, False, max_seq_length)\n",
        "    y_test = convert_text(y_test, tags_tokenizer, False, max_seq_length)\n",
        "    \n",
        "    print(\"Max token sequence: {}\".format(max_seq_length))\n",
        "\n",
        "    print('X train shape: ', x_train.shape)\n",
        "    print('Y train shape: ', y_train.shape)\n",
        "\n",
        "    print('X val shape: ', x_val.shape)\n",
        "    print('Y val shape: ', y_val.shape)\n",
        "\n",
        "    print('X test shape: ', x_test.shape)\n",
        "    print('Y test shape: ', y_test.shape)\n",
        "\n",
        "    return max_seq_length"
      ],
      "metadata": {
        "id": "e5VJ10jBZ3-J"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**RUN PRE-PROCESSING FUNCTIONS**"
      ],
      "metadata": {
        "id": "_OfIxsm-aCx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we call all of the pre-processing functions to ready our data to be given to the models."
      ],
      "metadata": {
        "id": "iEKeITEGpahu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-processing params\n",
        "\n",
        "#num of documents used\n",
        "TRAIN_SIZE = 100\n",
        "VAL_SIZE = 50\n",
        "# Glove -> 50, 100, 200, 300\n",
        "embedding_model_type = \"glove\"\n",
        "embedding_dimension = 200"
      ],
      "metadata": {
        "id": "J4QEKW_1b93f"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load embedding model\n",
        "embedding_model = load_embedding_model(embedding_model_type, embedding_dimension)"
      ],
      "metadata": {
        "id": "REqqa8DUcC5N"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split data into train val and test\n",
        "split_data(TRAIN_SIZE, VAL_SIZE)\n",
        "\n",
        "# get length of each sample before padding to truncate them later\n",
        "y_test_lens = [len(sample) for sample in y_test] \n",
        "\n",
        "# build the vocab for text and tags\n",
        "tokenizer, tags_tokenizer = build_vocabulary(embedding_dimension)\n",
        "\n",
        "# convert sequences to integers and pad them\n",
        "max_seq_length = convert(tokenizer, tags_tokenizer)\n",
        "\n",
        "tags=list(tags_tokenizer.vocab.keys())\n",
        "tag_ids=list(tags_tokenizer.vocab.values())"
      ],
      "metadata": {
        "id": "Y_-Vz5eLaHL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae9342c6-7c47-46bf-a7aa-049b573fdc9b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset splits statistics: \n",
            "Train data:  (100,)\n",
            "Validation data:  (50,)\n",
            "Test data:  (49,)\n",
            "Fitting tokenizer...\n",
            "Fit completed!\n",
            "Fitting tokenizer...\n",
            "Fit completed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████| 7405/7405 [00:00<00:00, 88884.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting tokenizer...\n",
            "Fit completed!\n",
            "Fitting tokenizer...\n",
            "Fit completed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████| 2497/2497 [00:00<00:00, 55279.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting tokenizer...\n",
            "Fit completed!\n",
            "Fitting tokenizer...\n",
            "Fit completed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████| 1046/1046 [00:00<00:00, 45597.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word Tokenizer info:  {'vocab_size': 10949}\n",
            "\n",
            "Tags Tokenizer info:  {'vocab_size': 46}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max token sequence: 1897\n",
            "X train shape:  (100, 1897)\n",
            "Y train shape:  (100, 1897)\n",
            "X val shape:  (50, 1897)\n",
            "Y val shape:  (50, 1897)\n",
            "X test shape:  (49, 1897)\n",
            "Y test shape:  (49, 1897)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Models"
      ],
      "metadata": {
        "id": "DPFxBn5SlZgU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary libraries"
      ],
      "metadata": {
        "id": "6CcTOcMxD6vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, GRU, Dropout, Masking, Embedding, Bidirectional, TimeDistributed"
      ],
      "metadata": {
        "id": "da1hJUWnCwAc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.vocab)+1\n",
        "num_classes = len(tags_tokenizer.vocab)+1"
      ],
      "metadata": {
        "id": "Hbv_tGU6uyYb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model functions definition"
      ],
      "metadata": {
        "id": "xylLsFgdkxac"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbcDJc4HpB9l"
      },
      "source": [
        "def show_history(history: keras.callbacks.History):\n",
        "    \"\"\"\n",
        "    Shows training history data stored by the History Keras callback\n",
        "\n",
        "    :param history: History Keras callback\n",
        "    \"\"\"\n",
        "\n",
        "    history_data = history.history\n",
        "    print(\"Displaying the following history keys: \", history_data.keys())\n",
        "\n",
        "    for key, value in history_data.items():\n",
        "        if not key.startswith('val'):\n",
        "            fig, ax = plt.subplots(1, 1)\n",
        "            ax.set_title(key)\n",
        "            ax.plot(value)\n",
        "            if 'val_{}'.format(key) in history_data:\n",
        "                ax.plot(history_data['val_{}'.format(key)])\n",
        "            else:\n",
        "                print(\"Couldn't find validation values for metric: \", key)\n",
        "\n",
        "            ax.set_ylabel(key)\n",
        "            ax.set_xlabel('epoch')\n",
        "            ax.legend(['train', 'val'], loc='best')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def train_model(model: keras.Model,\n",
        "                x_train: np.ndarray,\n",
        "                y_train: np.ndarray,\n",
        "                x_val: np.ndarray,\n",
        "                y_val: np.ndarray,\n",
        "                training_info: Dict):\n",
        "    \"\"\"\n",
        "    Training routine for the Keras model.\n",
        "    At the end of the training, retrieved History data is shown.\n",
        "\n",
        "    :param model: Keras built model\n",
        "    :param x_train: training data in np.ndarray format\n",
        "    :param y_train: training labels in np.ndarray format\n",
        "    :param x_val: validation data in np.ndarray format\n",
        "    :param y_val: validation labels in np.ndarray format\n",
        "    :param training_info: dictionary storing model fit() argument information\n",
        "\n",
        "    :return\n",
        "        model: trained Keras model\n",
        "    \"\"\"\n",
        "    print(\"Start training! \\nParameters: {}\\nTrain size: {}\\nVal size: {}\".format(training_info,TRAIN_SIZE,VAL_SIZE))\n",
        "    history = model.fit(x=x_train, y=y_train,\n",
        "                        validation_data=(x_val, y_val),\n",
        "                        **training_info)\n",
        "    print(\"Training completed! Showing history...\")\n",
        "\n",
        "    show_history(history)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def predict_data(model: keras.Model,\n",
        "                 x: np.ndarray,\n",
        "                 prediction_info: Dict) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Inference routine of a given input set of examples\n",
        "\n",
        "    :param model: Keras built and possibly trained model\n",
        "    :param x: input set of examples in np.ndarray format\n",
        "    :param prediction_info: dictionary storing model predict() argument information\n",
        "\n",
        "    :return\n",
        "        predictions: predicted labels in np.ndarray format\n",
        "    \"\"\"\n",
        "\n",
        "    print('Starting prediction: \\n{}'.format(prediction_info))\n",
        "    print('Predicting on {} samples'.format(x.shape[0]))\n",
        "\n",
        "    predictions = model.predict(x, **prediction_info)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "def evaluate_predictions(predictions: np.ndarray,\n",
        "                         y: np.ndarray,\n",
        "                         metrics: List[Callable],\n",
        "                         metric_names: List[str]):\n",
        "    \"\"\"\n",
        "    Evaluates given model predictions on a list of metric functions\n",
        "\n",
        "    :param predictions: model predictions in np.ndarray format\n",
        "    :param y: ground-truth labels in np.ndarray format\n",
        "    :param metrics: list of metric functions\n",
        "    :param metric_names: list of metric names\n",
        "\n",
        "    :return\n",
        "        metric_info: dictionary containing metric values for each input metric\n",
        "    \"\"\"\n",
        "\n",
        "    assert len(metrics) == len(metric_names)\n",
        "\n",
        "    print(\"Evaluating predictions! Total samples: \", y.shape[0])\n",
        "\n",
        "    metric_info = {}\n",
        "\n",
        "    for metric, metric_name in zip(metrics, metric_names):\n",
        "        metric_value = metric(y_pred=predictions, y_true=y)\n",
        "        metric_info[metric_name] = metric_value\n",
        "\n",
        "    return metric_info"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq9A0EepgjhK"
      },
      "source": [
        "## Baseline model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Compile"
      ],
      "metadata": {
        "id": "wIFxyfurkHe0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15fGsHiKgo9X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59f78dad-7efb-43ff-e745-163dca128b7d"
      },
      "source": [
        "baseline = Sequential()\n",
        "\n",
        "# Embedding layer\n",
        "baseline.add(Embedding(input_dim = vocab_size,\n",
        "              input_length = max_seq_length,\n",
        "              output_dim=embedding_dimension,\n",
        "              weights = embedding_matrix if embedding_matrix is None else [embedding_matrix],\n",
        "              trainable=False,\n",
        "              mask_zero=True))\n",
        "\n",
        "# Bidirectional layer\n",
        "baseline.add(Bidirectional(LSTM(64, return_sequences=True \n",
        "               ,dropout=0.1\n",
        "               )))               \n",
        "\n",
        "baseline.add(TimeDistributed(Dense(num_classes,\n",
        "            activation= 'softmax')))\n",
        "\n",
        "# Compile the model\n",
        "baseline.compile(\n",
        "    optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "baseline.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 1897, 200)         2189800   \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 1897, 128)        135680    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 1897, 46)         5934      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,331,414\n",
            "Trainable params: 141,614\n",
            "Non-trainable params: 2,189,800\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "TPMhFU5hkduA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "training_info = {\n",
        "    'verbose': 1,\n",
        "    'epochs': 1000,\n",
        "    'batch_size': 32,\n",
        "    'callbacks': [keras.callbacks.EarlyStopping(monitor='val_loss', \n",
        "                                                patience=15,\n",
        "                                                restore_best_weights=True)]\n",
        "}\n",
        "baseline = train_model(model=baseline, x_train=x_train, y_train=y_train,\n",
        "                    x_val=x_val, y_val=y_val, training_info=training_info)"
      ],
      "metadata": {
        "id": "UcFTBmf9kZyg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a4a70eeb-8395-4cb2-ba6a-32878457f2cd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training! \n",
            "Parameters: {'verbose': 1, 'epochs': 1000, 'batch_size': 32, 'callbacks': [<keras.callbacks.EarlyStopping object at 0x000001DCECED0E80>]}\n",
            "Train size: 100\n",
            "Val size: 50\n",
            "Epoch 1/1000\n",
            "4/4 [==============================] - 30s 3s/step - loss: 0.9192 - accuracy: 0.0482 - val_loss: 1.0497 - val_accuracy: 0.1394\n",
            "Epoch 2/1000\n",
            "4/4 [==============================] - 2s 630ms/step - loss: 0.8308 - accuracy: 0.1410 - val_loss: 0.9677 - val_accuracy: 0.1699\n",
            "Epoch 3/1000\n",
            "4/4 [==============================] - 2s 594ms/step - loss: 0.7746 - accuracy: 0.1657 - val_loss: 0.9158 - val_accuracy: 0.1770\n",
            "Epoch 4/1000\n",
            "4/4 [==============================] - 3s 705ms/step - loss: 0.7349 - accuracy: 0.1820 - val_loss: 0.8866 - val_accuracy: 0.2524\n",
            "Epoch 5/1000\n",
            "4/4 [==============================] - 3s 695ms/step - loss: 0.7134 - accuracy: 0.2588 - val_loss: 0.8670 - val_accuracy: 0.2767\n",
            "Epoch 6/1000\n",
            "4/4 [==============================] - 2s 645ms/step - loss: 0.6970 - accuracy: 0.2795 - val_loss: 0.8476 - val_accuracy: 0.2771\n",
            "Epoch 7/1000\n",
            "4/4 [==============================] - 2s 605ms/step - loss: 0.6802 - accuracy: 0.2858 - val_loss: 0.8282 - val_accuracy: 0.2898\n",
            "Epoch 8/1000\n",
            "4/4 [==============================] - 2s 635ms/step - loss: 0.6644 - accuracy: 0.2990 - val_loss: 0.8085 - val_accuracy: 0.3100\n",
            "Epoch 9/1000\n",
            "4/4 [==============================] - 2s 625ms/step - loss: 0.6481 - accuracy: 0.3250 - val_loss: 0.7885 - val_accuracy: 0.3381\n",
            "Epoch 10/1000\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 0.6297 - accuracy: 0.3562 - val_loss: 0.7685 - val_accuracy: 0.3731\n",
            "Epoch 11/1000\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.6142 - accuracy: 0.3813 - val_loss: 0.7482 - val_accuracy: 0.3803\n",
            "Epoch 12/1000\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.5948 - accuracy: 0.4033 - val_loss: 0.7237 - val_accuracy: 0.4167\n",
            "Epoch 13/1000\n",
            "4/4 [==============================] - 1s 312ms/step - loss: 0.5762 - accuracy: 0.4247 - val_loss: 0.7009 - val_accuracy: 0.4277\n",
            "Epoch 14/1000\n",
            "4/4 [==============================] - 1s 313ms/step - loss: 0.5563 - accuracy: 0.4442 - val_loss: 0.6800 - val_accuracy: 0.4362\n",
            "Epoch 15/1000\n",
            "4/4 [==============================] - 1s 281ms/step - loss: 0.5380 - accuracy: 0.4546 - val_loss: 0.6575 - val_accuracy: 0.4510\n",
            "Epoch 16/1000\n",
            "4/4 [==============================] - 1s 273ms/step - loss: 0.5198 - accuracy: 0.4675 - val_loss: 0.6373 - val_accuracy: 0.4616\n",
            "Epoch 17/1000\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 0.5033 - accuracy: 0.4793 - val_loss: 0.6188 - val_accuracy: 0.4690\n",
            "Epoch 18/1000\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.4877 - accuracy: 0.4890 - val_loss: 0.6022 - val_accuracy: 0.4761\n",
            "Epoch 19/1000\n",
            "4/4 [==============================] - 1s 282ms/step - loss: 0.4748 - accuracy: 0.4971 - val_loss: 0.5860 - val_accuracy: 0.4883\n",
            "Epoch 20/1000\n",
            "4/4 [==============================] - 1s 310ms/step - loss: 0.4619 - accuracy: 0.5081 - val_loss: 0.5723 - val_accuracy: 0.4966\n",
            "Epoch 21/1000\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.4494 - accuracy: 0.5166 - val_loss: 0.5601 - val_accuracy: 0.5030\n",
            "Epoch 22/1000\n",
            "4/4 [==============================] - 3s 1s/step - loss: 0.4381 - accuracy: 0.5255 - val_loss: 0.5468 - val_accuracy: 0.5146\n",
            "Epoch 23/1000\n",
            "4/4 [==============================] - 2s 636ms/step - loss: 0.4285 - accuracy: 0.5340 - val_loss: 0.5358 - val_accuracy: 0.5222\n",
            "Epoch 24/1000\n",
            "4/4 [==============================] - 2s 662ms/step - loss: 0.4192 - accuracy: 0.5424 - val_loss: 0.5247 - val_accuracy: 0.5310\n",
            "Epoch 25/1000\n",
            "4/4 [==============================] - 2s 414ms/step - loss: 0.4101 - accuracy: 0.5476 - val_loss: 0.5165 - val_accuracy: 0.5320\n",
            "Epoch 26/1000\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 0.4013 - accuracy: 0.5585 - val_loss: 0.5055 - val_accuracy: 0.5467\n",
            "Epoch 27/1000\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.3941 - accuracy: 0.5689 - val_loss: 0.4972 - val_accuracy: 0.5503\n",
            "Epoch 28/1000\n",
            "4/4 [==============================] - 1s 281ms/step - loss: 0.3867 - accuracy: 0.5705 - val_loss: 0.4900 - val_accuracy: 0.5518\n",
            "Epoch 29/1000\n",
            "4/4 [==============================] - 1s 293ms/step - loss: 0.3801 - accuracy: 0.5747 - val_loss: 0.4832 - val_accuracy: 0.5565\n",
            "Epoch 30/1000\n",
            "4/4 [==============================] - 1s 296ms/step - loss: 0.3737 - accuracy: 0.5813 - val_loss: 0.4742 - val_accuracy: 0.5681\n",
            "Epoch 31/1000\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.3681 - accuracy: 0.5903 - val_loss: 0.4684 - val_accuracy: 0.5742\n",
            "Epoch 32/1000\n",
            "4/4 [==============================] - 1s 287ms/step - loss: 0.3621 - accuracy: 0.5949 - val_loss: 0.4636 - val_accuracy: 0.5732\n",
            "Epoch 33/1000\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.3580 - accuracy: 0.5925 - val_loss: 0.4576 - val_accuracy: 0.5792\n",
            "Epoch 34/1000\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.3518 - accuracy: 0.6047 - val_loss: 0.4512 - val_accuracy: 0.5893\n",
            "Epoch 35/1000\n",
            "4/4 [==============================] - 1s 267ms/step - loss: 0.3480 - accuracy: 0.6110 - val_loss: 0.4459 - val_accuracy: 0.5905\n",
            "Epoch 36/1000\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.3431 - accuracy: 0.6106 - val_loss: 0.4417 - val_accuracy: 0.5910\n",
            "Epoch 37/1000\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.3387 - accuracy: 0.6157 - val_loss: 0.4355 - val_accuracy: 0.5979\n",
            "Epoch 38/1000\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 0.3343 - accuracy: 0.6227 - val_loss: 0.4311 - val_accuracy: 0.6009\n",
            "Epoch 39/1000\n",
            "4/4 [==============================] - 1s 314ms/step - loss: 0.3303 - accuracy: 0.6260 - val_loss: 0.4269 - val_accuracy: 0.6032\n",
            "Epoch 40/1000\n",
            "4/4 [==============================] - 1s 285ms/step - loss: 0.3267 - accuracy: 0.6276 - val_loss: 0.4227 - val_accuracy: 0.6043\n",
            "Epoch 41/1000\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.3234 - accuracy: 0.6305 - val_loss: 0.4188 - val_accuracy: 0.6077\n",
            "Epoch 42/1000\n",
            "4/4 [==============================] - 1s 276ms/step - loss: 0.3194 - accuracy: 0.6347 - val_loss: 0.4143 - val_accuracy: 0.6108\n",
            "Epoch 43/1000\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.3159 - accuracy: 0.6373 - val_loss: 0.4099 - val_accuracy: 0.6130\n",
            "Epoch 44/1000\n",
            "4/4 [==============================] - 1s 278ms/step - loss: 0.3126 - accuracy: 0.6413 - val_loss: 0.4067 - val_accuracy: 0.6165\n",
            "Epoch 45/1000\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.3096 - accuracy: 0.6439 - val_loss: 0.4043 - val_accuracy: 0.6178\n",
            "Epoch 46/1000\n",
            "4/4 [==============================] - 1s 260ms/step - loss: 0.3067 - accuracy: 0.6468 - val_loss: 0.3998 - val_accuracy: 0.6204\n",
            "Epoch 47/1000\n",
            "4/4 [==============================] - 1s 305ms/step - loss: 0.3031 - accuracy: 0.6504 - val_loss: 0.3954 - val_accuracy: 0.6246\n",
            "Epoch 48/1000\n",
            "4/4 [==============================] - 1s 264ms/step - loss: 0.3001 - accuracy: 0.6531 - val_loss: 0.3934 - val_accuracy: 0.6263\n",
            "Epoch 49/1000\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.2972 - accuracy: 0.6554 - val_loss: 0.3892 - val_accuracy: 0.6284\n",
            "Epoch 50/1000\n",
            "4/4 [==============================] - 1s 282ms/step - loss: 0.2946 - accuracy: 0.6581 - val_loss: 0.3855 - val_accuracy: 0.6309\n",
            "Epoch 51/1000\n",
            "4/4 [==============================] - 1s 262ms/step - loss: 0.2915 - accuracy: 0.6603 - val_loss: 0.3840 - val_accuracy: 0.6321\n",
            "Epoch 52/1000\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.2892 - accuracy: 0.6622 - val_loss: 0.3800 - val_accuracy: 0.6351\n",
            "Epoch 53/1000\n",
            "4/4 [==============================] - 1s 269ms/step - loss: 0.2859 - accuracy: 0.6650 - val_loss: 0.3766 - val_accuracy: 0.6377\n",
            "Epoch 54/1000\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 0.2838 - accuracy: 0.6668 - val_loss: 0.3747 - val_accuracy: 0.6391\n",
            "Epoch 55/1000\n",
            "4/4 [==============================] - 1s 294ms/step - loss: 0.2815 - accuracy: 0.6699 - val_loss: 0.3716 - val_accuracy: 0.6416\n",
            "Epoch 56/1000\n",
            "4/4 [==============================] - 1s 277ms/step - loss: 0.2789 - accuracy: 0.6720 - val_loss: 0.3683 - val_accuracy: 0.6457\n",
            "Epoch 57/1000\n",
            "4/4 [==============================] - 1s 270ms/step - loss: 0.2765 - accuracy: 0.6744 - val_loss: 0.3666 - val_accuracy: 0.6463\n",
            "Epoch 58/1000\n",
            "4/4 [==============================] - 1s 268ms/step - loss: 0.2743 - accuracy: 0.6778 - val_loss: 0.3662 - val_accuracy: 0.6465\n",
            "Epoch 59/1000\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.2731 - accuracy: 0.6773 - val_loss: 0.3620 - val_accuracy: 0.6499\n",
            "Epoch 60/1000\n",
            "4/4 [==============================] - 1s 266ms/step - loss: 0.2700 - accuracy: 0.6818 - val_loss: 0.3590 - val_accuracy: 0.6526\n",
            "Epoch 61/1000\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 0.2675 - accuracy: 0.6849 - val_loss: 0.3574 - val_accuracy: 0.6550\n",
            "Epoch 62/1000\n",
            "4/4 [==============================] - 1s 279ms/step - loss: 0.2652 - accuracy: 0.6886 - val_loss: 0.3545 - val_accuracy: 0.6574\n",
            "Epoch 63/1000\n",
            "4/4 [==============================] - 1s 270ms/step - loss: 0.2634 - accuracy: 0.6871 - val_loss: 0.3517 - val_accuracy: 0.6597\n",
            "Epoch 64/1000\n",
            "4/4 [==============================] - 1s 271ms/step - loss: 0.2613 - accuracy: 0.6904 - val_loss: 0.3513 - val_accuracy: 0.6594\n",
            "Epoch 65/1000\n",
            "4/4 [==============================] - 1s 278ms/step - loss: 0.2595 - accuracy: 0.6940 - val_loss: 0.3482 - val_accuracy: 0.6619\n",
            "Epoch 66/1000\n",
            "4/4 [==============================] - 1s 271ms/step - loss: 0.2577 - accuracy: 0.6950 - val_loss: 0.3457 - val_accuracy: 0.6646\n",
            "Epoch 67/1000\n",
            "4/4 [==============================] - 1s 274ms/step - loss: 0.2553 - accuracy: 0.6980 - val_loss: 0.3442 - val_accuracy: 0.6663\n",
            "Epoch 68/1000\n",
            "4/4 [==============================] - 1s 262ms/step - loss: 0.2537 - accuracy: 0.7010 - val_loss: 0.3420 - val_accuracy: 0.6687\n",
            "Epoch 69/1000\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.2522 - accuracy: 0.7025 - val_loss: 0.3398 - val_accuracy: 0.6692\n",
            "Epoch 70/1000\n",
            "4/4 [==============================] - 1s 302ms/step - loss: 0.2503 - accuracy: 0.7050 - val_loss: 0.3374 - val_accuracy: 0.6715\n",
            "Epoch 71/1000\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 0.2489 - accuracy: 0.7058 - val_loss: 0.3375 - val_accuracy: 0.6718\n",
            "Epoch 72/1000\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 0.2475 - accuracy: 0.7059 - val_loss: 0.3348 - val_accuracy: 0.6752\n",
            "Epoch 73/1000\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.2452 - accuracy: 0.7119 - val_loss: 0.3322 - val_accuracy: 0.6764\n",
            "Epoch 74/1000\n",
            "4/4 [==============================] - 1s 267ms/step - loss: 0.2435 - accuracy: 0.7144 - val_loss: 0.3323 - val_accuracy: 0.6752\n",
            "Epoch 75/1000\n",
            "4/4 [==============================] - 1s 277ms/step - loss: 0.2421 - accuracy: 0.7121 - val_loss: 0.3298 - val_accuracy: 0.6786\n",
            "Epoch 76/1000\n",
            "4/4 [==============================] - 1s 278ms/step - loss: 0.2403 - accuracy: 0.7177 - val_loss: 0.3284 - val_accuracy: 0.6800\n",
            "Epoch 77/1000\n",
            "4/4 [==============================] - 1s 282ms/step - loss: 0.2386 - accuracy: 0.7192 - val_loss: 0.3269 - val_accuracy: 0.6811\n",
            "Epoch 78/1000\n",
            "4/4 [==============================] - 1s 292ms/step - loss: 0.2369 - accuracy: 0.7200 - val_loss: 0.3241 - val_accuracy: 0.6841\n",
            "Epoch 79/1000\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.2356 - accuracy: 0.7216 - val_loss: 0.3231 - val_accuracy: 0.6842\n",
            "Epoch 80/1000\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 0.2339 - accuracy: 0.7248 - val_loss: 0.3220 - val_accuracy: 0.6862\n",
            "Epoch 81/1000\n",
            "4/4 [==============================] - 1s 283ms/step - loss: 0.2325 - accuracy: 0.7263 - val_loss: 0.3201 - val_accuracy: 0.6874\n",
            "Epoch 82/1000\n",
            "4/4 [==============================] - 1s 272ms/step - loss: 0.2307 - accuracy: 0.7294 - val_loss: 0.3189 - val_accuracy: 0.6879\n",
            "Epoch 83/1000\n",
            "4/4 [==============================] - 1s 296ms/step - loss: 0.2291 - accuracy: 0.7319 - val_loss: 0.3171 - val_accuracy: 0.6899\n",
            "Epoch 84/1000\n",
            "4/4 [==============================] - 1s 291ms/step - loss: 0.2282 - accuracy: 0.7304 - val_loss: 0.3158 - val_accuracy: 0.6909\n",
            "Epoch 85/1000\n",
            "4/4 [==============================] - 1s 266ms/step - loss: 0.2272 - accuracy: 0.7318 - val_loss: 0.3159 - val_accuracy: 0.6911\n",
            "Epoch 86/1000\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 0.2260 - accuracy: 0.7316 - val_loss: 0.3124 - val_accuracy: 0.6955\n",
            "Epoch 87/1000\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.2245 - accuracy: 0.7355 - val_loss: 0.3114 - val_accuracy: 0.6967\n",
            "Epoch 88/1000\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.2229 - accuracy: 0.7383 - val_loss: 0.3118 - val_accuracy: 0.6947\n",
            "Epoch 89/1000\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.2212 - accuracy: 0.7402 - val_loss: 0.3091 - val_accuracy: 0.6982\n",
            "Epoch 90/1000\n",
            "4/4 [==============================] - 1s 277ms/step - loss: 0.2193 - accuracy: 0.7412 - val_loss: 0.3072 - val_accuracy: 0.6996\n",
            "Epoch 91/1000\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.2189 - accuracy: 0.7436 - val_loss: 0.3065 - val_accuracy: 0.7011\n",
            "Epoch 92/1000\n",
            "4/4 [==============================] - 1s 266ms/step - loss: 0.2169 - accuracy: 0.7464 - val_loss: 0.3066 - val_accuracy: 0.6985\n",
            "Epoch 93/1000\n",
            "4/4 [==============================] - 1s 264ms/step - loss: 0.2166 - accuracy: 0.7459 - val_loss: 0.3033 - val_accuracy: 0.7040\n",
            "Epoch 94/1000\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.2144 - accuracy: 0.7484 - val_loss: 0.3026 - val_accuracy: 0.7038\n",
            "Epoch 95/1000\n",
            "4/4 [==============================] - 1s 278ms/step - loss: 0.2134 - accuracy: 0.7475 - val_loss: 0.3020 - val_accuracy: 0.7058\n",
            "Epoch 96/1000\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.2131 - accuracy: 0.7509 - val_loss: 0.3003 - val_accuracy: 0.7045\n",
            "Epoch 97/1000\n",
            "4/4 [==============================] - 1s 295ms/step - loss: 0.2117 - accuracy: 0.7497 - val_loss: 0.2985 - val_accuracy: 0.7072\n",
            "Epoch 98/1000\n",
            "4/4 [==============================] - 1s 263ms/step - loss: 0.2105 - accuracy: 0.7518 - val_loss: 0.2984 - val_accuracy: 0.7071\n",
            "Epoch 99/1000\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.2092 - accuracy: 0.7525 - val_loss: 0.2963 - val_accuracy: 0.7100\n",
            "Epoch 100/1000\n",
            "4/4 [==============================] - 1s 280ms/step - loss: 0.2075 - accuracy: 0.7551 - val_loss: 0.2949 - val_accuracy: 0.7114\n",
            "Epoch 101/1000\n",
            "4/4 [==============================] - 1s 291ms/step - loss: 0.2070 - accuracy: 0.7571 - val_loss: 0.2957 - val_accuracy: 0.7091\n",
            "Epoch 102/1000\n",
            "4/4 [==============================] - 1s 322ms/step - loss: 0.2049 - accuracy: 0.7584 - val_loss: 0.2929 - val_accuracy: 0.7118\n",
            "Epoch 103/1000\n",
            "4/4 [==============================] - 1s 275ms/step - loss: 0.2043 - accuracy: 0.7597 - val_loss: 0.2926 - val_accuracy: 0.7113\n",
            "Epoch 104/1000\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.2027 - accuracy: 0.7609 - val_loss: 0.2912 - val_accuracy: 0.7150\n",
            "Epoch 105/1000\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.2022 - accuracy: 0.7625 - val_loss: 0.2898 - val_accuracy: 0.7139\n",
            "Epoch 106/1000\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.2008 - accuracy: 0.7627 - val_loss: 0.2884 - val_accuracy: 0.7165\n",
            "Epoch 107/1000\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.1993 - accuracy: 0.7675 - val_loss: 0.2879 - val_accuracy: 0.7175\n",
            "Epoch 108/1000\n",
            "4/4 [==============================] - 1s 316ms/step - loss: 0.1983 - accuracy: 0.7676 - val_loss: 0.2873 - val_accuracy: 0.7189\n",
            "Epoch 109/1000\n",
            "4/4 [==============================] - 1s 266ms/step - loss: 0.1979 - accuracy: 0.7662 - val_loss: 0.2863 - val_accuracy: 0.7189\n",
            "Epoch 110/1000\n",
            "4/4 [==============================] - 1s 278ms/step - loss: 0.1965 - accuracy: 0.7676 - val_loss: 0.2846 - val_accuracy: 0.7197\n",
            "Epoch 111/1000\n",
            "4/4 [==============================] - 1s 277ms/step - loss: 0.1955 - accuracy: 0.7707 - val_loss: 0.2836 - val_accuracy: 0.7214\n",
            "Epoch 112/1000\n",
            "4/4 [==============================] - 1s 260ms/step - loss: 0.1947 - accuracy: 0.7723 - val_loss: 0.2841 - val_accuracy: 0.7210\n",
            "Epoch 113/1000\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.1931 - accuracy: 0.7732 - val_loss: 0.2817 - val_accuracy: 0.7233\n",
            "Epoch 114/1000\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 0.1924 - accuracy: 0.7736 - val_loss: 0.2808 - val_accuracy: 0.7240\n",
            "Epoch 115/1000\n",
            "4/4 [==============================] - 1s 263ms/step - loss: 0.1914 - accuracy: 0.7760 - val_loss: 0.2799 - val_accuracy: 0.7250\n",
            "Epoch 116/1000\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.1902 - accuracy: 0.7784 - val_loss: 0.2795 - val_accuracy: 0.7247\n",
            "Epoch 117/1000\n",
            "4/4 [==============================] - 1s 294ms/step - loss: 0.1892 - accuracy: 0.7770 - val_loss: 0.2782 - val_accuracy: 0.7264\n",
            "Epoch 118/1000\n",
            "4/4 [==============================] - 1s 295ms/step - loss: 0.1883 - accuracy: 0.7803 - val_loss: 0.2771 - val_accuracy: 0.7269\n",
            "Epoch 119/1000\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.1874 - accuracy: 0.7807 - val_loss: 0.2765 - val_accuracy: 0.7281\n",
            "Epoch 120/1000\n",
            "4/4 [==============================] - 1s 280ms/step - loss: 0.1862 - accuracy: 0.7825 - val_loss: 0.2761 - val_accuracy: 0.7283\n",
            "Epoch 121/1000\n",
            "4/4 [==============================] - 1s 277ms/step - loss: 0.1854 - accuracy: 0.7811 - val_loss: 0.2750 - val_accuracy: 0.7296\n",
            "Epoch 122/1000\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.1845 - accuracy: 0.7844 - val_loss: 0.2735 - val_accuracy: 0.7304\n",
            "Epoch 123/1000\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 0.1836 - accuracy: 0.7834 - val_loss: 0.2727 - val_accuracy: 0.7323\n",
            "Epoch 124/1000\n",
            "4/4 [==============================] - 1s 271ms/step - loss: 0.1822 - accuracy: 0.7874 - val_loss: 0.2721 - val_accuracy: 0.7316\n",
            "Epoch 125/1000\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 0.1815 - accuracy: 0.7868 - val_loss: 0.2712 - val_accuracy: 0.7318\n",
            "Epoch 126/1000\n",
            "4/4 [==============================] - 1s 283ms/step - loss: 0.1805 - accuracy: 0.7893 - val_loss: 0.2703 - val_accuracy: 0.7332\n",
            "Epoch 127/1000\n",
            "4/4 [==============================] - 1s 289ms/step - loss: 0.1794 - accuracy: 0.7886 - val_loss: 0.2699 - val_accuracy: 0.7346\n",
            "Epoch 128/1000\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.1785 - accuracy: 0.7913 - val_loss: 0.2691 - val_accuracy: 0.7356\n",
            "Epoch 129/1000\n",
            "4/4 [==============================] - 1s 289ms/step - loss: 0.1774 - accuracy: 0.7915 - val_loss: 0.2675 - val_accuracy: 0.7359\n",
            "Epoch 130/1000\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.1772 - accuracy: 0.7925 - val_loss: 0.2680 - val_accuracy: 0.7346\n",
            "Epoch 131/1000\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.1765 - accuracy: 0.7933 - val_loss: 0.2676 - val_accuracy: 0.7363\n",
            "Epoch 132/1000\n",
            "4/4 [==============================] - 1s 262ms/step - loss: 0.1753 - accuracy: 0.7950 - val_loss: 0.2671 - val_accuracy: 0.7338\n",
            "Epoch 133/1000\n",
            "4/4 [==============================] - 1s 281ms/step - loss: 0.1745 - accuracy: 0.7944 - val_loss: 0.2663 - val_accuracy: 0.7377\n",
            "Epoch 134/1000\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 0.1743 - accuracy: 0.7964 - val_loss: 0.2665 - val_accuracy: 0.7339\n",
            "Epoch 135/1000\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.1732 - accuracy: 0.7965 - val_loss: 0.2639 - val_accuracy: 0.7394\n",
            "Epoch 136/1000\n",
            "4/4 [==============================] - 1s 270ms/step - loss: 0.1721 - accuracy: 0.7999 - val_loss: 0.2636 - val_accuracy: 0.7380\n",
            "Epoch 137/1000\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.1719 - accuracy: 0.7981 - val_loss: 0.2626 - val_accuracy: 0.7414\n",
            "Epoch 138/1000\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.1707 - accuracy: 0.8019 - val_loss: 0.2621 - val_accuracy: 0.7399\n",
            "Epoch 139/1000\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.1694 - accuracy: 0.8005 - val_loss: 0.2606 - val_accuracy: 0.7427\n",
            "Epoch 140/1000\n",
            "4/4 [==============================] - 1s 278ms/step - loss: 0.1687 - accuracy: 0.8034 - val_loss: 0.2598 - val_accuracy: 0.7425\n",
            "Epoch 141/1000\n",
            "4/4 [==============================] - 1s 292ms/step - loss: 0.1676 - accuracy: 0.8024 - val_loss: 0.2600 - val_accuracy: 0.7434\n",
            "Epoch 142/1000\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.1664 - accuracy: 0.8049 - val_loss: 0.2589 - val_accuracy: 0.7437\n",
            "Epoch 143/1000\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.1663 - accuracy: 0.8036 - val_loss: 0.2574 - val_accuracy: 0.7469\n",
            "Epoch 144/1000\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.1650 - accuracy: 0.8081 - val_loss: 0.2571 - val_accuracy: 0.7469\n",
            "Epoch 145/1000\n",
            "4/4 [==============================] - 1s 282ms/step - loss: 0.1645 - accuracy: 0.8074 - val_loss: 0.2566 - val_accuracy: 0.7477\n",
            "Epoch 146/1000\n",
            "4/4 [==============================] - 1s 282ms/step - loss: 0.1633 - accuracy: 0.8102 - val_loss: 0.2559 - val_accuracy: 0.7484\n",
            "Epoch 147/1000\n",
            "4/4 [==============================] - 1s 266ms/step - loss: 0.1626 - accuracy: 0.8104 - val_loss: 0.2554 - val_accuracy: 0.7484\n",
            "Epoch 148/1000\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.1618 - accuracy: 0.8142 - val_loss: 0.2553 - val_accuracy: 0.7475\n",
            "Epoch 149/1000\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.1613 - accuracy: 0.8115 - val_loss: 0.2534 - val_accuracy: 0.7493\n",
            "Epoch 150/1000\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.1605 - accuracy: 0.8124 - val_loss: 0.2537 - val_accuracy: 0.7478\n",
            "Epoch 151/1000\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.1599 - accuracy: 0.8145 - val_loss: 0.2529 - val_accuracy: 0.7496\n",
            "Epoch 152/1000\n",
            "4/4 [==============================] - 1s 281ms/step - loss: 0.1585 - accuracy: 0.8143 - val_loss: 0.2523 - val_accuracy: 0.7506\n",
            "Epoch 153/1000\n",
            "4/4 [==============================] - 1s 266ms/step - loss: 0.1576 - accuracy: 0.8173 - val_loss: 0.2521 - val_accuracy: 0.7511\n",
            "Epoch 154/1000\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.1571 - accuracy: 0.8171 - val_loss: 0.2514 - val_accuracy: 0.7516\n",
            "Epoch 155/1000\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.1563 - accuracy: 0.8174 - val_loss: 0.2507 - val_accuracy: 0.7516\n",
            "Epoch 156/1000\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 0.1558 - accuracy: 0.8180 - val_loss: 0.2503 - val_accuracy: 0.7513\n",
            "Epoch 157/1000\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 0.1552 - accuracy: 0.8172 - val_loss: 0.2494 - val_accuracy: 0.7535\n",
            "Epoch 158/1000\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.1540 - accuracy: 0.8221 - val_loss: 0.2485 - val_accuracy: 0.7543\n",
            "Epoch 159/1000\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 0.1534 - accuracy: 0.8215 - val_loss: 0.2474 - val_accuracy: 0.7557\n",
            "Epoch 160/1000\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 0.1531 - accuracy: 0.8221 - val_loss: 0.2468 - val_accuracy: 0.7558\n",
            "Epoch 161/1000\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.1521 - accuracy: 0.8234 - val_loss: 0.2466 - val_accuracy: 0.7561\n",
            "Epoch 162/1000\n",
            "4/4 [==============================] - 1s 260ms/step - loss: 0.1507 - accuracy: 0.8248 - val_loss: 0.2461 - val_accuracy: 0.7570\n",
            "Epoch 163/1000\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.1503 - accuracy: 0.8236 - val_loss: 0.2454 - val_accuracy: 0.7580\n",
            "Epoch 164/1000\n",
            "4/4 [==============================] - 1s 276ms/step - loss: 0.1497 - accuracy: 0.8252 - val_loss: 0.2453 - val_accuracy: 0.7575\n",
            "Epoch 165/1000\n",
            "4/4 [==============================] - 1s 311ms/step - loss: 0.1490 - accuracy: 0.8280 - val_loss: 0.2445 - val_accuracy: 0.7586\n",
            "Epoch 166/1000\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.1480 - accuracy: 0.8286 - val_loss: 0.2443 - val_accuracy: 0.7574\n",
            "Epoch 167/1000\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 0.1478 - accuracy: 0.8266 - val_loss: 0.2443 - val_accuracy: 0.7585\n",
            "Epoch 168/1000\n",
            "4/4 [==============================] - 1s 262ms/step - loss: 0.1469 - accuracy: 0.8312 - val_loss: 0.2439 - val_accuracy: 0.7557\n",
            "Epoch 169/1000\n",
            "4/4 [==============================] - 1s 263ms/step - loss: 0.1469 - accuracy: 0.8274 - val_loss: 0.2429 - val_accuracy: 0.7593\n",
            "Epoch 170/1000\n",
            "4/4 [==============================] - 1s 272ms/step - loss: 0.1456 - accuracy: 0.8305 - val_loss: 0.2427 - val_accuracy: 0.7586\n",
            "Epoch 171/1000\n",
            "4/4 [==============================] - 1s 268ms/step - loss: 0.1450 - accuracy: 0.8313 - val_loss: 0.2415 - val_accuracy: 0.7608\n",
            "Epoch 172/1000\n",
            "4/4 [==============================] - 1s 279ms/step - loss: 0.1442 - accuracy: 0.8338 - val_loss: 0.2408 - val_accuracy: 0.7614\n",
            "Epoch 173/1000\n",
            "4/4 [==============================] - 1s 301ms/step - loss: 0.1440 - accuracy: 0.8339 - val_loss: 0.2408 - val_accuracy: 0.7622\n",
            "Epoch 174/1000\n",
            "4/4 [==============================] - 1s 281ms/step - loss: 0.1423 - accuracy: 0.8364 - val_loss: 0.2399 - val_accuracy: 0.7633\n",
            "Epoch 175/1000\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.1424 - accuracy: 0.8359 - val_loss: 0.2390 - val_accuracy: 0.7633\n",
            "Epoch 176/1000\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.1413 - accuracy: 0.8348 - val_loss: 0.2394 - val_accuracy: 0.7633\n",
            "Epoch 177/1000\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.1406 - accuracy: 0.8366 - val_loss: 0.2392 - val_accuracy: 0.7642\n",
            "Epoch 178/1000\n",
            "4/4 [==============================] - 1s 286ms/step - loss: 0.1399 - accuracy: 0.8385 - val_loss: 0.2378 - val_accuracy: 0.7645\n",
            "Epoch 179/1000\n",
            "4/4 [==============================] - 1s 269ms/step - loss: 0.1387 - accuracy: 0.8402 - val_loss: 0.2376 - val_accuracy: 0.7646\n",
            "Epoch 180/1000\n",
            "4/4 [==============================] - 1s 281ms/step - loss: 0.1384 - accuracy: 0.8402 - val_loss: 0.2377 - val_accuracy: 0.7656\n",
            "Epoch 181/1000\n",
            "4/4 [==============================] - 1s 288ms/step - loss: 0.1382 - accuracy: 0.8404 - val_loss: 0.2367 - val_accuracy: 0.7648\n",
            "Epoch 182/1000\n",
            "4/4 [==============================] - 1s 264ms/step - loss: 0.1376 - accuracy: 0.8413 - val_loss: 0.2362 - val_accuracy: 0.7660\n",
            "Epoch 183/1000\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.1371 - accuracy: 0.8424 - val_loss: 0.2359 - val_accuracy: 0.7655\n",
            "Epoch 184/1000\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.1365 - accuracy: 0.8402 - val_loss: 0.2358 - val_accuracy: 0.7678\n",
            "Epoch 185/1000\n",
            "4/4 [==============================] - 1s 290ms/step - loss: 0.1359 - accuracy: 0.8434 - val_loss: 0.2341 - val_accuracy: 0.7677\n",
            "Epoch 186/1000\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.1347 - accuracy: 0.8438 - val_loss: 0.2344 - val_accuracy: 0.7676\n",
            "Epoch 187/1000\n",
            "4/4 [==============================] - 1s 263ms/step - loss: 0.1344 - accuracy: 0.8452 - val_loss: 0.2365 - val_accuracy: 0.7664\n",
            "Epoch 188/1000\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.1345 - accuracy: 0.8457 - val_loss: 0.2348 - val_accuracy: 0.7664\n",
            "Epoch 189/1000\n",
            "4/4 [==============================] - 1s 283ms/step - loss: 0.1335 - accuracy: 0.8456 - val_loss: 0.2334 - val_accuracy: 0.7692\n",
            "Epoch 190/1000\n",
            "4/4 [==============================] - 1s 275ms/step - loss: 0.1323 - accuracy: 0.8486 - val_loss: 0.2341 - val_accuracy: 0.7687\n",
            "Epoch 191/1000\n",
            "4/4 [==============================] - 1s 285ms/step - loss: 0.1326 - accuracy: 0.8491 - val_loss: 0.2338 - val_accuracy: 0.7669\n",
            "Epoch 192/1000\n",
            "4/4 [==============================] - 1s 275ms/step - loss: 0.1328 - accuracy: 0.8438 - val_loss: 0.2353 - val_accuracy: 0.7682\n",
            "Epoch 193/1000\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.1331 - accuracy: 0.8477 - val_loss: 0.2335 - val_accuracy: 0.7678\n",
            "Epoch 194/1000\n",
            "4/4 [==============================] - 1s 278ms/step - loss: 0.1309 - accuracy: 0.8476 - val_loss: 0.2328 - val_accuracy: 0.7715\n",
            "Epoch 195/1000\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.1302 - accuracy: 0.8488 - val_loss: 0.2308 - val_accuracy: 0.7709\n",
            "Epoch 196/1000\n",
            "4/4 [==============================] - 1s 282ms/step - loss: 0.1293 - accuracy: 0.8508 - val_loss: 0.2300 - val_accuracy: 0.7722\n",
            "Epoch 197/1000\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.1283 - accuracy: 0.8528 - val_loss: 0.2297 - val_accuracy: 0.7714\n",
            "Epoch 198/1000\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.1282 - accuracy: 0.8514 - val_loss: 0.2299 - val_accuracy: 0.7724\n",
            "Epoch 199/1000\n",
            "4/4 [==============================] - 1s 281ms/step - loss: 0.1270 - accuracy: 0.8545 - val_loss: 0.2288 - val_accuracy: 0.7723\n",
            "Epoch 200/1000\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.1268 - accuracy: 0.8540 - val_loss: 0.2288 - val_accuracy: 0.7737\n",
            "Epoch 201/1000\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.1259 - accuracy: 0.8553 - val_loss: 0.2282 - val_accuracy: 0.7741\n",
            "Epoch 202/1000\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.1257 - accuracy: 0.8564 - val_loss: 0.2283 - val_accuracy: 0.7747\n",
            "Epoch 203/1000\n",
            "4/4 [==============================] - 1s 268ms/step - loss: 0.1252 - accuracy: 0.8578 - val_loss: 0.2289 - val_accuracy: 0.7732\n",
            "Epoch 204/1000\n",
            "4/4 [==============================] - 1s 307ms/step - loss: 0.1246 - accuracy: 0.8570 - val_loss: 0.2278 - val_accuracy: 0.7749\n",
            "Epoch 205/1000\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.1236 - accuracy: 0.8594 - val_loss: 0.2277 - val_accuracy: 0.7744\n",
            "Epoch 206/1000\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 0.1225 - accuracy: 0.8600 - val_loss: 0.2275 - val_accuracy: 0.7757\n",
            "Epoch 207/1000\n",
            "4/4 [==============================] - 1s 297ms/step - loss: 0.1228 - accuracy: 0.8602 - val_loss: 0.2263 - val_accuracy: 0.7753\n",
            "Epoch 208/1000\n",
            "4/4 [==============================] - 1s 262ms/step - loss: 0.1223 - accuracy: 0.8589 - val_loss: 0.2272 - val_accuracy: 0.7764\n",
            "Epoch 209/1000\n",
            "4/4 [==============================] - 1s 290ms/step - loss: 0.1220 - accuracy: 0.8609 - val_loss: 0.2263 - val_accuracy: 0.7766\n",
            "Epoch 210/1000\n",
            "4/4 [==============================] - 1s 288ms/step - loss: 0.1210 - accuracy: 0.8590 - val_loss: 0.2265 - val_accuracy: 0.7771\n",
            "Epoch 211/1000\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.1206 - accuracy: 0.8624 - val_loss: 0.2260 - val_accuracy: 0.7763\n",
            "Epoch 212/1000\n",
            "4/4 [==============================] - 1s 310ms/step - loss: 0.1204 - accuracy: 0.8608 - val_loss: 0.2259 - val_accuracy: 0.7777\n",
            "Epoch 213/1000\n",
            "4/4 [==============================] - 1s 309ms/step - loss: 0.1190 - accuracy: 0.8647 - val_loss: 0.2253 - val_accuracy: 0.7778\n",
            "Epoch 214/1000\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.1191 - accuracy: 0.8632 - val_loss: 0.2243 - val_accuracy: 0.7781\n",
            "Epoch 215/1000\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.1184 - accuracy: 0.8650 - val_loss: 0.2240 - val_accuracy: 0.7777\n",
            "Epoch 216/1000\n",
            "4/4 [==============================] - 1s 275ms/step - loss: 0.1180 - accuracy: 0.8654 - val_loss: 0.2238 - val_accuracy: 0.7795\n",
            "Epoch 217/1000\n",
            "4/4 [==============================] - 1s 285ms/step - loss: 0.1173 - accuracy: 0.8666 - val_loss: 0.2241 - val_accuracy: 0.7796\n",
            "Epoch 218/1000\n",
            "4/4 [==============================] - 1s 332ms/step - loss: 0.1166 - accuracy: 0.8669 - val_loss: 0.2234 - val_accuracy: 0.7797\n",
            "Epoch 219/1000\n",
            "4/4 [==============================] - 1s 290ms/step - loss: 0.1164 - accuracy: 0.8660 - val_loss: 0.2238 - val_accuracy: 0.7799\n",
            "Epoch 220/1000\n",
            "4/4 [==============================] - 1s 282ms/step - loss: 0.1162 - accuracy: 0.8696 - val_loss: 0.2237 - val_accuracy: 0.7786\n",
            "Epoch 221/1000\n",
            "4/4 [==============================] - 1s 285ms/step - loss: 0.1160 - accuracy: 0.8672 - val_loss: 0.2231 - val_accuracy: 0.7805\n",
            "Epoch 222/1000\n",
            "4/4 [==============================] - 1s 291ms/step - loss: 0.1149 - accuracy: 0.8697 - val_loss: 0.2227 - val_accuracy: 0.7796\n",
            "Epoch 223/1000\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.1144 - accuracy: 0.8702 - val_loss: 0.2226 - val_accuracy: 0.7812\n",
            "Epoch 224/1000\n",
            "4/4 [==============================] - 1s 268ms/step - loss: 0.1134 - accuracy: 0.8707 - val_loss: 0.2224 - val_accuracy: 0.7812\n",
            "Epoch 225/1000\n",
            "4/4 [==============================] - 1s 285ms/step - loss: 0.1130 - accuracy: 0.8704 - val_loss: 0.2220 - val_accuracy: 0.7813\n",
            "Epoch 226/1000\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.1125 - accuracy: 0.8718 - val_loss: 0.2213 - val_accuracy: 0.7818\n",
            "Epoch 227/1000\n",
            "4/4 [==============================] - 1s 290ms/step - loss: 0.1119 - accuracy: 0.8719 - val_loss: 0.2219 - val_accuracy: 0.7818\n",
            "Epoch 228/1000\n",
            "4/4 [==============================] - 1s 276ms/step - loss: 0.1121 - accuracy: 0.8737 - val_loss: 0.2215 - val_accuracy: 0.7803\n",
            "Epoch 229/1000\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 0.1116 - accuracy: 0.8723 - val_loss: 0.2232 - val_accuracy: 0.7806\n",
            "Epoch 230/1000\n",
            "4/4 [==============================] - 1s 279ms/step - loss: 0.1116 - accuracy: 0.8728 - val_loss: 0.2218 - val_accuracy: 0.7804\n",
            "Epoch 231/1000\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.1109 - accuracy: 0.8723 - val_loss: 0.2222 - val_accuracy: 0.7832\n",
            "Epoch 232/1000\n",
            "4/4 [==============================] - 1s 264ms/step - loss: 0.1107 - accuracy: 0.8744 - val_loss: 0.2220 - val_accuracy: 0.7800\n",
            "Epoch 233/1000\n",
            "4/4 [==============================] - 1s 279ms/step - loss: 0.1107 - accuracy: 0.8731 - val_loss: 0.2226 - val_accuracy: 0.7820\n",
            "Epoch 234/1000\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.1101 - accuracy: 0.8751 - val_loss: 0.2222 - val_accuracy: 0.7787\n",
            "Epoch 235/1000\n",
            "4/4 [==============================] - 1s 275ms/step - loss: 0.1099 - accuracy: 0.8739 - val_loss: 0.2189 - val_accuracy: 0.7846\n",
            "Epoch 236/1000\n",
            "4/4 [==============================] - 1s 285ms/step - loss: 0.1082 - accuracy: 0.8769 - val_loss: 0.2182 - val_accuracy: 0.7835\n",
            "Epoch 237/1000\n",
            "4/4 [==============================] - 1s 275ms/step - loss: 0.1079 - accuracy: 0.8781 - val_loss: 0.2182 - val_accuracy: 0.7847\n",
            "Epoch 238/1000\n",
            "4/4 [==============================] - 1s 264ms/step - loss: 0.1074 - accuracy: 0.8769 - val_loss: 0.2178 - val_accuracy: 0.7846\n",
            "Epoch 239/1000\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.1065 - accuracy: 0.8805 - val_loss: 0.2191 - val_accuracy: 0.7848\n",
            "Epoch 240/1000\n",
            "4/4 [==============================] - 1s 297ms/step - loss: 0.1064 - accuracy: 0.8796 - val_loss: 0.2183 - val_accuracy: 0.7834\n",
            "Epoch 241/1000\n",
            "4/4 [==============================] - 1s 263ms/step - loss: 0.1059 - accuracy: 0.8799 - val_loss: 0.2185 - val_accuracy: 0.7849\n",
            "Epoch 242/1000\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.1052 - accuracy: 0.8823 - val_loss: 0.2173 - val_accuracy: 0.7848\n",
            "Epoch 243/1000\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.1055 - accuracy: 0.8803 - val_loss: 0.2178 - val_accuracy: 0.7855\n",
            "Epoch 244/1000\n",
            "4/4 [==============================] - 1s 272ms/step - loss: 0.1050 - accuracy: 0.8821 - val_loss: 0.2169 - val_accuracy: 0.7852\n",
            "Epoch 245/1000\n",
            "4/4 [==============================] - 1s 304ms/step - loss: 0.1038 - accuracy: 0.8841 - val_loss: 0.2168 - val_accuracy: 0.7854\n",
            "Epoch 246/1000\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 0.1034 - accuracy: 0.8832 - val_loss: 0.2163 - val_accuracy: 0.7865\n",
            "Epoch 247/1000\n",
            "4/4 [==============================] - 1s 282ms/step - loss: 0.1031 - accuracy: 0.8821 - val_loss: 0.2164 - val_accuracy: 0.7867\n",
            "Epoch 248/1000\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.1025 - accuracy: 0.8844 - val_loss: 0.2167 - val_accuracy: 0.7850\n",
            "Epoch 249/1000\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.1025 - accuracy: 0.8833 - val_loss: 0.2166 - val_accuracy: 0.7866\n",
            "Epoch 250/1000\n",
            "4/4 [==============================] - 1s 277ms/step - loss: 0.1018 - accuracy: 0.8852 - val_loss: 0.2156 - val_accuracy: 0.7867\n",
            "Epoch 251/1000\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 0.1018 - accuracy: 0.8850 - val_loss: 0.2158 - val_accuracy: 0.7871\n",
            "Epoch 252/1000\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 0.1010 - accuracy: 0.8857 - val_loss: 0.2151 - val_accuracy: 0.7873\n",
            "Epoch 253/1000\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 0.1009 - accuracy: 0.8853 - val_loss: 0.2151 - val_accuracy: 0.7866\n",
            "Epoch 254/1000\n",
            "4/4 [==============================] - 1s 277ms/step - loss: 0.1004 - accuracy: 0.8879 - val_loss: 0.2162 - val_accuracy: 0.7863\n",
            "Epoch 255/1000\n",
            "4/4 [==============================] - 1s 291ms/step - loss: 0.1005 - accuracy: 0.8880 - val_loss: 0.2152 - val_accuracy: 0.7874\n",
            "Epoch 256/1000\n",
            "4/4 [==============================] - 1s 264ms/step - loss: 0.0998 - accuracy: 0.8866 - val_loss: 0.2150 - val_accuracy: 0.7874\n",
            "Epoch 257/1000\n",
            "4/4 [==============================] - 1s 278ms/step - loss: 0.0991 - accuracy: 0.8879 - val_loss: 0.2148 - val_accuracy: 0.7875\n",
            "Epoch 258/1000\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.0983 - accuracy: 0.8896 - val_loss: 0.2144 - val_accuracy: 0.7889\n",
            "Epoch 259/1000\n",
            "4/4 [==============================] - 1s 266ms/step - loss: 0.0986 - accuracy: 0.8886 - val_loss: 0.2139 - val_accuracy: 0.7888\n",
            "Epoch 260/1000\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 0.0974 - accuracy: 0.8899 - val_loss: 0.2141 - val_accuracy: 0.7883\n",
            "Epoch 261/1000\n",
            "4/4 [==============================] - 1s 291ms/step - loss: 0.0969 - accuracy: 0.8903 - val_loss: 0.2150 - val_accuracy: 0.7887\n",
            "Epoch 262/1000\n",
            "4/4 [==============================] - 1s 275ms/step - loss: 0.0973 - accuracy: 0.8899 - val_loss: 0.2147 - val_accuracy: 0.7876\n",
            "Epoch 263/1000\n",
            "4/4 [==============================] - 1s 266ms/step - loss: 0.0969 - accuracy: 0.8905 - val_loss: 0.2142 - val_accuracy: 0.7889\n",
            "Epoch 264/1000\n",
            "4/4 [==============================] - 1s 301ms/step - loss: 0.0960 - accuracy: 0.8915 - val_loss: 0.2142 - val_accuracy: 0.7888\n",
            "Epoch 265/1000\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.0960 - accuracy: 0.8927 - val_loss: 0.2140 - val_accuracy: 0.7881\n",
            "Epoch 266/1000\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.0959 - accuracy: 0.8919 - val_loss: 0.2143 - val_accuracy: 0.7895\n",
            "Epoch 267/1000\n",
            "4/4 [==============================] - 1s 293ms/step - loss: 0.0948 - accuracy: 0.8946 - val_loss: 0.2134 - val_accuracy: 0.7891\n",
            "Epoch 268/1000\n",
            "4/4 [==============================] - 1s 304ms/step - loss: 0.0946 - accuracy: 0.8940 - val_loss: 0.2133 - val_accuracy: 0.7897\n",
            "Epoch 269/1000\n",
            "4/4 [==============================] - 1s 298ms/step - loss: 0.0945 - accuracy: 0.8936 - val_loss: 0.2135 - val_accuracy: 0.7897\n",
            "Epoch 270/1000\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 0.0945 - accuracy: 0.8940 - val_loss: 0.2123 - val_accuracy: 0.7897\n",
            "Epoch 271/1000\n",
            "4/4 [==============================] - 1s 296ms/step - loss: 0.0936 - accuracy: 0.8943 - val_loss: 0.2127 - val_accuracy: 0.7916\n",
            "Epoch 272/1000\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 0.0929 - accuracy: 0.8949 - val_loss: 0.2125 - val_accuracy: 0.7904\n",
            "Epoch 273/1000\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.0928 - accuracy: 0.8941 - val_loss: 0.2120 - val_accuracy: 0.7912\n",
            "Epoch 274/1000\n",
            "4/4 [==============================] - 1s 304ms/step - loss: 0.0925 - accuracy: 0.8978 - val_loss: 0.2116 - val_accuracy: 0.7921\n",
            "Epoch 275/1000\n",
            "4/4 [==============================] - 1s 275ms/step - loss: 0.0917 - accuracy: 0.8976 - val_loss: 0.2117 - val_accuracy: 0.7926\n",
            "Epoch 276/1000\n",
            "4/4 [==============================] - 1s 272ms/step - loss: 0.0916 - accuracy: 0.8961 - val_loss: 0.2120 - val_accuracy: 0.7926\n",
            "Epoch 277/1000\n",
            "4/4 [==============================] - 1s 277ms/step - loss: 0.0909 - accuracy: 0.8997 - val_loss: 0.2115 - val_accuracy: 0.7926\n",
            "Epoch 278/1000\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.0906 - accuracy: 0.8989 - val_loss: 0.2112 - val_accuracy: 0.7938\n",
            "Epoch 279/1000\n",
            "4/4 [==============================] - 1s 266ms/step - loss: 0.0902 - accuracy: 0.8984 - val_loss: 0.2115 - val_accuracy: 0.7927\n",
            "Epoch 280/1000\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 0.0901 - accuracy: 0.8991 - val_loss: 0.2116 - val_accuracy: 0.7920\n",
            "Epoch 281/1000\n",
            "4/4 [==============================] - 1s 278ms/step - loss: 0.0895 - accuracy: 0.9004 - val_loss: 0.2110 - val_accuracy: 0.7923\n",
            "Epoch 282/1000\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.0893 - accuracy: 0.9006 - val_loss: 0.2108 - val_accuracy: 0.7938\n",
            "Epoch 283/1000\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.0885 - accuracy: 0.9011 - val_loss: 0.2110 - val_accuracy: 0.7931\n",
            "Epoch 284/1000\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.0885 - accuracy: 0.9001 - val_loss: 0.2111 - val_accuracy: 0.7927\n",
            "Epoch 285/1000\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 0.0884 - accuracy: 0.9017 - val_loss: 0.2102 - val_accuracy: 0.7935\n",
            "Epoch 286/1000\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.0882 - accuracy: 0.9019 - val_loss: 0.2106 - val_accuracy: 0.7939\n",
            "Epoch 287/1000\n",
            "4/4 [==============================] - 1s 271ms/step - loss: 0.0872 - accuracy: 0.9032 - val_loss: 0.2105 - val_accuracy: 0.7937\n",
            "Epoch 288/1000\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.0869 - accuracy: 0.9028 - val_loss: 0.2108 - val_accuracy: 0.7939\n",
            "Epoch 289/1000\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.0866 - accuracy: 0.9027 - val_loss: 0.2103 - val_accuracy: 0.7944\n",
            "Epoch 290/1000\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.0866 - accuracy: 0.9046 - val_loss: 0.2102 - val_accuracy: 0.7945\n",
            "Epoch 291/1000\n",
            "4/4 [==============================] - 1s 276ms/step - loss: 0.0861 - accuracy: 0.9037 - val_loss: 0.2101 - val_accuracy: 0.7945\n",
            "Epoch 292/1000\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 0.0856 - accuracy: 0.9050 - val_loss: 0.2103 - val_accuracy: 0.7949\n",
            "Epoch 293/1000\n",
            "4/4 [==============================] - 1s 262ms/step - loss: 0.0852 - accuracy: 0.9049 - val_loss: 0.2098 - val_accuracy: 0.7939\n",
            "Epoch 294/1000\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.0850 - accuracy: 0.9043 - val_loss: 0.2096 - val_accuracy: 0.7951\n",
            "Epoch 295/1000\n",
            "4/4 [==============================] - 1s 300ms/step - loss: 0.0850 - accuracy: 0.9042 - val_loss: 0.2096 - val_accuracy: 0.7952\n",
            "Epoch 296/1000\n",
            "4/4 [==============================] - 1s 277ms/step - loss: 0.0848 - accuracy: 0.9051 - val_loss: 0.2094 - val_accuracy: 0.7956\n",
            "Epoch 297/1000\n",
            "4/4 [==============================] - 1s 260ms/step - loss: 0.0841 - accuracy: 0.9060 - val_loss: 0.2093 - val_accuracy: 0.7956\n",
            "Epoch 298/1000\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.0834 - accuracy: 0.9087 - val_loss: 0.2097 - val_accuracy: 0.7951\n",
            "Epoch 299/1000\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 0.0837 - accuracy: 0.9070 - val_loss: 0.2091 - val_accuracy: 0.7956\n",
            "Epoch 300/1000\n",
            "4/4 [==============================] - 1s 269ms/step - loss: 0.0830 - accuracy: 0.9073 - val_loss: 0.2090 - val_accuracy: 0.7958\n",
            "Epoch 301/1000\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.0833 - accuracy: 0.9084 - val_loss: 0.2097 - val_accuracy: 0.7950\n",
            "Epoch 302/1000\n",
            "4/4 [==============================] - 1s 278ms/step - loss: 0.0827 - accuracy: 0.9090 - val_loss: 0.2089 - val_accuracy: 0.7959\n",
            "Epoch 303/1000\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.0826 - accuracy: 0.9088 - val_loss: 0.2094 - val_accuracy: 0.7953\n",
            "Epoch 304/1000\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 0.0822 - accuracy: 0.9096 - val_loss: 0.2087 - val_accuracy: 0.7960\n",
            "Epoch 305/1000\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 0.0815 - accuracy: 0.9094 - val_loss: 0.2098 - val_accuracy: 0.7959\n",
            "Epoch 306/1000\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.0816 - accuracy: 0.9091 - val_loss: 0.2095 - val_accuracy: 0.7964\n",
            "Epoch 307/1000\n",
            "4/4 [==============================] - 1s 274ms/step - loss: 0.0814 - accuracy: 0.9090 - val_loss: 0.2094 - val_accuracy: 0.7966\n",
            "Epoch 308/1000\n",
            "4/4 [==============================] - 1s 298ms/step - loss: 0.0806 - accuracy: 0.9108 - val_loss: 0.2084 - val_accuracy: 0.7976\n",
            "Epoch 309/1000\n",
            "4/4 [==============================] - 1s 263ms/step - loss: 0.0806 - accuracy: 0.9110 - val_loss: 0.2087 - val_accuracy: 0.7968\n",
            "Epoch 310/1000\n",
            "4/4 [==============================] - 1s 291ms/step - loss: 0.0799 - accuracy: 0.9110 - val_loss: 0.2089 - val_accuracy: 0.7972\n",
            "Epoch 311/1000\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.0799 - accuracy: 0.9117 - val_loss: 0.2089 - val_accuracy: 0.7967\n",
            "Epoch 312/1000\n",
            "4/4 [==============================] - 1s 309ms/step - loss: 0.0797 - accuracy: 0.9125 - val_loss: 0.2102 - val_accuracy: 0.7971\n",
            "Epoch 313/1000\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.0794 - accuracy: 0.9134 - val_loss: 0.2096 - val_accuracy: 0.7956\n",
            "Epoch 314/1000\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.0790 - accuracy: 0.9117 - val_loss: 0.2099 - val_accuracy: 0.7975\n",
            "Epoch 315/1000\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 0.0789 - accuracy: 0.9134 - val_loss: 0.2095 - val_accuracy: 0.7955\n",
            "Epoch 316/1000\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.0787 - accuracy: 0.9120 - val_loss: 0.2111 - val_accuracy: 0.7962\n",
            "Epoch 317/1000\n",
            "4/4 [==============================] - 1s 292ms/step - loss: 0.0787 - accuracy: 0.9131 - val_loss: 0.2082 - val_accuracy: 0.7971\n",
            "Epoch 318/1000\n",
            "4/4 [==============================] - 1s 312ms/step - loss: 0.0777 - accuracy: 0.9155 - val_loss: 0.2087 - val_accuracy: 0.7979\n",
            "Epoch 319/1000\n",
            "4/4 [==============================] - 1s 295ms/step - loss: 0.0780 - accuracy: 0.9139 - val_loss: 0.2082 - val_accuracy: 0.7976\n",
            "Epoch 320/1000\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.0768 - accuracy: 0.9166 - val_loss: 0.2082 - val_accuracy: 0.7985\n",
            "Epoch 321/1000\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.0769 - accuracy: 0.9150 - val_loss: 0.2088 - val_accuracy: 0.7990\n",
            "Epoch 322/1000\n",
            "4/4 [==============================] - 1s 297ms/step - loss: 0.0765 - accuracy: 0.9147 - val_loss: 0.2087 - val_accuracy: 0.7987\n",
            "Epoch 323/1000\n",
            "4/4 [==============================] - 1s 287ms/step - loss: 0.0763 - accuracy: 0.9159 - val_loss: 0.2091 - val_accuracy: 0.7966\n",
            "Epoch 324/1000\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.0761 - accuracy: 0.9165 - val_loss: 0.2084 - val_accuracy: 0.7989\n",
            "Epoch 325/1000\n",
            "4/4 [==============================] - 1s 262ms/step - loss: 0.0759 - accuracy: 0.9165 - val_loss: 0.2078 - val_accuracy: 0.7978\n",
            "Epoch 326/1000\n",
            "4/4 [==============================] - 1s 299ms/step - loss: 0.0755 - accuracy: 0.9182 - val_loss: 0.2080 - val_accuracy: 0.7977\n",
            "Epoch 327/1000\n",
            "4/4 [==============================] - 1s 283ms/step - loss: 0.0749 - accuracy: 0.9163 - val_loss: 0.2087 - val_accuracy: 0.7985\n",
            "Epoch 328/1000\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 0.0748 - accuracy: 0.9176 - val_loss: 0.2083 - val_accuracy: 0.7991\n",
            "Epoch 329/1000\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.0748 - accuracy: 0.9169 - val_loss: 0.2090 - val_accuracy: 0.7995\n",
            "Epoch 330/1000\n",
            "4/4 [==============================] - 1s 291ms/step - loss: 0.0742 - accuracy: 0.9186 - val_loss: 0.2075 - val_accuracy: 0.7985\n",
            "Epoch 331/1000\n",
            "4/4 [==============================] - 1s 285ms/step - loss: 0.0740 - accuracy: 0.9188 - val_loss: 0.2076 - val_accuracy: 0.7994\n",
            "Epoch 332/1000\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 0.0730 - accuracy: 0.9206 - val_loss: 0.2081 - val_accuracy: 0.7990\n",
            "Epoch 333/1000\n",
            "4/4 [==============================] - 1s 279ms/step - loss: 0.0741 - accuracy: 0.9174 - val_loss: 0.2076 - val_accuracy: 0.7989\n",
            "Epoch 334/1000\n",
            "4/4 [==============================] - 1s 264ms/step - loss: 0.0732 - accuracy: 0.9197 - val_loss: 0.2079 - val_accuracy: 0.7987\n",
            "Epoch 335/1000\n",
            "4/4 [==============================] - 1s 271ms/step - loss: 0.0733 - accuracy: 0.9194 - val_loss: 0.2077 - val_accuracy: 0.7984\n",
            "Epoch 336/1000\n",
            "4/4 [==============================] - 1s 263ms/step - loss: 0.0727 - accuracy: 0.9199 - val_loss: 0.2087 - val_accuracy: 0.7985\n",
            "Epoch 337/1000\n",
            "4/4 [==============================] - 1s 270ms/step - loss: 0.0724 - accuracy: 0.9210 - val_loss: 0.2073 - val_accuracy: 0.7994\n",
            "Epoch 338/1000\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 0.0723 - accuracy: 0.9209 - val_loss: 0.2086 - val_accuracy: 0.7988\n",
            "Epoch 339/1000\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 0.0722 - accuracy: 0.9203 - val_loss: 0.2077 - val_accuracy: 0.7985\n",
            "Epoch 340/1000\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.0715 - accuracy: 0.9215 - val_loss: 0.2088 - val_accuracy: 0.7990\n",
            "Epoch 341/1000\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.0710 - accuracy: 0.9226 - val_loss: 0.2087 - val_accuracy: 0.7977\n",
            "Epoch 342/1000\n",
            "4/4 [==============================] - 1s 293ms/step - loss: 0.0711 - accuracy: 0.9227 - val_loss: 0.2075 - val_accuracy: 0.7993\n",
            "Epoch 343/1000\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.0707 - accuracy: 0.9216 - val_loss: 0.2069 - val_accuracy: 0.7995\n",
            "Epoch 344/1000\n",
            "4/4 [==============================] - 1s 300ms/step - loss: 0.0705 - accuracy: 0.9214 - val_loss: 0.2076 - val_accuracy: 0.8005\n",
            "Epoch 345/1000\n",
            "4/4 [==============================] - 1s 281ms/step - loss: 0.0698 - accuracy: 0.9244 - val_loss: 0.2076 - val_accuracy: 0.8005\n",
            "Epoch 346/1000\n",
            "4/4 [==============================] - 1s 306ms/step - loss: 0.0702 - accuracy: 0.9238 - val_loss: 0.2071 - val_accuracy: 0.8005\n",
            "Epoch 347/1000\n",
            "4/4 [==============================] - 1s 268ms/step - loss: 0.0693 - accuracy: 0.9250 - val_loss: 0.2070 - val_accuracy: 0.8007\n",
            "Epoch 348/1000\n",
            "4/4 [==============================] - 1s 272ms/step - loss: 0.0691 - accuracy: 0.9241 - val_loss: 0.2071 - val_accuracy: 0.8008\n",
            "Epoch 349/1000\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.0693 - accuracy: 0.9243 - val_loss: 0.2070 - val_accuracy: 0.8011\n",
            "Epoch 350/1000\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.0690 - accuracy: 0.9249 - val_loss: 0.2071 - val_accuracy: 0.8008\n",
            "Epoch 351/1000\n",
            "4/4 [==============================] - 1s 294ms/step - loss: 0.0685 - accuracy: 0.9258 - val_loss: 0.2073 - val_accuracy: 0.8006\n",
            "Epoch 352/1000\n",
            "4/4 [==============================] - 1s 272ms/step - loss: 0.0682 - accuracy: 0.9252 - val_loss: 0.2069 - val_accuracy: 0.8010\n",
            "Epoch 353/1000\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 0.0678 - accuracy: 0.9270 - val_loss: 0.2071 - val_accuracy: 0.8010\n",
            "Epoch 354/1000\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.0676 - accuracy: 0.9269 - val_loss: 0.2071 - val_accuracy: 0.8002\n",
            "Epoch 355/1000\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.0670 - accuracy: 0.9279 - val_loss: 0.2074 - val_accuracy: 0.8012\n",
            "Epoch 356/1000\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 0.0667 - accuracy: 0.9276 - val_loss: 0.2073 - val_accuracy: 0.8011\n",
            "Epoch 357/1000\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.0670 - accuracy: 0.9274 - val_loss: 0.2072 - val_accuracy: 0.8010\n",
            "Epoch 358/1000\n",
            "4/4 [==============================] - 1s 264ms/step - loss: 0.0668 - accuracy: 0.9266 - val_loss: 0.2074 - val_accuracy: 0.8009\n",
            "Training completed! Showing history...\n",
            "Displaying the following history keys:  dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6KaMwmfOKXS"
      },
      "source": [
        "##GRU Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Compile"
      ],
      "metadata": {
        "id": "Ve47TeQ9Osfr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao61F3grOOPf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66f2eda-22a7-43ce-84c6-c4f01ced14c8"
      },
      "source": [
        "GRU_model = Sequential()\n",
        "\n",
        "# Embedding layer\n",
        "GRU_model.add(Embedding(input_dim = vocab_size,\n",
        "              input_length = max_seq_length,\n",
        "              output_dim = embedding_dimension,\n",
        "              weights = embedding_matrix if embedding_matrix is None else [embedding_matrix],\n",
        "              trainable=False,\n",
        "              mask_zero=True))\n",
        "\n",
        "# GRU layer\n",
        "GRU_model.add(GRU(64, return_sequences=True \n",
        "               ,dropout=0.1\n",
        "               ))               \n",
        "\n",
        "# Dense layer\n",
        "GRU_model.add(TimeDistributed(Dense(num_classes,\n",
        "            activation= 'softmax')))\n",
        "\n",
        "# Compile the model\n",
        "GRU_model.compile(\n",
        "    optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "GRU_model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 1897, 200)         2189800   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 1897, 64)          51072     \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 1897, 46)         2990      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,243,862\n",
            "Trainable params: 54,062\n",
            "Non-trainable params: 2,189,800\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk2v-XJQPGvE"
      },
      "source": [
        "###Train "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx1G3pFyPIjZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "21f8a017-a1b7-4ffe-a88b-03fa00d12920"
      },
      "source": [
        "# Training\n",
        "\n",
        "training_info = {\n",
        "    'verbose': 1,\n",
        "    'epochs': 1000,\n",
        "    'batch_size': 32,\n",
        "    'callbacks': [keras.callbacks.EarlyStopping(monitor='val_loss', \n",
        "                                                patience=15,\n",
        "                                                restore_best_weights=True)]\n",
        "}\n",
        "GRU_model = train_model(model=GRU_model, x_train=x_train, y_train=y_train,\n",
        "                    x_val=x_val, y_val=y_val, training_info=training_info)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training! \n",
            "Parameters: {'verbose': 1, 'epochs': 1000, 'batch_size': 32, 'callbacks': [<keras.callbacks.EarlyStopping object at 0x000001DCE81B4FD0>]}\n",
            "Train size: 100\n",
            "Val size: 50\n",
            "Epoch 1/1000\n",
            "4/4 [==============================] - 4s 447ms/step - loss: 0.9234 - accuracy: 0.0301 - val_loss: 1.0853 - val_accuracy: 0.0889\n",
            "Epoch 2/1000\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.8684 - accuracy: 0.0986 - val_loss: 1.0264 - val_accuracy: 0.1268\n",
            "Epoch 3/1000\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.8223 - accuracy: 0.1300 - val_loss: 0.9749 - val_accuracy: 0.1340\n",
            "Epoch 4/1000\n",
            "4/4 [==============================] - 0s 134ms/step - loss: 0.7806 - accuracy: 0.1322 - val_loss: 0.9319 - val_accuracy: 0.1386\n",
            "Epoch 5/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 0.7465 - accuracy: 0.1543 - val_loss: 0.8960 - val_accuracy: 0.2148\n",
            "Epoch 6/1000\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.7183 - accuracy: 0.2290 - val_loss: 0.8685 - val_accuracy: 0.2542\n",
            "Epoch 7/1000\n",
            "4/4 [==============================] - 0s 136ms/step - loss: 0.6967 - accuracy: 0.2663 - val_loss: 0.8458 - val_accuracy: 0.2801\n",
            "Epoch 8/1000\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.6769 - accuracy: 0.2980 - val_loss: 0.8207 - val_accuracy: 0.3211\n",
            "Epoch 9/1000\n",
            "4/4 [==============================] - 0s 126ms/step - loss: 0.6568 - accuracy: 0.3286 - val_loss: 0.7945 - val_accuracy: 0.3287\n",
            "Epoch 10/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 0.6356 - accuracy: 0.3375 - val_loss: 0.7706 - val_accuracy: 0.3545\n",
            "Epoch 11/1000\n",
            "4/4 [==============================] - 0s 125ms/step - loss: 0.6177 - accuracy: 0.3697 - val_loss: 0.7474 - val_accuracy: 0.3946\n",
            "Epoch 12/1000\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.5991 - accuracy: 0.3981 - val_loss: 0.7266 - val_accuracy: 0.3949\n",
            "Epoch 13/1000\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.5814 - accuracy: 0.4058 - val_loss: 0.7067 - val_accuracy: 0.3999\n",
            "Epoch 14/1000\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.5644 - accuracy: 0.4108 - val_loss: 0.6879 - val_accuracy: 0.4086\n",
            "Epoch 15/1000\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.5494 - accuracy: 0.4196 - val_loss: 0.6699 - val_accuracy: 0.4198\n",
            "Epoch 16/1000\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.5336 - accuracy: 0.4293 - val_loss: 0.6521 - val_accuracy: 0.4272\n",
            "Epoch 17/1000\n",
            "4/4 [==============================] - 0s 127ms/step - loss: 0.5190 - accuracy: 0.4416 - val_loss: 0.6357 - val_accuracy: 0.4405\n",
            "Epoch 18/1000\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.5054 - accuracy: 0.4555 - val_loss: 0.6208 - val_accuracy: 0.4531\n",
            "Epoch 19/1000\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.4929 - accuracy: 0.4677 - val_loss: 0.6067 - val_accuracy: 0.4583\n",
            "Epoch 20/1000\n",
            "4/4 [==============================] - 0s 113ms/step - loss: 0.4808 - accuracy: 0.4763 - val_loss: 0.5937 - val_accuracy: 0.4658\n",
            "Epoch 21/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 0.4702 - accuracy: 0.4836 - val_loss: 0.5816 - val_accuracy: 0.4732\n",
            "Epoch 22/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 0.4604 - accuracy: 0.4922 - val_loss: 0.5698 - val_accuracy: 0.4835\n",
            "Epoch 23/1000\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.4501 - accuracy: 0.5019 - val_loss: 0.5591 - val_accuracy: 0.4912\n",
            "Epoch 24/1000\n",
            "4/4 [==============================] - 1s 130ms/step - loss: 0.4411 - accuracy: 0.5080 - val_loss: 0.5492 - val_accuracy: 0.4996\n",
            "Epoch 25/1000\n",
            "4/4 [==============================] - 0s 131ms/step - loss: 0.4321 - accuracy: 0.5191 - val_loss: 0.5381 - val_accuracy: 0.5146\n",
            "Epoch 26/1000\n",
            "4/4 [==============================] - 0s 130ms/step - loss: 0.4239 - accuracy: 0.5310 - val_loss: 0.5285 - val_accuracy: 0.5258\n",
            "Epoch 27/1000\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.4156 - accuracy: 0.5421 - val_loss: 0.5202 - val_accuracy: 0.5342\n",
            "Epoch 28/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 0.4087 - accuracy: 0.5506 - val_loss: 0.5117 - val_accuracy: 0.5428\n",
            "Epoch 29/1000\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 0.4017 - accuracy: 0.5582 - val_loss: 0.5036 - val_accuracy: 0.5486\n",
            "Epoch 30/1000\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.3951 - accuracy: 0.5643 - val_loss: 0.4963 - val_accuracy: 0.5546\n",
            "Epoch 31/1000\n",
            "4/4 [==============================] - 0s 113ms/step - loss: 0.3889 - accuracy: 0.5717 - val_loss: 0.4898 - val_accuracy: 0.5594\n",
            "Epoch 32/1000\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.3831 - accuracy: 0.5770 - val_loss: 0.4835 - val_accuracy: 0.5664\n",
            "Epoch 33/1000\n",
            "4/4 [==============================] - 1s 126ms/step - loss: 0.3781 - accuracy: 0.5807 - val_loss: 0.4775 - val_accuracy: 0.5710\n",
            "Epoch 34/1000\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.3730 - accuracy: 0.5871 - val_loss: 0.4719 - val_accuracy: 0.5746\n",
            "Epoch 35/1000\n",
            "4/4 [==============================] - 1s 131ms/step - loss: 0.3685 - accuracy: 0.5906 - val_loss: 0.4665 - val_accuracy: 0.5761\n",
            "Epoch 36/1000\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.3636 - accuracy: 0.5945 - val_loss: 0.4610 - val_accuracy: 0.5788\n",
            "Epoch 37/1000\n",
            "4/4 [==============================] - 0s 128ms/step - loss: 0.3596 - accuracy: 0.5957 - val_loss: 0.4564 - val_accuracy: 0.5808\n",
            "Epoch 38/1000\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.3551 - accuracy: 0.5992 - val_loss: 0.4514 - val_accuracy: 0.5838\n",
            "Epoch 39/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 0.3514 - accuracy: 0.6037 - val_loss: 0.4463 - val_accuracy: 0.5864\n",
            "Epoch 40/1000\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.3470 - accuracy: 0.6079 - val_loss: 0.4422 - val_accuracy: 0.5893\n",
            "Epoch 41/1000\n",
            "4/4 [==============================] - 0s 124ms/step - loss: 0.3431 - accuracy: 0.6104 - val_loss: 0.4383 - val_accuracy: 0.5914\n",
            "Epoch 42/1000\n",
            "4/4 [==============================] - 0s 130ms/step - loss: 0.3395 - accuracy: 0.6127 - val_loss: 0.4337 - val_accuracy: 0.5942\n",
            "Epoch 43/1000\n",
            "4/4 [==============================] - 0s 129ms/step - loss: 0.3354 - accuracy: 0.6163 - val_loss: 0.4296 - val_accuracy: 0.5972\n",
            "Epoch 44/1000\n",
            "4/4 [==============================] - 0s 133ms/step - loss: 0.3324 - accuracy: 0.6187 - val_loss: 0.4257 - val_accuracy: 0.5999\n",
            "Epoch 45/1000\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.3288 - accuracy: 0.6240 - val_loss: 0.4220 - val_accuracy: 0.6038\n",
            "Epoch 46/1000\n",
            "4/4 [==============================] - 0s 129ms/step - loss: 0.3255 - accuracy: 0.6263 - val_loss: 0.4190 - val_accuracy: 0.6055\n",
            "Epoch 47/1000\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 0.3226 - accuracy: 0.6289 - val_loss: 0.4153 - val_accuracy: 0.6070\n",
            "Epoch 48/1000\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.3199 - accuracy: 0.6293 - val_loss: 0.4115 - val_accuracy: 0.6091\n",
            "Epoch 49/1000\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.3167 - accuracy: 0.6335 - val_loss: 0.4078 - val_accuracy: 0.6116\n",
            "Epoch 50/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 0.3139 - accuracy: 0.6373 - val_loss: 0.4047 - val_accuracy: 0.6156\n",
            "Epoch 51/1000\n",
            "4/4 [==============================] - 0s 135ms/step - loss: 0.3113 - accuracy: 0.6389 - val_loss: 0.4022 - val_accuracy: 0.6177\n",
            "Epoch 52/1000\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.3091 - accuracy: 0.6428 - val_loss: 0.3989 - val_accuracy: 0.6207\n",
            "Epoch 53/1000\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.3062 - accuracy: 0.6458 - val_loss: 0.3959 - val_accuracy: 0.6230\n",
            "Epoch 54/1000\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.3038 - accuracy: 0.6469 - val_loss: 0.3935 - val_accuracy: 0.6227\n",
            "Epoch 55/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 0.3014 - accuracy: 0.6495 - val_loss: 0.3909 - val_accuracy: 0.6252\n",
            "Epoch 56/1000\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.2991 - accuracy: 0.6496 - val_loss: 0.3872 - val_accuracy: 0.6306\n",
            "Epoch 57/1000\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.2967 - accuracy: 0.6541 - val_loss: 0.3846 - val_accuracy: 0.6318\n",
            "Epoch 58/1000\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.2942 - accuracy: 0.6557 - val_loss: 0.3833 - val_accuracy: 0.6289\n",
            "Epoch 59/1000\n",
            "4/4 [==============================] - 0s 135ms/step - loss: 0.2923 - accuracy: 0.6566 - val_loss: 0.3796 - val_accuracy: 0.6335\n",
            "Epoch 60/1000\n",
            "4/4 [==============================] - 0s 121ms/step - loss: 0.2903 - accuracy: 0.6593 - val_loss: 0.3769 - val_accuracy: 0.6380\n",
            "Epoch 61/1000\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.2874 - accuracy: 0.6652 - val_loss: 0.3756 - val_accuracy: 0.6384\n",
            "Epoch 62/1000\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.2862 - accuracy: 0.6654 - val_loss: 0.3727 - val_accuracy: 0.6397\n",
            "Epoch 63/1000\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.2839 - accuracy: 0.6673 - val_loss: 0.3704 - val_accuracy: 0.6414\n",
            "Epoch 64/1000\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.2817 - accuracy: 0.6681 - val_loss: 0.3694 - val_accuracy: 0.6438\n",
            "Epoch 65/1000\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.2805 - accuracy: 0.6716 - val_loss: 0.3669 - val_accuracy: 0.6449\n",
            "Epoch 66/1000\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.2778 - accuracy: 0.6728 - val_loss: 0.3640 - val_accuracy: 0.6467\n",
            "Epoch 67/1000\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.2762 - accuracy: 0.6741 - val_loss: 0.3621 - val_accuracy: 0.6464\n",
            "Epoch 68/1000\n",
            "4/4 [==============================] - 0s 121ms/step - loss: 0.2744 - accuracy: 0.6774 - val_loss: 0.3600 - val_accuracy: 0.6491\n",
            "Epoch 69/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 0.2727 - accuracy: 0.6789 - val_loss: 0.3580 - val_accuracy: 0.6539\n",
            "Epoch 70/1000\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.2709 - accuracy: 0.6814 - val_loss: 0.3568 - val_accuracy: 0.6562\n",
            "Epoch 71/1000\n",
            "4/4 [==============================] - 1s 127ms/step - loss: 0.2691 - accuracy: 0.6840 - val_loss: 0.3554 - val_accuracy: 0.6581\n",
            "Epoch 72/1000\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.2675 - accuracy: 0.6858 - val_loss: 0.3529 - val_accuracy: 0.6589\n",
            "Epoch 73/1000\n",
            "4/4 [==============================] - 0s 131ms/step - loss: 0.2660 - accuracy: 0.6871 - val_loss: 0.3510 - val_accuracy: 0.6608\n",
            "Epoch 74/1000\n",
            "4/4 [==============================] - 0s 118ms/step - loss: 0.2648 - accuracy: 0.6880 - val_loss: 0.3499 - val_accuracy: 0.6597\n",
            "Epoch 75/1000\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.2629 - accuracy: 0.6891 - val_loss: 0.3477 - val_accuracy: 0.6648\n",
            "Epoch 76/1000\n",
            "4/4 [==============================] - 0s 131ms/step - loss: 0.2615 - accuracy: 0.6940 - val_loss: 0.3461 - val_accuracy: 0.6666\n",
            "Epoch 77/1000\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.2600 - accuracy: 0.6943 - val_loss: 0.3445 - val_accuracy: 0.6657\n",
            "Epoch 78/1000\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.2580 - accuracy: 0.6957 - val_loss: 0.3421 - val_accuracy: 0.6697\n",
            "Epoch 79/1000\n",
            "4/4 [==============================] - 0s 124ms/step - loss: 0.2571 - accuracy: 0.6975 - val_loss: 0.3409 - val_accuracy: 0.6701\n",
            "Epoch 80/1000\n",
            "4/4 [==============================] - 0s 120ms/step - loss: 0.2556 - accuracy: 0.7004 - val_loss: 0.3391 - val_accuracy: 0.6705\n",
            "Epoch 81/1000\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.2535 - accuracy: 0.7024 - val_loss: 0.3375 - val_accuracy: 0.6727\n",
            "Epoch 82/1000\n",
            "4/4 [==============================] - 0s 128ms/step - loss: 0.2525 - accuracy: 0.7021 - val_loss: 0.3360 - val_accuracy: 0.6749\n",
            "Epoch 83/1000\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.2510 - accuracy: 0.7036 - val_loss: 0.3349 - val_accuracy: 0.6741\n",
            "Epoch 84/1000\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.2500 - accuracy: 0.7035 - val_loss: 0.3332 - val_accuracy: 0.6763\n",
            "Epoch 85/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 0.2483 - accuracy: 0.7076 - val_loss: 0.3315 - val_accuracy: 0.6800\n",
            "Epoch 86/1000\n",
            "4/4 [==============================] - 1s 129ms/step - loss: 0.2471 - accuracy: 0.7099 - val_loss: 0.3312 - val_accuracy: 0.6767\n",
            "Epoch 87/1000\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.2453 - accuracy: 0.7111 - val_loss: 0.3292 - val_accuracy: 0.6796\n",
            "Epoch 88/1000\n",
            "4/4 [==============================] - 0s 120ms/step - loss: 0.2443 - accuracy: 0.7110 - val_loss: 0.3280 - val_accuracy: 0.6814\n",
            "Epoch 89/1000\n",
            "4/4 [==============================] - 1s 131ms/step - loss: 0.2433 - accuracy: 0.7127 - val_loss: 0.3273 - val_accuracy: 0.6790\n",
            "Epoch 90/1000\n",
            "4/4 [==============================] - 0s 122ms/step - loss: 0.2428 - accuracy: 0.7132 - val_loss: 0.3250 - val_accuracy: 0.6824\n",
            "Epoch 91/1000\n",
            "4/4 [==============================] - 1s 129ms/step - loss: 0.2411 - accuracy: 0.7167 - val_loss: 0.3239 - val_accuracy: 0.6853\n",
            "Epoch 92/1000\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.2399 - accuracy: 0.7161 - val_loss: 0.3234 - val_accuracy: 0.6838\n",
            "Epoch 93/1000\n",
            "4/4 [==============================] - 0s 123ms/step - loss: 0.2386 - accuracy: 0.7166 - val_loss: 0.3221 - val_accuracy: 0.6848\n",
            "Epoch 94/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 0.2372 - accuracy: 0.7216 - val_loss: 0.3207 - val_accuracy: 0.6869\n",
            "Epoch 95/1000\n",
            "4/4 [==============================] - 0s 118ms/step - loss: 0.2362 - accuracy: 0.7225 - val_loss: 0.3193 - val_accuracy: 0.6880\n",
            "Epoch 96/1000\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.2349 - accuracy: 0.7229 - val_loss: 0.3185 - val_accuracy: 0.6877\n",
            "Epoch 97/1000\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.2337 - accuracy: 0.7232 - val_loss: 0.3169 - val_accuracy: 0.6897\n",
            "Epoch 98/1000\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.2326 - accuracy: 0.7249 - val_loss: 0.3160 - val_accuracy: 0.6924\n",
            "Epoch 99/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 0.2312 - accuracy: 0.7266 - val_loss: 0.3156 - val_accuracy: 0.6895\n",
            "Epoch 100/1000\n",
            "4/4 [==============================] - 0s 125ms/step - loss: 0.2310 - accuracy: 0.7266 - val_loss: 0.3138 - val_accuracy: 0.6928\n",
            "Epoch 101/1000\n",
            "4/4 [==============================] - 0s 124ms/step - loss: 0.2299 - accuracy: 0.7293 - val_loss: 0.3125 - val_accuracy: 0.6961\n",
            "Epoch 102/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 0.2286 - accuracy: 0.7308 - val_loss: 0.3115 - val_accuracy: 0.6946\n",
            "Epoch 103/1000\n",
            "4/4 [==============================] - 1s 128ms/step - loss: 0.2275 - accuracy: 0.7321 - val_loss: 0.3105 - val_accuracy: 0.6967\n",
            "Epoch 104/1000\n",
            "4/4 [==============================] - 0s 114ms/step - loss: 0.2265 - accuracy: 0.7327 - val_loss: 0.3100 - val_accuracy: 0.6962\n",
            "Epoch 105/1000\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.2253 - accuracy: 0.7326 - val_loss: 0.3090 - val_accuracy: 0.6982\n",
            "Epoch 106/1000\n",
            "4/4 [==============================] - 0s 123ms/step - loss: 0.2247 - accuracy: 0.7360 - val_loss: 0.3082 - val_accuracy: 0.6994\n",
            "Epoch 107/1000\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.2234 - accuracy: 0.7368 - val_loss: 0.3072 - val_accuracy: 0.6987\n",
            "Epoch 108/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 0.2227 - accuracy: 0.7366 - val_loss: 0.3064 - val_accuracy: 0.7011\n",
            "Epoch 109/1000\n",
            "4/4 [==============================] - 1s 126ms/step - loss: 0.2216 - accuracy: 0.7382 - val_loss: 0.3062 - val_accuracy: 0.7016\n",
            "Epoch 110/1000\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.2207 - accuracy: 0.7393 - val_loss: 0.3052 - val_accuracy: 0.7015\n",
            "Epoch 111/1000\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.2196 - accuracy: 0.7401 - val_loss: 0.3039 - val_accuracy: 0.7031\n",
            "Epoch 112/1000\n",
            "4/4 [==============================] - 1s 131ms/step - loss: 0.2191 - accuracy: 0.7414 - val_loss: 0.3034 - val_accuracy: 0.7006\n",
            "Epoch 113/1000\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.2179 - accuracy: 0.7417 - val_loss: 0.3016 - val_accuracy: 0.7042\n",
            "Epoch 114/1000\n",
            "4/4 [==============================] - 0s 123ms/step - loss: 0.2165 - accuracy: 0.7443 - val_loss: 0.3014 - val_accuracy: 0.7041\n",
            "Epoch 115/1000\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.2158 - accuracy: 0.7444 - val_loss: 0.3008 - val_accuracy: 0.7031\n",
            "Epoch 116/1000\n",
            "4/4 [==============================] - 0s 119ms/step - loss: 0.2151 - accuracy: 0.7453 - val_loss: 0.2992 - val_accuracy: 0.7062\n",
            "Epoch 117/1000\n",
            "4/4 [==============================] - 0s 117ms/step - loss: 0.2140 - accuracy: 0.7471 - val_loss: 0.2987 - val_accuracy: 0.7066\n",
            "Epoch 118/1000\n",
            "4/4 [==============================] - 0s 129ms/step - loss: 0.2133 - accuracy: 0.7463 - val_loss: 0.2976 - val_accuracy: 0.7071\n",
            "Epoch 119/1000\n",
            "4/4 [==============================] - 1s 127ms/step - loss: 0.2124 - accuracy: 0.7487 - val_loss: 0.2961 - val_accuracy: 0.7086\n",
            "Epoch 120/1000\n",
            "4/4 [==============================] - 1s 127ms/step - loss: 0.2128 - accuracy: 0.7480 - val_loss: 0.2958 - val_accuracy: 0.7093\n",
            "Epoch 121/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 0.2107 - accuracy: 0.7508 - val_loss: 0.2956 - val_accuracy: 0.7103\n",
            "Epoch 122/1000\n",
            "4/4 [==============================] - 0s 126ms/step - loss: 0.2108 - accuracy: 0.7501 - val_loss: 0.2953 - val_accuracy: 0.7106\n",
            "Epoch 123/1000\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.2096 - accuracy: 0.7517 - val_loss: 0.2948 - val_accuracy: 0.7079\n",
            "Epoch 124/1000\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.2093 - accuracy: 0.7509 - val_loss: 0.2920 - val_accuracy: 0.7130\n",
            "Epoch 125/1000\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.2083 - accuracy: 0.7535 - val_loss: 0.2917 - val_accuracy: 0.7138\n",
            "Epoch 126/1000\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 0.2063 - accuracy: 0.7561 - val_loss: 0.2926 - val_accuracy: 0.7130\n",
            "Epoch 127/1000\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.2056 - accuracy: 0.7571 - val_loss: 0.2904 - val_accuracy: 0.7146\n",
            "Epoch 128/1000\n",
            "4/4 [==============================] - 0s 140ms/step - loss: 0.2050 - accuracy: 0.7567 - val_loss: 0.2892 - val_accuracy: 0.7147\n",
            "Epoch 129/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 0.2038 - accuracy: 0.7588 - val_loss: 0.2886 - val_accuracy: 0.7166\n",
            "Epoch 130/1000\n",
            "4/4 [==============================] - 0s 121ms/step - loss: 0.2031 - accuracy: 0.7598 - val_loss: 0.2889 - val_accuracy: 0.7168\n",
            "Epoch 131/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 0.2026 - accuracy: 0.7595 - val_loss: 0.2880 - val_accuracy: 0.7175\n",
            "Epoch 132/1000\n",
            "4/4 [==============================] - 1s 120ms/step - loss: 0.2013 - accuracy: 0.7596 - val_loss: 0.2871 - val_accuracy: 0.7179\n",
            "Epoch 133/1000\n",
            "4/4 [==============================] - 0s 126ms/step - loss: 0.2005 - accuracy: 0.7632 - val_loss: 0.2862 - val_accuracy: 0.7190\n",
            "Epoch 134/1000\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.2000 - accuracy: 0.7641 - val_loss: 0.2852 - val_accuracy: 0.7202\n",
            "Epoch 135/1000\n",
            "4/4 [==============================] - 1s 129ms/step - loss: 0.1996 - accuracy: 0.7638 - val_loss: 0.2849 - val_accuracy: 0.7211\n",
            "Epoch 136/1000\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.1986 - accuracy: 0.7647 - val_loss: 0.2844 - val_accuracy: 0.7213\n",
            "Epoch 137/1000\n",
            "4/4 [==============================] - 1s 128ms/step - loss: 0.1981 - accuracy: 0.7661 - val_loss: 0.2841 - val_accuracy: 0.7212\n",
            "Epoch 138/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 0.1971 - accuracy: 0.7665 - val_loss: 0.2847 - val_accuracy: 0.7202\n",
            "Epoch 139/1000\n",
            "4/4 [==============================] - 0s 119ms/step - loss: 0.1974 - accuracy: 0.7623 - val_loss: 0.2834 - val_accuracy: 0.7211\n",
            "Epoch 140/1000\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.1963 - accuracy: 0.7665 - val_loss: 0.2825 - val_accuracy: 0.7232\n",
            "Epoch 141/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 0.1952 - accuracy: 0.7685 - val_loss: 0.2822 - val_accuracy: 0.7225\n",
            "Epoch 142/1000\n",
            "4/4 [==============================] - 1s 131ms/step - loss: 0.1943 - accuracy: 0.7689 - val_loss: 0.2812 - val_accuracy: 0.7238\n",
            "Epoch 143/1000\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.1941 - accuracy: 0.7708 - val_loss: 0.2802 - val_accuracy: 0.7245\n",
            "Epoch 144/1000\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.1931 - accuracy: 0.7714 - val_loss: 0.2796 - val_accuracy: 0.7247\n",
            "Epoch 145/1000\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.1925 - accuracy: 0.7718 - val_loss: 0.2787 - val_accuracy: 0.7257\n",
            "Epoch 146/1000\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.1923 - accuracy: 0.7729 - val_loss: 0.2781 - val_accuracy: 0.7266\n",
            "Epoch 147/1000\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.1910 - accuracy: 0.7734 - val_loss: 0.2781 - val_accuracy: 0.7260\n",
            "Epoch 148/1000\n",
            "4/4 [==============================] - 0s 125ms/step - loss: 0.1907 - accuracy: 0.7724 - val_loss: 0.2770 - val_accuracy: 0.7283\n",
            "Epoch 149/1000\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.1890 - accuracy: 0.7766 - val_loss: 0.2766 - val_accuracy: 0.7271\n",
            "Epoch 150/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 0.1895 - accuracy: 0.7753 - val_loss: 0.2759 - val_accuracy: 0.7269\n",
            "Epoch 151/1000\n",
            "4/4 [==============================] - 0s 130ms/step - loss: 0.1880 - accuracy: 0.7773 - val_loss: 0.2752 - val_accuracy: 0.7284\n",
            "Epoch 152/1000\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 0.1878 - accuracy: 0.7777 - val_loss: 0.2749 - val_accuracy: 0.7281\n",
            "Epoch 153/1000\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.1869 - accuracy: 0.7788 - val_loss: 0.2748 - val_accuracy: 0.7299\n",
            "Epoch 154/1000\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.1867 - accuracy: 0.7792 - val_loss: 0.2746 - val_accuracy: 0.7293\n",
            "Epoch 155/1000\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.1860 - accuracy: 0.7801 - val_loss: 0.2741 - val_accuracy: 0.7297\n",
            "Epoch 156/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 0.1848 - accuracy: 0.7812 - val_loss: 0.2737 - val_accuracy: 0.7301\n",
            "Epoch 157/1000\n",
            "4/4 [==============================] - 0s 118ms/step - loss: 0.1844 - accuracy: 0.7807 - val_loss: 0.2728 - val_accuracy: 0.7316\n",
            "Epoch 158/1000\n",
            "4/4 [==============================] - 0s 124ms/step - loss: 0.1842 - accuracy: 0.7832 - val_loss: 0.2720 - val_accuracy: 0.7317\n",
            "Epoch 159/1000\n",
            "4/4 [==============================] - 0s 122ms/step - loss: 0.1835 - accuracy: 0.7825 - val_loss: 0.2718 - val_accuracy: 0.7309\n",
            "Epoch 160/1000\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.1829 - accuracy: 0.7830 - val_loss: 0.2713 - val_accuracy: 0.7312\n",
            "Epoch 161/1000\n",
            "4/4 [==============================] - 0s 134ms/step - loss: 0.1822 - accuracy: 0.7849 - val_loss: 0.2707 - val_accuracy: 0.7321\n",
            "Epoch 162/1000\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.1817 - accuracy: 0.7828 - val_loss: 0.2701 - val_accuracy: 0.7331\n",
            "Epoch 163/1000\n",
            "4/4 [==============================] - 1s 128ms/step - loss: 0.1813 - accuracy: 0.7840 - val_loss: 0.2703 - val_accuracy: 0.7332\n",
            "Epoch 164/1000\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.1802 - accuracy: 0.7878 - val_loss: 0.2694 - val_accuracy: 0.7341\n",
            "Epoch 165/1000\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.1803 - accuracy: 0.7867 - val_loss: 0.2686 - val_accuracy: 0.7345\n",
            "Epoch 166/1000\n",
            "4/4 [==============================] - 0s 114ms/step - loss: 0.1795 - accuracy: 0.7866 - val_loss: 0.2686 - val_accuracy: 0.7348\n",
            "Epoch 167/1000\n",
            "4/4 [==============================] - 0s 119ms/step - loss: 0.1788 - accuracy: 0.7873 - val_loss: 0.2681 - val_accuracy: 0.7348\n",
            "Epoch 168/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 0.1781 - accuracy: 0.7899 - val_loss: 0.2675 - val_accuracy: 0.7360\n",
            "Epoch 169/1000\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.1783 - accuracy: 0.7886 - val_loss: 0.2670 - val_accuracy: 0.7359\n",
            "Epoch 170/1000\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.1768 - accuracy: 0.7909 - val_loss: 0.2670 - val_accuracy: 0.7354\n",
            "Epoch 171/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 0.1767 - accuracy: 0.7874 - val_loss: 0.2681 - val_accuracy: 0.7339\n",
            "Epoch 172/1000\n",
            "4/4 [==============================] - 0s 128ms/step - loss: 0.1768 - accuracy: 0.7900 - val_loss: 0.2665 - val_accuracy: 0.7359\n",
            "Epoch 173/1000\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.1763 - accuracy: 0.7912 - val_loss: 0.2660 - val_accuracy: 0.7366\n",
            "Epoch 174/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 0.1758 - accuracy: 0.7919 - val_loss: 0.2665 - val_accuracy: 0.7373\n",
            "Epoch 175/1000\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.1747 - accuracy: 0.7915 - val_loss: 0.2646 - val_accuracy: 0.7381\n",
            "Epoch 176/1000\n",
            "4/4 [==============================] - 0s 120ms/step - loss: 0.1744 - accuracy: 0.7914 - val_loss: 0.2645 - val_accuracy: 0.7388\n",
            "Epoch 177/1000\n",
            "4/4 [==============================] - 0s 109ms/step - loss: 0.1732 - accuracy: 0.7938 - val_loss: 0.2641 - val_accuracy: 0.7388\n",
            "Epoch 178/1000\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.1728 - accuracy: 0.7955 - val_loss: 0.2637 - val_accuracy: 0.7389\n",
            "Epoch 179/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 0.1724 - accuracy: 0.7963 - val_loss: 0.2632 - val_accuracy: 0.7392\n",
            "Epoch 180/1000\n",
            "4/4 [==============================] - 0s 121ms/step - loss: 0.1718 - accuracy: 0.7965 - val_loss: 0.2631 - val_accuracy: 0.7392\n",
            "Epoch 181/1000\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.1714 - accuracy: 0.7961 - val_loss: 0.2625 - val_accuracy: 0.7399\n",
            "Epoch 182/1000\n",
            "4/4 [==============================] - 0s 126ms/step - loss: 0.1710 - accuracy: 0.7979 - val_loss: 0.2628 - val_accuracy: 0.7400\n",
            "Epoch 183/1000\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.1702 - accuracy: 0.7990 - val_loss: 0.2625 - val_accuracy: 0.7401\n",
            "Epoch 184/1000\n",
            "4/4 [==============================] - 0s 131ms/step - loss: 0.1703 - accuracy: 0.7964 - val_loss: 0.2613 - val_accuracy: 0.7423\n",
            "Epoch 185/1000\n",
            "4/4 [==============================] - 1s 129ms/step - loss: 0.1693 - accuracy: 0.8003 - val_loss: 0.2620 - val_accuracy: 0.7403\n",
            "Epoch 186/1000\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.1691 - accuracy: 0.7993 - val_loss: 0.2614 - val_accuracy: 0.7414\n",
            "Epoch 187/1000\n",
            "4/4 [==============================] - 0s 131ms/step - loss: 0.1686 - accuracy: 0.8012 - val_loss: 0.2609 - val_accuracy: 0.7422\n",
            "Epoch 188/1000\n",
            "4/4 [==============================] - 0s 124ms/step - loss: 0.1683 - accuracy: 0.8000 - val_loss: 0.2604 - val_accuracy: 0.7424\n",
            "Epoch 189/1000\n",
            "4/4 [==============================] - 1s 131ms/step - loss: 0.1675 - accuracy: 0.8005 - val_loss: 0.2597 - val_accuracy: 0.7434\n",
            "Epoch 190/1000\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.1678 - accuracy: 0.7988 - val_loss: 0.2590 - val_accuracy: 0.7442\n",
            "Epoch 191/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 0.1666 - accuracy: 0.8036 - val_loss: 0.2591 - val_accuracy: 0.7449\n",
            "Epoch 192/1000\n",
            "4/4 [==============================] - 0s 121ms/step - loss: 0.1660 - accuracy: 0.8028 - val_loss: 0.2586 - val_accuracy: 0.7445\n",
            "Epoch 193/1000\n",
            "4/4 [==============================] - 0s 122ms/step - loss: 0.1657 - accuracy: 0.8028 - val_loss: 0.2585 - val_accuracy: 0.7444\n",
            "Epoch 194/1000\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.1648 - accuracy: 0.8043 - val_loss: 0.2572 - val_accuracy: 0.7456\n",
            "Epoch 195/1000\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.1653 - accuracy: 0.8027 - val_loss: 0.2571 - val_accuracy: 0.7467\n",
            "Epoch 196/1000\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.1641 - accuracy: 0.8071 - val_loss: 0.2578 - val_accuracy: 0.7457\n",
            "Epoch 197/1000\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 0.1636 - accuracy: 0.8062 - val_loss: 0.2573 - val_accuracy: 0.7470\n",
            "Epoch 198/1000\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.1632 - accuracy: 0.8060 - val_loss: 0.2566 - val_accuracy: 0.7480\n",
            "Epoch 199/1000\n",
            "4/4 [==============================] - 1s 127ms/step - loss: 0.1628 - accuracy: 0.8056 - val_loss: 0.2564 - val_accuracy: 0.7477\n",
            "Epoch 200/1000\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.1626 - accuracy: 0.8064 - val_loss: 0.2562 - val_accuracy: 0.7484\n",
            "Epoch 201/1000\n",
            "4/4 [==============================] - 0s 114ms/step - loss: 0.1625 - accuracy: 0.8068 - val_loss: 0.2568 - val_accuracy: 0.7470\n",
            "Epoch 202/1000\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.1618 - accuracy: 0.8065 - val_loss: 0.2557 - val_accuracy: 0.7485\n",
            "Epoch 203/1000\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 0.1617 - accuracy: 0.8076 - val_loss: 0.2564 - val_accuracy: 0.7480\n",
            "Epoch 204/1000\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.1622 - accuracy: 0.8047 - val_loss: 0.2574 - val_accuracy: 0.7462\n",
            "Epoch 205/1000\n",
            "4/4 [==============================] - 0s 121ms/step - loss: 0.1605 - accuracy: 0.8088 - val_loss: 0.2566 - val_accuracy: 0.7469\n",
            "Epoch 206/1000\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.1605 - accuracy: 0.8099 - val_loss: 0.2563 - val_accuracy: 0.7481\n",
            "Epoch 207/1000\n",
            "4/4 [==============================] - 0s 112ms/step - loss: 0.1598 - accuracy: 0.8102 - val_loss: 0.2552 - val_accuracy: 0.7487\n",
            "Epoch 208/1000\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.1591 - accuracy: 0.8110 - val_loss: 0.2544 - val_accuracy: 0.7496\n",
            "Epoch 209/1000\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.1590 - accuracy: 0.8106 - val_loss: 0.2541 - val_accuracy: 0.7511\n",
            "Epoch 210/1000\n",
            "4/4 [==============================] - 0s 126ms/step - loss: 0.1580 - accuracy: 0.8125 - val_loss: 0.2537 - val_accuracy: 0.7509\n",
            "Epoch 211/1000\n",
            "4/4 [==============================] - 0s 120ms/step - loss: 0.1575 - accuracy: 0.8130 - val_loss: 0.2537 - val_accuracy: 0.7510\n",
            "Epoch 212/1000\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.1575 - accuracy: 0.8115 - val_loss: 0.2529 - val_accuracy: 0.7512\n",
            "Epoch 213/1000\n",
            "4/4 [==============================] - 0s 122ms/step - loss: 0.1565 - accuracy: 0.8131 - val_loss: 0.2524 - val_accuracy: 0.7525\n",
            "Epoch 214/1000\n",
            "4/4 [==============================] - 0s 132ms/step - loss: 0.1568 - accuracy: 0.8138 - val_loss: 0.2518 - val_accuracy: 0.7527\n",
            "Epoch 215/1000\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.1555 - accuracy: 0.8150 - val_loss: 0.2512 - val_accuracy: 0.7525\n",
            "Epoch 216/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 0.1558 - accuracy: 0.8146 - val_loss: 0.2516 - val_accuracy: 0.7523\n",
            "Epoch 217/1000\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.1550 - accuracy: 0.8152 - val_loss: 0.2520 - val_accuracy: 0.7521\n",
            "Epoch 218/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 0.1547 - accuracy: 0.8148 - val_loss: 0.2516 - val_accuracy: 0.7525\n",
            "Epoch 219/1000\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.1543 - accuracy: 0.8163 - val_loss: 0.2509 - val_accuracy: 0.7532\n",
            "Epoch 220/1000\n",
            "4/4 [==============================] - 0s 123ms/step - loss: 0.1539 - accuracy: 0.8176 - val_loss: 0.2507 - val_accuracy: 0.7530\n",
            "Epoch 221/1000\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 0.1540 - accuracy: 0.8182 - val_loss: 0.2507 - val_accuracy: 0.7529\n",
            "Epoch 222/1000\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.1538 - accuracy: 0.8173 - val_loss: 0.2504 - val_accuracy: 0.7537\n",
            "Epoch 223/1000\n",
            "4/4 [==============================] - 0s 124ms/step - loss: 0.1531 - accuracy: 0.8172 - val_loss: 0.2502 - val_accuracy: 0.7539\n",
            "Epoch 224/1000\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 0.1526 - accuracy: 0.8181 - val_loss: 0.2492 - val_accuracy: 0.7559\n",
            "Epoch 225/1000\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.1522 - accuracy: 0.8182 - val_loss: 0.2492 - val_accuracy: 0.7561\n",
            "Epoch 226/1000\n",
            "4/4 [==============================] - 0s 127ms/step - loss: 0.1525 - accuracy: 0.8175 - val_loss: 0.2497 - val_accuracy: 0.7556\n",
            "Epoch 227/1000\n",
            "4/4 [==============================] - 0s 126ms/step - loss: 0.1518 - accuracy: 0.8196 - val_loss: 0.2494 - val_accuracy: 0.7552\n",
            "Epoch 228/1000\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.1512 - accuracy: 0.8202 - val_loss: 0.2484 - val_accuracy: 0.7559\n",
            "Epoch 229/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 0.1504 - accuracy: 0.8207 - val_loss: 0.2483 - val_accuracy: 0.7554\n",
            "Epoch 230/1000\n",
            "4/4 [==============================] - 0s 125ms/step - loss: 0.1506 - accuracy: 0.8211 - val_loss: 0.2475 - val_accuracy: 0.7561\n",
            "Epoch 231/1000\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 0.1496 - accuracy: 0.8226 - val_loss: 0.2474 - val_accuracy: 0.7564\n",
            "Epoch 232/1000\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.1493 - accuracy: 0.8241 - val_loss: 0.2477 - val_accuracy: 0.7568\n",
            "Epoch 233/1000\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 0.1493 - accuracy: 0.8226 - val_loss: 0.2479 - val_accuracy: 0.7569\n",
            "Epoch 234/1000\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.1489 - accuracy: 0.8237 - val_loss: 0.2475 - val_accuracy: 0.7575\n",
            "Epoch 235/1000\n",
            "4/4 [==============================] - 0s 127ms/step - loss: 0.1490 - accuracy: 0.8214 - val_loss: 0.2472 - val_accuracy: 0.7577\n",
            "Epoch 236/1000\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.1486 - accuracy: 0.8234 - val_loss: 0.2474 - val_accuracy: 0.7565\n",
            "Epoch 237/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 0.1478 - accuracy: 0.8246 - val_loss: 0.2473 - val_accuracy: 0.7576\n",
            "Epoch 238/1000\n",
            "4/4 [==============================] - 0s 129ms/step - loss: 0.1477 - accuracy: 0.8250 - val_loss: 0.2473 - val_accuracy: 0.7580\n",
            "Epoch 239/1000\n",
            "4/4 [==============================] - 0s 126ms/step - loss: 0.1479 - accuracy: 0.8238 - val_loss: 0.2465 - val_accuracy: 0.7581\n",
            "Epoch 240/1000\n",
            "4/4 [==============================] - 0s 125ms/step - loss: 0.1464 - accuracy: 0.8268 - val_loss: 0.2463 - val_accuracy: 0.7584\n",
            "Epoch 241/1000\n",
            "4/4 [==============================] - 0s 125ms/step - loss: 0.1466 - accuracy: 0.8256 - val_loss: 0.2459 - val_accuracy: 0.7592\n",
            "Epoch 242/1000\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.1464 - accuracy: 0.8259 - val_loss: 0.2458 - val_accuracy: 0.7595\n",
            "Epoch 243/1000\n",
            "4/4 [==============================] - 1s 128ms/step - loss: 0.1457 - accuracy: 0.8264 - val_loss: 0.2457 - val_accuracy: 0.7594\n",
            "Epoch 244/1000\n",
            "4/4 [==============================] - 1s 130ms/step - loss: 0.1452 - accuracy: 0.8268 - val_loss: 0.2453 - val_accuracy: 0.7597\n",
            "Epoch 245/1000\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.1454 - accuracy: 0.8275 - val_loss: 0.2454 - val_accuracy: 0.7600\n",
            "Epoch 246/1000\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 0.1441 - accuracy: 0.8300 - val_loss: 0.2453 - val_accuracy: 0.7597\n",
            "Epoch 247/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 0.1446 - accuracy: 0.8284 - val_loss: 0.2442 - val_accuracy: 0.7600\n",
            "Epoch 248/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 0.1440 - accuracy: 0.8274 - val_loss: 0.2440 - val_accuracy: 0.7605\n",
            "Epoch 249/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 0.1432 - accuracy: 0.8304 - val_loss: 0.2445 - val_accuracy: 0.7604\n",
            "Epoch 250/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 0.1433 - accuracy: 0.8287 - val_loss: 0.2444 - val_accuracy: 0.7602\n",
            "Epoch 251/1000\n",
            "4/4 [==============================] - 1s 127ms/step - loss: 0.1433 - accuracy: 0.8288 - val_loss: 0.2442 - val_accuracy: 0.7606\n",
            "Epoch 252/1000\n",
            "4/4 [==============================] - 0s 124ms/step - loss: 0.1428 - accuracy: 0.8300 - val_loss: 0.2440 - val_accuracy: 0.7598\n",
            "Epoch 253/1000\n",
            "4/4 [==============================] - 0s 120ms/step - loss: 0.1427 - accuracy: 0.8304 - val_loss: 0.2437 - val_accuracy: 0.7606\n",
            "Epoch 254/1000\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.1420 - accuracy: 0.8320 - val_loss: 0.2438 - val_accuracy: 0.7614\n",
            "Epoch 255/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 0.1415 - accuracy: 0.8310 - val_loss: 0.2440 - val_accuracy: 0.7616\n",
            "Epoch 256/1000\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 0.1414 - accuracy: 0.8336 - val_loss: 0.2440 - val_accuracy: 0.7602\n",
            "Epoch 257/1000\n",
            "4/4 [==============================] - 0s 129ms/step - loss: 0.1409 - accuracy: 0.8324 - val_loss: 0.2431 - val_accuracy: 0.7627\n",
            "Epoch 258/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 0.1413 - accuracy: 0.8307 - val_loss: 0.2430 - val_accuracy: 0.7632\n",
            "Epoch 259/1000\n",
            "4/4 [==============================] - 0s 99ms/step - loss: 0.1410 - accuracy: 0.8310 - val_loss: 0.2431 - val_accuracy: 0.7612\n",
            "Epoch 260/1000\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.1405 - accuracy: 0.8332 - val_loss: 0.2419 - val_accuracy: 0.7626\n",
            "Epoch 261/1000\n",
            "4/4 [==============================] - 0s 119ms/step - loss: 0.1396 - accuracy: 0.8324 - val_loss: 0.2418 - val_accuracy: 0.7627\n",
            "Epoch 262/1000\n",
            "4/4 [==============================] - 0s 134ms/step - loss: 0.1393 - accuracy: 0.8338 - val_loss: 0.2422 - val_accuracy: 0.7627\n",
            "Epoch 263/1000\n",
            "4/4 [==============================] - 0s 130ms/step - loss: 0.1389 - accuracy: 0.8340 - val_loss: 0.2418 - val_accuracy: 0.7627\n",
            "Epoch 264/1000\n",
            "4/4 [==============================] - 0s 128ms/step - loss: 0.1390 - accuracy: 0.8341 - val_loss: 0.2414 - val_accuracy: 0.7628\n",
            "Epoch 265/1000\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.1380 - accuracy: 0.8346 - val_loss: 0.2413 - val_accuracy: 0.7629\n",
            "Epoch 266/1000\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.1382 - accuracy: 0.8358 - val_loss: 0.2413 - val_accuracy: 0.7635\n",
            "Epoch 267/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 0.1377 - accuracy: 0.8364 - val_loss: 0.2408 - val_accuracy: 0.7643\n",
            "Epoch 268/1000\n",
            "4/4 [==============================] - 1s 131ms/step - loss: 0.1378 - accuracy: 0.8361 - val_loss: 0.2403 - val_accuracy: 0.7642\n",
            "Epoch 269/1000\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.1380 - accuracy: 0.8362 - val_loss: 0.2395 - val_accuracy: 0.7650\n",
            "Epoch 270/1000\n",
            "4/4 [==============================] - 0s 113ms/step - loss: 0.1370 - accuracy: 0.8365 - val_loss: 0.2397 - val_accuracy: 0.7652\n",
            "Epoch 271/1000\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.1366 - accuracy: 0.8376 - val_loss: 0.2405 - val_accuracy: 0.7641\n",
            "Epoch 272/1000\n",
            "4/4 [==============================] - 0s 124ms/step - loss: 0.1367 - accuracy: 0.8374 - val_loss: 0.2404 - val_accuracy: 0.7646\n",
            "Epoch 273/1000\n",
            "4/4 [==============================] - 0s 132ms/step - loss: 0.1359 - accuracy: 0.8380 - val_loss: 0.2404 - val_accuracy: 0.7648\n",
            "Epoch 274/1000\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.1363 - accuracy: 0.8381 - val_loss: 0.2399 - val_accuracy: 0.7646\n",
            "Epoch 275/1000\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.1365 - accuracy: 0.8366 - val_loss: 0.2395 - val_accuracy: 0.7653\n",
            "Epoch 276/1000\n",
            "4/4 [==============================] - 0s 109ms/step - loss: 0.1355 - accuracy: 0.8378 - val_loss: 0.2407 - val_accuracy: 0.7646\n",
            "Epoch 277/1000\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.1353 - accuracy: 0.8381 - val_loss: 0.2394 - val_accuracy: 0.7660\n",
            "Epoch 278/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 0.1349 - accuracy: 0.8400 - val_loss: 0.2387 - val_accuracy: 0.7670\n",
            "Epoch 279/1000\n",
            "4/4 [==============================] - 0s 123ms/step - loss: 0.1350 - accuracy: 0.8391 - val_loss: 0.2388 - val_accuracy: 0.7656\n",
            "Epoch 280/1000\n",
            "4/4 [==============================] - 0s 132ms/step - loss: 0.1341 - accuracy: 0.8390 - val_loss: 0.2385 - val_accuracy: 0.7661\n",
            "Epoch 281/1000\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.1337 - accuracy: 0.8387 - val_loss: 0.2384 - val_accuracy: 0.7661\n",
            "Epoch 282/1000\n",
            "4/4 [==============================] - 0s 124ms/step - loss: 0.1338 - accuracy: 0.8387 - val_loss: 0.2384 - val_accuracy: 0.7660\n",
            "Epoch 283/1000\n",
            "4/4 [==============================] - 0s 129ms/step - loss: 0.1326 - accuracy: 0.8408 - val_loss: 0.2376 - val_accuracy: 0.7664\n",
            "Epoch 284/1000\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.1329 - accuracy: 0.8410 - val_loss: 0.2381 - val_accuracy: 0.7661\n",
            "Epoch 285/1000\n",
            "4/4 [==============================] - 1s 117ms/step - loss: 0.1329 - accuracy: 0.8404 - val_loss: 0.2388 - val_accuracy: 0.7661\n",
            "Epoch 286/1000\n",
            "4/4 [==============================] - 0s 130ms/step - loss: 0.1326 - accuracy: 0.8409 - val_loss: 0.2386 - val_accuracy: 0.7663\n",
            "Epoch 287/1000\n",
            "4/4 [==============================] - 0s 122ms/step - loss: 0.1317 - accuracy: 0.8424 - val_loss: 0.2379 - val_accuracy: 0.7665\n",
            "Epoch 288/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 0.1318 - accuracy: 0.8421 - val_loss: 0.2376 - val_accuracy: 0.7676\n",
            "Epoch 289/1000\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.1324 - accuracy: 0.8425 - val_loss: 0.2372 - val_accuracy: 0.7678\n",
            "Epoch 290/1000\n",
            "4/4 [==============================] - 0s 118ms/step - loss: 0.1314 - accuracy: 0.8443 - val_loss: 0.2376 - val_accuracy: 0.7681\n",
            "Epoch 291/1000\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.1314 - accuracy: 0.8432 - val_loss: 0.2373 - val_accuracy: 0.7689\n",
            "Epoch 292/1000\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.1310 - accuracy: 0.8439 - val_loss: 0.2377 - val_accuracy: 0.7682\n",
            "Epoch 293/1000\n",
            "4/4 [==============================] - 1s 130ms/step - loss: 0.1311 - accuracy: 0.8424 - val_loss: 0.2381 - val_accuracy: 0.7674\n",
            "Epoch 294/1000\n",
            "4/4 [==============================] - 1s 127ms/step - loss: 0.1306 - accuracy: 0.8441 - val_loss: 0.2378 - val_accuracy: 0.7683\n",
            "Epoch 295/1000\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.1301 - accuracy: 0.8438 - val_loss: 0.2384 - val_accuracy: 0.7667\n",
            "Epoch 296/1000\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.1304 - accuracy: 0.8423 - val_loss: 0.2369 - val_accuracy: 0.7687\n",
            "Epoch 297/1000\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.1302 - accuracy: 0.8440 - val_loss: 0.2374 - val_accuracy: 0.7676\n",
            "Epoch 298/1000\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.1294 - accuracy: 0.8443 - val_loss: 0.2371 - val_accuracy: 0.7685\n",
            "Epoch 299/1000\n",
            "4/4 [==============================] - 0s 119ms/step - loss: 0.1293 - accuracy: 0.8461 - val_loss: 0.2375 - val_accuracy: 0.7694\n",
            "Epoch 300/1000\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.1291 - accuracy: 0.8472 - val_loss: 0.2372 - val_accuracy: 0.7689\n",
            "Epoch 301/1000\n",
            "4/4 [==============================] - 0s 119ms/step - loss: 0.1289 - accuracy: 0.8468 - val_loss: 0.2381 - val_accuracy: 0.7681\n",
            "Epoch 302/1000\n",
            "4/4 [==============================] - 1s 126ms/step - loss: 0.1284 - accuracy: 0.8458 - val_loss: 0.2386 - val_accuracy: 0.7670\n",
            "Epoch 303/1000\n",
            "4/4 [==============================] - 1s 128ms/step - loss: 0.1283 - accuracy: 0.8461 - val_loss: 0.2375 - val_accuracy: 0.7688\n",
            "Epoch 304/1000\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.1275 - accuracy: 0.8483 - val_loss: 0.2369 - val_accuracy: 0.7687\n",
            "Epoch 305/1000\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.1271 - accuracy: 0.8474 - val_loss: 0.2367 - val_accuracy: 0.7685\n",
            "Epoch 306/1000\n",
            "4/4 [==============================] - 0s 127ms/step - loss: 0.1276 - accuracy: 0.8462 - val_loss: 0.2369 - val_accuracy: 0.7688\n",
            "Epoch 307/1000\n",
            "4/4 [==============================] - 0s 129ms/step - loss: 0.1278 - accuracy: 0.8465 - val_loss: 0.2366 - val_accuracy: 0.7685\n",
            "Epoch 308/1000\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 0.1267 - accuracy: 0.8476 - val_loss: 0.2366 - val_accuracy: 0.7702\n",
            "Epoch 309/1000\n",
            "4/4 [==============================] - 0s 137ms/step - loss: 0.1265 - accuracy: 0.8475 - val_loss: 0.2369 - val_accuracy: 0.7689\n",
            "Epoch 310/1000\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.1263 - accuracy: 0.8490 - val_loss: 0.2359 - val_accuracy: 0.7705\n",
            "Epoch 311/1000\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.1262 - accuracy: 0.8498 - val_loss: 0.2355 - val_accuracy: 0.7705\n",
            "Epoch 312/1000\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.1264 - accuracy: 0.8502 - val_loss: 0.2356 - val_accuracy: 0.7700\n",
            "Epoch 313/1000\n",
            "4/4 [==============================] - 0s 120ms/step - loss: 0.1254 - accuracy: 0.8506 - val_loss: 0.2359 - val_accuracy: 0.7707\n",
            "Epoch 314/1000\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 0.1256 - accuracy: 0.8500 - val_loss: 0.2356 - val_accuracy: 0.7713\n",
            "Epoch 315/1000\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.1250 - accuracy: 0.8504 - val_loss: 0.2357 - val_accuracy: 0.7708\n",
            "Epoch 316/1000\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.1250 - accuracy: 0.8497 - val_loss: 0.2354 - val_accuracy: 0.7706\n",
            "Epoch 317/1000\n",
            "4/4 [==============================] - 0s 124ms/step - loss: 0.1248 - accuracy: 0.8515 - val_loss: 0.2352 - val_accuracy: 0.7709\n",
            "Epoch 318/1000\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.1241 - accuracy: 0.8523 - val_loss: 0.2355 - val_accuracy: 0.7710\n",
            "Epoch 319/1000\n",
            "4/4 [==============================] - 0s 125ms/step - loss: 0.1236 - accuracy: 0.8517 - val_loss: 0.2360 - val_accuracy: 0.7703\n",
            "Epoch 320/1000\n",
            "4/4 [==============================] - 0s 128ms/step - loss: 0.1243 - accuracy: 0.8508 - val_loss: 0.2355 - val_accuracy: 0.7702\n",
            "Epoch 321/1000\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.1231 - accuracy: 0.8513 - val_loss: 0.2352 - val_accuracy: 0.7710\n",
            "Epoch 322/1000\n",
            "4/4 [==============================] - 1s 130ms/step - loss: 0.1233 - accuracy: 0.8521 - val_loss: 0.2350 - val_accuracy: 0.7718\n",
            "Epoch 323/1000\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.1231 - accuracy: 0.8516 - val_loss: 0.2349 - val_accuracy: 0.7715\n",
            "Epoch 324/1000\n",
            "4/4 [==============================] - 0s 121ms/step - loss: 0.1223 - accuracy: 0.8522 - val_loss: 0.2348 - val_accuracy: 0.7714\n",
            "Epoch 325/1000\n",
            "4/4 [==============================] - 1s 131ms/step - loss: 0.1225 - accuracy: 0.8557 - val_loss: 0.2349 - val_accuracy: 0.7713\n",
            "Epoch 326/1000\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.1226 - accuracy: 0.8524 - val_loss: 0.2354 - val_accuracy: 0.7708\n",
            "Epoch 327/1000\n",
            "4/4 [==============================] - 0s 131ms/step - loss: 0.1225 - accuracy: 0.8538 - val_loss: 0.2356 - val_accuracy: 0.7701\n",
            "Epoch 328/1000\n",
            "4/4 [==============================] - 0s 132ms/step - loss: 0.1212 - accuracy: 0.8556 - val_loss: 0.2352 - val_accuracy: 0.7706\n",
            "Epoch 329/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 0.1218 - accuracy: 0.8549 - val_loss: 0.2348 - val_accuracy: 0.7725\n",
            "Epoch 330/1000\n",
            "4/4 [==============================] - 0s 112ms/step - loss: 0.1217 - accuracy: 0.8542 - val_loss: 0.2346 - val_accuracy: 0.7708\n",
            "Epoch 331/1000\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.1214 - accuracy: 0.8540 - val_loss: 0.2344 - val_accuracy: 0.7704\n",
            "Epoch 332/1000\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 0.1208 - accuracy: 0.8559 - val_loss: 0.2342 - val_accuracy: 0.7721\n",
            "Epoch 333/1000\n",
            "4/4 [==============================] - 0s 122ms/step - loss: 0.1202 - accuracy: 0.8561 - val_loss: 0.2342 - val_accuracy: 0.7718\n",
            "Epoch 334/1000\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.1208 - accuracy: 0.8554 - val_loss: 0.2335 - val_accuracy: 0.7736\n",
            "Epoch 335/1000\n",
            "4/4 [==============================] - 0s 120ms/step - loss: 0.1199 - accuracy: 0.8557 - val_loss: 0.2336 - val_accuracy: 0.7729\n",
            "Epoch 336/1000\n",
            "4/4 [==============================] - 1s 130ms/step - loss: 0.1198 - accuracy: 0.8554 - val_loss: 0.2342 - val_accuracy: 0.7724\n",
            "Epoch 337/1000\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.1193 - accuracy: 0.8557 - val_loss: 0.2342 - val_accuracy: 0.7735\n",
            "Epoch 338/1000\n",
            "4/4 [==============================] - 0s 131ms/step - loss: 0.1196 - accuracy: 0.8572 - val_loss: 0.2336 - val_accuracy: 0.7726\n",
            "Epoch 339/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 0.1195 - accuracy: 0.8566 - val_loss: 0.2332 - val_accuracy: 0.7727\n",
            "Epoch 340/1000\n",
            "4/4 [==============================] - 0s 127ms/step - loss: 0.1200 - accuracy: 0.8549 - val_loss: 0.2335 - val_accuracy: 0.7725\n",
            "Epoch 341/1000\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.1188 - accuracy: 0.8556 - val_loss: 0.2345 - val_accuracy: 0.7717\n",
            "Epoch 342/1000\n",
            "4/4 [==============================] - 0s 123ms/step - loss: 0.1186 - accuracy: 0.8581 - val_loss: 0.2339 - val_accuracy: 0.7727\n",
            "Epoch 343/1000\n",
            "4/4 [==============================] - 0s 124ms/step - loss: 0.1189 - accuracy: 0.8583 - val_loss: 0.2335 - val_accuracy: 0.7744\n",
            "Epoch 344/1000\n",
            "4/4 [==============================] - 0s 124ms/step - loss: 0.1191 - accuracy: 0.8555 - val_loss: 0.2337 - val_accuracy: 0.7738\n",
            "Epoch 345/1000\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 0.1177 - accuracy: 0.8559 - val_loss: 0.2335 - val_accuracy: 0.7736\n",
            "Epoch 346/1000\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.1174 - accuracy: 0.8591 - val_loss: 0.2337 - val_accuracy: 0.7728\n",
            "Epoch 347/1000\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.1181 - accuracy: 0.8583 - val_loss: 0.2338 - val_accuracy: 0.7721\n",
            "Epoch 348/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 0.1177 - accuracy: 0.8593 - val_loss: 0.2334 - val_accuracy: 0.7730\n",
            "Epoch 349/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 0.1174 - accuracy: 0.8583 - val_loss: 0.2333 - val_accuracy: 0.7739\n",
            "Epoch 350/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 0.1168 - accuracy: 0.8598 - val_loss: 0.2337 - val_accuracy: 0.7741\n",
            "Epoch 351/1000\n",
            "4/4 [==============================] - 0s 114ms/step - loss: 0.1173 - accuracy: 0.8586 - val_loss: 0.2337 - val_accuracy: 0.7721\n",
            "Epoch 352/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 0.1164 - accuracy: 0.8604 - val_loss: 0.2331 - val_accuracy: 0.7741\n",
            "Epoch 353/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 0.1160 - accuracy: 0.8609 - val_loss: 0.2336 - val_accuracy: 0.7730\n",
            "Epoch 354/1000\n",
            "4/4 [==============================] - 0s 123ms/step - loss: 0.1166 - accuracy: 0.8605 - val_loss: 0.2331 - val_accuracy: 0.7740\n",
            "Epoch 355/1000\n",
            "4/4 [==============================] - 0s 120ms/step - loss: 0.1164 - accuracy: 0.8596 - val_loss: 0.2333 - val_accuracy: 0.7742\n",
            "Epoch 356/1000\n",
            "4/4 [==============================] - 0s 114ms/step - loss: 0.1155 - accuracy: 0.8609 - val_loss: 0.2339 - val_accuracy: 0.7730\n",
            "Epoch 357/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 0.1163 - accuracy: 0.8598 - val_loss: 0.2330 - val_accuracy: 0.7755\n",
            "Epoch 358/1000\n",
            "4/4 [==============================] - 0s 112ms/step - loss: 0.1155 - accuracy: 0.8618 - val_loss: 0.2326 - val_accuracy: 0.7748\n",
            "Epoch 359/1000\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.1152 - accuracy: 0.8607 - val_loss: 0.2323 - val_accuracy: 0.7749\n",
            "Epoch 360/1000\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.1155 - accuracy: 0.8607 - val_loss: 0.2321 - val_accuracy: 0.7751\n",
            "Epoch 361/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 0.1158 - accuracy: 0.8593 - val_loss: 0.2330 - val_accuracy: 0.7736\n",
            "Epoch 362/1000\n",
            "4/4 [==============================] - 0s 122ms/step - loss: 0.1149 - accuracy: 0.8609 - val_loss: 0.2335 - val_accuracy: 0.7738\n",
            "Epoch 363/1000\n",
            "4/4 [==============================] - 0s 119ms/step - loss: 0.1146 - accuracy: 0.8625 - val_loss: 0.2338 - val_accuracy: 0.7728\n",
            "Epoch 364/1000\n",
            "4/4 [==============================] - 0s 125ms/step - loss: 0.1148 - accuracy: 0.8608 - val_loss: 0.2321 - val_accuracy: 0.7744\n",
            "Epoch 365/1000\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.1147 - accuracy: 0.8615 - val_loss: 0.2320 - val_accuracy: 0.7749\n",
            "Epoch 366/1000\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.1141 - accuracy: 0.8621 - val_loss: 0.2329 - val_accuracy: 0.7740\n",
            "Epoch 367/1000\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.1136 - accuracy: 0.8630 - val_loss: 0.2330 - val_accuracy: 0.7742\n",
            "Epoch 368/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 0.1134 - accuracy: 0.8649 - val_loss: 0.2330 - val_accuracy: 0.7736\n",
            "Epoch 369/1000\n",
            "4/4 [==============================] - 0s 113ms/step - loss: 0.1136 - accuracy: 0.8637 - val_loss: 0.2328 - val_accuracy: 0.7737\n",
            "Epoch 370/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 0.1131 - accuracy: 0.8638 - val_loss: 0.2326 - val_accuracy: 0.7735\n",
            "Epoch 371/1000\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.1123 - accuracy: 0.8642 - val_loss: 0.2325 - val_accuracy: 0.7733\n",
            "Epoch 372/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 0.1128 - accuracy: 0.8641 - val_loss: 0.2320 - val_accuracy: 0.7745\n",
            "Epoch 373/1000\n",
            "4/4 [==============================] - 1s 130ms/step - loss: 0.1126 - accuracy: 0.8640 - val_loss: 0.2318 - val_accuracy: 0.7738\n",
            "Epoch 374/1000\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 0.1127 - accuracy: 0.8646 - val_loss: 0.2322 - val_accuracy: 0.7739\n",
            "Epoch 375/1000\n",
            "4/4 [==============================] - 1s 126ms/step - loss: 0.1122 - accuracy: 0.8659 - val_loss: 0.2329 - val_accuracy: 0.7732\n",
            "Epoch 376/1000\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 0.1116 - accuracy: 0.8662 - val_loss: 0.2323 - val_accuracy: 0.7752\n",
            "Epoch 377/1000\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.1121 - accuracy: 0.8648 - val_loss: 0.2326 - val_accuracy: 0.7748\n",
            "Epoch 378/1000\n",
            "4/4 [==============================] - 1s 128ms/step - loss: 0.1117 - accuracy: 0.8657 - val_loss: 0.2333 - val_accuracy: 0.7728\n",
            "Epoch 379/1000\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.1111 - accuracy: 0.8657 - val_loss: 0.2326 - val_accuracy: 0.7738\n",
            "Epoch 380/1000\n",
            "4/4 [==============================] - 1s 127ms/step - loss: 0.1114 - accuracy: 0.8655 - val_loss: 0.2329 - val_accuracy: 0.7745\n",
            "Epoch 381/1000\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.1113 - accuracy: 0.8645 - val_loss: 0.2325 - val_accuracy: 0.7752\n",
            "Epoch 382/1000\n",
            "4/4 [==============================] - 1s 129ms/step - loss: 0.1117 - accuracy: 0.8646 - val_loss: 0.2319 - val_accuracy: 0.7755\n",
            "Epoch 383/1000\n",
            "4/4 [==============================] - 0s 111ms/step - loss: 0.1109 - accuracy: 0.8664 - val_loss: 0.2322 - val_accuracy: 0.7756\n",
            "Epoch 384/1000\n",
            "4/4 [==============================] - 0s 128ms/step - loss: 0.1107 - accuracy: 0.8660 - val_loss: 0.2320 - val_accuracy: 0.7755\n",
            "Epoch 385/1000\n",
            "4/4 [==============================] - 0s 134ms/step - loss: 0.1112 - accuracy: 0.8660 - val_loss: 0.2317 - val_accuracy: 0.7751\n",
            "Epoch 386/1000\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.1105 - accuracy: 0.8682 - val_loss: 0.2316 - val_accuracy: 0.7749\n",
            "Epoch 387/1000\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 0.1102 - accuracy: 0.8651 - val_loss: 0.2315 - val_accuracy: 0.7753\n",
            "Epoch 388/1000\n",
            "4/4 [==============================] - 1s 123ms/step - loss: 0.1096 - accuracy: 0.8675 - val_loss: 0.2322 - val_accuracy: 0.7745\n",
            "Epoch 389/1000\n",
            "4/4 [==============================] - 1s 127ms/step - loss: 0.1101 - accuracy: 0.8671 - val_loss: 0.2325 - val_accuracy: 0.7750\n",
            "Epoch 390/1000\n",
            "4/4 [==============================] - 0s 131ms/step - loss: 0.1094 - accuracy: 0.8689 - val_loss: 0.2324 - val_accuracy: 0.7752\n",
            "Epoch 391/1000\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 0.1089 - accuracy: 0.8680 - val_loss: 0.2319 - val_accuracy: 0.7750\n",
            "Epoch 392/1000\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 0.1105 - accuracy: 0.8659 - val_loss: 0.2318 - val_accuracy: 0.7754\n",
            "Epoch 393/1000\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.1087 - accuracy: 0.8673 - val_loss: 0.2319 - val_accuracy: 0.7751\n",
            "Epoch 394/1000\n",
            "4/4 [==============================] - 0s 128ms/step - loss: 0.1100 - accuracy: 0.8671 - val_loss: 0.2328 - val_accuracy: 0.7746\n",
            "Epoch 395/1000\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 0.1091 - accuracy: 0.8684 - val_loss: 0.2339 - val_accuracy: 0.7730\n",
            "Epoch 396/1000\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.1092 - accuracy: 0.8673 - val_loss: 0.2319 - val_accuracy: 0.7767\n",
            "Epoch 397/1000\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.1088 - accuracy: 0.8678 - val_loss: 0.2313 - val_accuracy: 0.7762\n",
            "Epoch 398/1000\n",
            "4/4 [==============================] - 0s 132ms/step - loss: 0.1082 - accuracy: 0.8682 - val_loss: 0.2315 - val_accuracy: 0.7756\n",
            "Epoch 399/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 0.1082 - accuracy: 0.8689 - val_loss: 0.2311 - val_accuracy: 0.7772\n",
            "Epoch 400/1000\n",
            "4/4 [==============================] - 1s 131ms/step - loss: 0.1078 - accuracy: 0.8697 - val_loss: 0.2310 - val_accuracy: 0.7771\n",
            "Epoch 401/1000\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.1083 - accuracy: 0.8681 - val_loss: 0.2309 - val_accuracy: 0.7764\n",
            "Epoch 402/1000\n",
            "4/4 [==============================] - 0s 129ms/step - loss: 0.1073 - accuracy: 0.8707 - val_loss: 0.2309 - val_accuracy: 0.7769\n",
            "Epoch 403/1000\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 0.1072 - accuracy: 0.8724 - val_loss: 0.2310 - val_accuracy: 0.7773\n",
            "Epoch 404/1000\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.1075 - accuracy: 0.8691 - val_loss: 0.2303 - val_accuracy: 0.7774\n",
            "Epoch 405/1000\n",
            "4/4 [==============================] - 0s 117ms/step - loss: 0.1067 - accuracy: 0.8725 - val_loss: 0.2301 - val_accuracy: 0.7776\n",
            "Epoch 406/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 0.1068 - accuracy: 0.8701 - val_loss: 0.2306 - val_accuracy: 0.7772\n",
            "Epoch 407/1000\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.1065 - accuracy: 0.8708 - val_loss: 0.2307 - val_accuracy: 0.7767\n",
            "Epoch 408/1000\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.1063 - accuracy: 0.8716 - val_loss: 0.2304 - val_accuracy: 0.7772\n",
            "Epoch 409/1000\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.1065 - accuracy: 0.8722 - val_loss: 0.2314 - val_accuracy: 0.7767\n",
            "Epoch 410/1000\n",
            "4/4 [==============================] - 0s 129ms/step - loss: 0.1058 - accuracy: 0.8731 - val_loss: 0.2317 - val_accuracy: 0.7770\n",
            "Epoch 411/1000\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.1063 - accuracy: 0.8724 - val_loss: 0.2306 - val_accuracy: 0.7758\n",
            "Epoch 412/1000\n",
            "4/4 [==============================] - 0s 130ms/step - loss: 0.1060 - accuracy: 0.8713 - val_loss: 0.2307 - val_accuracy: 0.7752\n",
            "Epoch 413/1000\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.1057 - accuracy: 0.8726 - val_loss: 0.2314 - val_accuracy: 0.7755\n",
            "Epoch 414/1000\n",
            "4/4 [==============================] - 0s 120ms/step - loss: 0.1058 - accuracy: 0.8712 - val_loss: 0.2317 - val_accuracy: 0.7763\n",
            "Epoch 415/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 0.1059 - accuracy: 0.8701 - val_loss: 0.2313 - val_accuracy: 0.7772\n",
            "Epoch 416/1000\n",
            "4/4 [==============================] - 0s 126ms/step - loss: 0.1051 - accuracy: 0.8714 - val_loss: 0.2311 - val_accuracy: 0.7764\n",
            "Epoch 417/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 0.1054 - accuracy: 0.8722 - val_loss: 0.2316 - val_accuracy: 0.7766\n",
            "Epoch 418/1000\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 0.1045 - accuracy: 0.8738 - val_loss: 0.2315 - val_accuracy: 0.7762\n",
            "Epoch 419/1000\n",
            "4/4 [==============================] - 1s 123ms/step - loss: 0.1048 - accuracy: 0.8748 - val_loss: 0.2312 - val_accuracy: 0.7767\n",
            "Epoch 420/1000\n",
            "4/4 [==============================] - 0s 124ms/step - loss: 0.1043 - accuracy: 0.8735 - val_loss: 0.2301 - val_accuracy: 0.7772\n",
            "Epoch 421/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 0.1051 - accuracy: 0.8735 - val_loss: 0.2301 - val_accuracy: 0.7777\n",
            "Epoch 422/1000\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 0.1040 - accuracy: 0.8754 - val_loss: 0.2311 - val_accuracy: 0.7761\n",
            "Epoch 423/1000\n",
            "4/4 [==============================] - 0s 120ms/step - loss: 0.1039 - accuracy: 0.8736 - val_loss: 0.2313 - val_accuracy: 0.7767\n",
            "Epoch 424/1000\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 0.1041 - accuracy: 0.8741 - val_loss: 0.2307 - val_accuracy: 0.7777\n",
            "Epoch 425/1000\n",
            "4/4 [==============================] - 0s 128ms/step - loss: 0.1041 - accuracy: 0.8733 - val_loss: 0.2302 - val_accuracy: 0.7784\n",
            "Epoch 426/1000\n",
            "4/4 [==============================] - 1s 130ms/step - loss: 0.1041 - accuracy: 0.8740 - val_loss: 0.2299 - val_accuracy: 0.7780\n",
            "Epoch 427/1000\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.1036 - accuracy: 0.8745 - val_loss: 0.2298 - val_accuracy: 0.7781\n",
            "Epoch 428/1000\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.1025 - accuracy: 0.8766 - val_loss: 0.2301 - val_accuracy: 0.7780\n",
            "Epoch 429/1000\n",
            "4/4 [==============================] - 0s 125ms/step - loss: 0.1025 - accuracy: 0.8750 - val_loss: 0.2298 - val_accuracy: 0.7782\n",
            "Epoch 430/1000\n",
            "4/4 [==============================] - 0s 118ms/step - loss: 0.1035 - accuracy: 0.8744 - val_loss: 0.2300 - val_accuracy: 0.7781\n",
            "Epoch 431/1000\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 0.1021 - accuracy: 0.8773 - val_loss: 0.2302 - val_accuracy: 0.7788\n",
            "Epoch 432/1000\n",
            "4/4 [==============================] - 0s 121ms/step - loss: 0.1022 - accuracy: 0.8779 - val_loss: 0.2300 - val_accuracy: 0.7788\n",
            "Epoch 433/1000\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.1031 - accuracy: 0.8745 - val_loss: 0.2300 - val_accuracy: 0.7795\n",
            "Epoch 434/1000\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.1016 - accuracy: 0.8765 - val_loss: 0.2303 - val_accuracy: 0.7793\n",
            "Epoch 435/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 0.1019 - accuracy: 0.8773 - val_loss: 0.2307 - val_accuracy: 0.7785\n",
            "Epoch 436/1000\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.1021 - accuracy: 0.8764 - val_loss: 0.2305 - val_accuracy: 0.7783\n",
            "Epoch 437/1000\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.1017 - accuracy: 0.8772 - val_loss: 0.2307 - val_accuracy: 0.7789\n",
            "Epoch 438/1000\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.1014 - accuracy: 0.8784 - val_loss: 0.2308 - val_accuracy: 0.7785\n",
            "Epoch 439/1000\n",
            "4/4 [==============================] - 0s 111ms/step - loss: 0.1021 - accuracy: 0.8761 - val_loss: 0.2301 - val_accuracy: 0.7788\n",
            "Epoch 440/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 0.1016 - accuracy: 0.8764 - val_loss: 0.2303 - val_accuracy: 0.7789\n",
            "Epoch 441/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 0.1017 - accuracy: 0.8773 - val_loss: 0.2307 - val_accuracy: 0.7797\n",
            "Epoch 442/1000\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.1005 - accuracy: 0.8787 - val_loss: 0.2310 - val_accuracy: 0.7788\n",
            "Epoch 443/1000\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.1006 - accuracy: 0.8791 - val_loss: 0.2304 - val_accuracy: 0.7792\n",
            "Epoch 444/1000\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.1010 - accuracy: 0.8769 - val_loss: 0.2300 - val_accuracy: 0.7798\n",
            "Training completed! Showing history...\n",
            "Displaying the following history keys:  dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXTD79UsQ51Z"
      },
      "source": [
        "##Additional LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Compile"
      ],
      "metadata": {
        "id": "skBamOnKBgux"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JgxTjbdQ9Pe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "533f36ac-cea2-4815-eea0-d31e4d22696e"
      },
      "source": [
        "two_LSTM = Sequential()\n",
        "\n",
        "# Embedding layer\n",
        "two_LSTM.add(Embedding(input_dim = vocab_size,\n",
        "              input_length = max_seq_length,\n",
        "              output_dim=embedding_dimension,\n",
        "              weights = embedding_matrix if embedding_matrix is None else [embedding_matrix],\n",
        "              trainable=False,\n",
        "              mask_zero=True))\n",
        "\n",
        "# Bidirectional layers\n",
        "two_LSTM.add(Bidirectional(LSTM(64, return_sequences=True \n",
        "               ,dropout=0.1\n",
        "               )))         \n",
        "two_LSTM.add(Bidirectional(LSTM(32, return_sequences=True \n",
        "               ,dropout=0.1\n",
        "               )))              \n",
        "\n",
        "# Dense layer\n",
        "\n",
        "two_LSTM.add(TimeDistributed(Dense(num_classes,\n",
        "            activation= 'softmax')))\n",
        "\n",
        "# Compile the model\n",
        "two_LSTM.compile(\n",
        "    optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "two_LSTM.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 1897, 200)         2189800   \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 1897, 128)        135680    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 1897, 64)         41216     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDis  (None, 1897, 46)         2990      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,369,686\n",
            "Trainable params: 179,886\n",
            "Non-trainable params: 2,189,800\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDyRtRjGswvI"
      },
      "source": [
        "###Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoviWkLTs3Da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4b32877e-3100-474e-8e1c-7bc54d1798a5"
      },
      "source": [
        "# Training\n",
        "\n",
        "training_info = {\n",
        "    'verbose': 1,\n",
        "    'epochs': 1000,\n",
        "    'batch_size': 32,\n",
        "    'callbacks': [keras.callbacks.EarlyStopping(monitor='val_loss', \n",
        "                                                patience=15,\n",
        "                                                restore_best_weights=True)]\n",
        "}\n",
        "two_LSTM = train_model(model=two_LSTM, x_train=x_train, y_train=y_train,\n",
        "                    x_val=x_val, y_val=y_val, training_info=training_info)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training! \n",
            "Parameters: {'verbose': 1, 'epochs': 1000, 'batch_size': 32, 'callbacks': [<keras.callbacks.EarlyStopping object at 0x000001DCECC0B820>]}\n",
            "Train size: 100\n",
            "Val size: 50\n",
            "Epoch 1/1000\n",
            "4/4 [==============================] - 16s 2s/step - loss: 0.9138 - accuracy: 0.0532 - val_loss: 1.0685 - val_accuracy: 0.0854\n",
            "Epoch 2/1000\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 0.8510 - accuracy: 0.1087 - val_loss: 1.0145 - val_accuracy: 0.1106\n",
            "Epoch 3/1000\n",
            "4/4 [==============================] - 2s 488ms/step - loss: 0.8119 - accuracy: 0.1095 - val_loss: 0.9798 - val_accuracy: 0.1074\n",
            "Epoch 4/1000\n",
            "4/4 [==============================] - 2s 470ms/step - loss: 0.7856 - accuracy: 0.1082 - val_loss: 0.9538 - val_accuracy: 0.1178\n",
            "Epoch 5/1000\n",
            "4/4 [==============================] - 2s 439ms/step - loss: 0.7662 - accuracy: 0.1396 - val_loss: 0.9346 - val_accuracy: 0.1637\n",
            "Epoch 6/1000\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 0.7521 - accuracy: 0.1410 - val_loss: 0.9208 - val_accuracy: 0.1462\n",
            "Epoch 7/1000\n",
            "4/4 [==============================] - 2s 445ms/step - loss: 0.7421 - accuracy: 0.1351 - val_loss: 0.9099 - val_accuracy: 0.1465\n",
            "Epoch 8/1000\n",
            "4/4 [==============================] - 2s 472ms/step - loss: 0.7346 - accuracy: 0.1356 - val_loss: 0.9009 - val_accuracy: 0.1466\n",
            "Epoch 9/1000\n",
            "4/4 [==============================] - 2s 468ms/step - loss: 0.7282 - accuracy: 0.1357 - val_loss: 0.8947 - val_accuracy: 0.1464\n",
            "Epoch 10/1000\n",
            "4/4 [==============================] - 2s 427ms/step - loss: 0.7229 - accuracy: 0.1356 - val_loss: 0.8880 - val_accuracy: 0.1493\n",
            "Epoch 11/1000\n",
            "4/4 [==============================] - 2s 521ms/step - loss: 0.7168 - accuracy: 0.1412 - val_loss: 0.8801 - val_accuracy: 0.1681\n",
            "Epoch 12/1000\n",
            "4/4 [==============================] - 2s 507ms/step - loss: 0.7093 - accuracy: 0.1786 - val_loss: 0.8715 - val_accuracy: 0.2187\n",
            "Epoch 13/1000\n",
            "4/4 [==============================] - 2s 504ms/step - loss: 0.7022 - accuracy: 0.2204 - val_loss: 0.8611 - val_accuracy: 0.2343\n",
            "Epoch 14/1000\n",
            "4/4 [==============================] - 2s 428ms/step - loss: 0.6939 - accuracy: 0.2326 - val_loss: 0.8505 - val_accuracy: 0.2707\n",
            "Epoch 15/1000\n",
            "4/4 [==============================] - 2s 474ms/step - loss: 0.6850 - accuracy: 0.2825 - val_loss: 0.8398 - val_accuracy: 0.3054\n",
            "Epoch 16/1000\n",
            "4/4 [==============================] - 2s 523ms/step - loss: 0.6749 - accuracy: 0.3173 - val_loss: 0.8260 - val_accuracy: 0.3249\n",
            "Epoch 17/1000\n",
            "4/4 [==============================] - 2s 452ms/step - loss: 0.6636 - accuracy: 0.3331 - val_loss: 0.8110 - val_accuracy: 0.3287\n",
            "Epoch 18/1000\n",
            "4/4 [==============================] - 2s 448ms/step - loss: 0.6517 - accuracy: 0.3398 - val_loss: 0.7957 - val_accuracy: 0.3411\n",
            "Epoch 19/1000\n",
            "4/4 [==============================] - 2s 424ms/step - loss: 0.6391 - accuracy: 0.3538 - val_loss: 0.7803 - val_accuracy: 0.3561\n",
            "Epoch 20/1000\n",
            "4/4 [==============================] - 2s 467ms/step - loss: 0.6252 - accuracy: 0.3707 - val_loss: 0.7637 - val_accuracy: 0.3822\n",
            "Epoch 21/1000\n",
            "4/4 [==============================] - 2s 438ms/step - loss: 0.6126 - accuracy: 0.3878 - val_loss: 0.7479 - val_accuracy: 0.3708\n",
            "Epoch 22/1000\n",
            "4/4 [==============================] - 2s 486ms/step - loss: 0.5985 - accuracy: 0.3867 - val_loss: 0.7296 - val_accuracy: 0.3936\n",
            "Epoch 23/1000\n",
            "4/4 [==============================] - 2s 504ms/step - loss: 0.5847 - accuracy: 0.4011 - val_loss: 0.7133 - val_accuracy: 0.3870\n",
            "Epoch 24/1000\n",
            "4/4 [==============================] - 2s 492ms/step - loss: 0.5698 - accuracy: 0.4044 - val_loss: 0.6947 - val_accuracy: 0.3990\n",
            "Epoch 25/1000\n",
            "4/4 [==============================] - 2s 440ms/step - loss: 0.5561 - accuracy: 0.4099 - val_loss: 0.6789 - val_accuracy: 0.4035\n",
            "Epoch 26/1000\n",
            "4/4 [==============================] - 2s 463ms/step - loss: 0.5422 - accuracy: 0.4194 - val_loss: 0.6608 - val_accuracy: 0.4203\n",
            "Epoch 27/1000\n",
            "4/4 [==============================] - 2s 482ms/step - loss: 0.5287 - accuracy: 0.4327 - val_loss: 0.6467 - val_accuracy: 0.4308\n",
            "Epoch 28/1000\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 0.5154 - accuracy: 0.4446 - val_loss: 0.6303 - val_accuracy: 0.4402\n",
            "Epoch 29/1000\n",
            "4/4 [==============================] - 2s 520ms/step - loss: 0.5039 - accuracy: 0.4491 - val_loss: 0.6164 - val_accuracy: 0.4417\n",
            "Epoch 30/1000\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.4916 - accuracy: 0.4549 - val_loss: 0.6027 - val_accuracy: 0.4558\n",
            "Epoch 31/1000\n",
            "4/4 [==============================] - 2s 450ms/step - loss: 0.4819 - accuracy: 0.4614 - val_loss: 0.5914 - val_accuracy: 0.4682\n",
            "Epoch 32/1000\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.4712 - accuracy: 0.4779 - val_loss: 0.5801 - val_accuracy: 0.4740\n",
            "Epoch 33/1000\n",
            "4/4 [==============================] - 2s 470ms/step - loss: 0.4619 - accuracy: 0.4834 - val_loss: 0.5692 - val_accuracy: 0.4814\n",
            "Epoch 34/1000\n",
            "4/4 [==============================] - 2s 411ms/step - loss: 0.4532 - accuracy: 0.4916 - val_loss: 0.5598 - val_accuracy: 0.4942\n",
            "Epoch 35/1000\n",
            "4/4 [==============================] - 2s 502ms/step - loss: 0.4452 - accuracy: 0.5062 - val_loss: 0.5506 - val_accuracy: 0.5051\n",
            "Epoch 36/1000\n",
            "4/4 [==============================] - 2s 487ms/step - loss: 0.4384 - accuracy: 0.5152 - val_loss: 0.5424 - val_accuracy: 0.5080\n",
            "Epoch 37/1000\n",
            "4/4 [==============================] - 2s 520ms/step - loss: 0.4309 - accuracy: 0.5193 - val_loss: 0.5341 - val_accuracy: 0.5140\n",
            "Epoch 38/1000\n",
            "4/4 [==============================] - 2s 448ms/step - loss: 0.4244 - accuracy: 0.5277 - val_loss: 0.5269 - val_accuracy: 0.5232\n",
            "Epoch 39/1000\n",
            "4/4 [==============================] - 2s 465ms/step - loss: 0.4181 - accuracy: 0.5360 - val_loss: 0.5204 - val_accuracy: 0.5226\n",
            "Epoch 40/1000\n",
            "4/4 [==============================] - 2s 429ms/step - loss: 0.4123 - accuracy: 0.5379 - val_loss: 0.5121 - val_accuracy: 0.5269\n",
            "Epoch 41/1000\n",
            "4/4 [==============================] - 2s 491ms/step - loss: 0.4060 - accuracy: 0.5418 - val_loss: 0.5053 - val_accuracy: 0.5346\n",
            "Epoch 42/1000\n",
            "4/4 [==============================] - 2s 463ms/step - loss: 0.4005 - accuracy: 0.5496 - val_loss: 0.4998 - val_accuracy: 0.5436\n",
            "Epoch 43/1000\n",
            "4/4 [==============================] - 2s 524ms/step - loss: 0.3952 - accuracy: 0.5591 - val_loss: 0.4933 - val_accuracy: 0.5467\n",
            "Epoch 44/1000\n",
            "4/4 [==============================] - 2s 440ms/step - loss: 0.3899 - accuracy: 0.5605 - val_loss: 0.4876 - val_accuracy: 0.5470\n",
            "Epoch 45/1000\n",
            "4/4 [==============================] - 2s 492ms/step - loss: 0.3852 - accuracy: 0.5634 - val_loss: 0.4819 - val_accuracy: 0.5554\n",
            "Epoch 46/1000\n",
            "4/4 [==============================] - 2s 461ms/step - loss: 0.3802 - accuracy: 0.5726 - val_loss: 0.4767 - val_accuracy: 0.5608\n",
            "Epoch 47/1000\n",
            "4/4 [==============================] - 2s 481ms/step - loss: 0.3754 - accuracy: 0.5768 - val_loss: 0.4707 - val_accuracy: 0.5647\n",
            "Epoch 48/1000\n",
            "4/4 [==============================] - 2s 430ms/step - loss: 0.3709 - accuracy: 0.5811 - val_loss: 0.4656 - val_accuracy: 0.5707\n",
            "Epoch 49/1000\n",
            "4/4 [==============================] - 2s 515ms/step - loss: 0.3667 - accuracy: 0.5879 - val_loss: 0.4604 - val_accuracy: 0.5763\n",
            "Epoch 50/1000\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 0.3621 - accuracy: 0.5931 - val_loss: 0.4567 - val_accuracy: 0.5783\n",
            "Epoch 51/1000\n",
            "4/4 [==============================] - 2s 521ms/step - loss: 0.3584 - accuracy: 0.5965 - val_loss: 0.4513 - val_accuracy: 0.5806\n",
            "Epoch 52/1000\n",
            "4/4 [==============================] - 2s 475ms/step - loss: 0.3537 - accuracy: 0.6015 - val_loss: 0.4468 - val_accuracy: 0.5862\n",
            "Epoch 53/1000\n",
            "4/4 [==============================] - 2s 450ms/step - loss: 0.3500 - accuracy: 0.6075 - val_loss: 0.4422 - val_accuracy: 0.5905\n",
            "Epoch 54/1000\n",
            "4/4 [==============================] - 2s 483ms/step - loss: 0.3459 - accuracy: 0.6119 - val_loss: 0.4380 - val_accuracy: 0.5957\n",
            "Epoch 55/1000\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.3426 - accuracy: 0.6162 - val_loss: 0.4335 - val_accuracy: 0.5965\n",
            "Epoch 56/1000\n",
            "4/4 [==============================] - 2s 499ms/step - loss: 0.3388 - accuracy: 0.6165 - val_loss: 0.4299 - val_accuracy: 0.5996\n",
            "Epoch 57/1000\n",
            "4/4 [==============================] - 2s 449ms/step - loss: 0.3361 - accuracy: 0.6208 - val_loss: 0.4262 - val_accuracy: 0.6037\n",
            "Epoch 58/1000\n",
            "4/4 [==============================] - 2s 409ms/step - loss: 0.3324 - accuracy: 0.6234 - val_loss: 0.4219 - val_accuracy: 0.6074\n",
            "Epoch 59/1000\n",
            "4/4 [==============================] - 2s 485ms/step - loss: 0.3287 - accuracy: 0.6277 - val_loss: 0.4170 - val_accuracy: 0.6118\n",
            "Epoch 60/1000\n",
            "4/4 [==============================] - 2s 498ms/step - loss: 0.3249 - accuracy: 0.6327 - val_loss: 0.4134 - val_accuracy: 0.6148\n",
            "Epoch 61/1000\n",
            "4/4 [==============================] - 2s 426ms/step - loss: 0.3220 - accuracy: 0.6339 - val_loss: 0.4104 - val_accuracy: 0.6159\n",
            "Epoch 62/1000\n",
            "4/4 [==============================] - 2s 482ms/step - loss: 0.3186 - accuracy: 0.6387 - val_loss: 0.4071 - val_accuracy: 0.6224\n",
            "Epoch 63/1000\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 0.3157 - accuracy: 0.6441 - val_loss: 0.4036 - val_accuracy: 0.6247\n",
            "Epoch 64/1000\n",
            "4/4 [==============================] - 2s 517ms/step - loss: 0.3132 - accuracy: 0.6452 - val_loss: 0.4008 - val_accuracy: 0.6262\n",
            "Epoch 65/1000\n",
            "4/4 [==============================] - 2s 512ms/step - loss: 0.3101 - accuracy: 0.6498 - val_loss: 0.3979 - val_accuracy: 0.6294\n",
            "Epoch 66/1000\n",
            "4/4 [==============================] - 2s 449ms/step - loss: 0.3077 - accuracy: 0.6519 - val_loss: 0.3947 - val_accuracy: 0.6285\n",
            "Epoch 67/1000\n",
            "4/4 [==============================] - 2s 472ms/step - loss: 0.3040 - accuracy: 0.6523 - val_loss: 0.3902 - val_accuracy: 0.6351\n",
            "Epoch 68/1000\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 0.3016 - accuracy: 0.6595 - val_loss: 0.3878 - val_accuracy: 0.6373\n",
            "Epoch 69/1000\n",
            "4/4 [==============================] - 2s 486ms/step - loss: 0.2995 - accuracy: 0.6625 - val_loss: 0.3850 - val_accuracy: 0.6402\n",
            "Epoch 70/1000\n",
            "4/4 [==============================] - 2s 487ms/step - loss: 0.2960 - accuracy: 0.6658 - val_loss: 0.3822 - val_accuracy: 0.6415\n",
            "Epoch 71/1000\n",
            "4/4 [==============================] - 2s 447ms/step - loss: 0.2933 - accuracy: 0.6665 - val_loss: 0.3781 - val_accuracy: 0.6462\n",
            "Epoch 72/1000\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 0.2906 - accuracy: 0.6716 - val_loss: 0.3761 - val_accuracy: 0.6453\n",
            "Epoch 73/1000\n",
            "4/4 [==============================] - 2s 503ms/step - loss: 0.2883 - accuracy: 0.6710 - val_loss: 0.3742 - val_accuracy: 0.6481\n",
            "Epoch 74/1000\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 0.2866 - accuracy: 0.6725 - val_loss: 0.3704 - val_accuracy: 0.6520\n",
            "Epoch 75/1000\n",
            "4/4 [==============================] - 2s 469ms/step - loss: 0.2840 - accuracy: 0.6787 - val_loss: 0.3683 - val_accuracy: 0.6516\n",
            "Epoch 76/1000\n",
            "4/4 [==============================] - 2s 440ms/step - loss: 0.2812 - accuracy: 0.6799 - val_loss: 0.3657 - val_accuracy: 0.6531\n",
            "Epoch 77/1000\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 0.2788 - accuracy: 0.6838 - val_loss: 0.3625 - val_accuracy: 0.6579\n",
            "Epoch 78/1000\n",
            "4/4 [==============================] - 2s 449ms/step - loss: 0.2767 - accuracy: 0.6854 - val_loss: 0.3613 - val_accuracy: 0.6558\n",
            "Epoch 79/1000\n",
            "4/4 [==============================] - 2s 523ms/step - loss: 0.2747 - accuracy: 0.6871 - val_loss: 0.3573 - val_accuracy: 0.6616\n",
            "Epoch 80/1000\n",
            "4/4 [==============================] - 2s 448ms/step - loss: 0.2720 - accuracy: 0.6897 - val_loss: 0.3548 - val_accuracy: 0.6642\n",
            "Epoch 81/1000\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 0.2696 - accuracy: 0.6928 - val_loss: 0.3529 - val_accuracy: 0.6648\n",
            "Epoch 82/1000\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.2676 - accuracy: 0.6935 - val_loss: 0.3504 - val_accuracy: 0.6658\n",
            "Epoch 83/1000\n",
            "4/4 [==============================] - 2s 499ms/step - loss: 0.2656 - accuracy: 0.6962 - val_loss: 0.3486 - val_accuracy: 0.6669\n",
            "Epoch 84/1000\n",
            "4/4 [==============================] - 2s 418ms/step - loss: 0.2638 - accuracy: 0.6991 - val_loss: 0.3462 - val_accuracy: 0.6723\n",
            "Epoch 85/1000\n",
            "4/4 [==============================] - 2s 474ms/step - loss: 0.2621 - accuracy: 0.7025 - val_loss: 0.3435 - val_accuracy: 0.6725\n",
            "Epoch 86/1000\n",
            "4/4 [==============================] - 2s 407ms/step - loss: 0.2591 - accuracy: 0.7043 - val_loss: 0.3419 - val_accuracy: 0.6722\n",
            "Epoch 87/1000\n",
            "4/4 [==============================] - 2s 485ms/step - loss: 0.2576 - accuracy: 0.7035 - val_loss: 0.3394 - val_accuracy: 0.6763\n",
            "Epoch 88/1000\n",
            "4/4 [==============================] - 2s 493ms/step - loss: 0.2555 - accuracy: 0.7097 - val_loss: 0.3370 - val_accuracy: 0.6773\n",
            "Epoch 89/1000\n",
            "4/4 [==============================] - 2s 445ms/step - loss: 0.2539 - accuracy: 0.7072 - val_loss: 0.3358 - val_accuracy: 0.6775\n",
            "Epoch 90/1000\n",
            "4/4 [==============================] - 2s 478ms/step - loss: 0.2520 - accuracy: 0.7095 - val_loss: 0.3338 - val_accuracy: 0.6818\n",
            "Epoch 91/1000\n",
            "4/4 [==============================] - 2s 486ms/step - loss: 0.2498 - accuracy: 0.7166 - val_loss: 0.3311 - val_accuracy: 0.6827\n",
            "Epoch 92/1000\n",
            "4/4 [==============================] - 2s 501ms/step - loss: 0.2481 - accuracy: 0.7158 - val_loss: 0.3289 - val_accuracy: 0.6850\n",
            "Epoch 93/1000\n",
            "4/4 [==============================] - 2s 510ms/step - loss: 0.2457 - accuracy: 0.7184 - val_loss: 0.3281 - val_accuracy: 0.6868\n",
            "Epoch 94/1000\n",
            "4/4 [==============================] - 2s 450ms/step - loss: 0.2445 - accuracy: 0.7217 - val_loss: 0.3254 - val_accuracy: 0.6864\n",
            "Epoch 95/1000\n",
            "4/4 [==============================] - 2s 482ms/step - loss: 0.2436 - accuracy: 0.7185 - val_loss: 0.3226 - val_accuracy: 0.6892\n",
            "Epoch 96/1000\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 0.2407 - accuracy: 0.7259 - val_loss: 0.3213 - val_accuracy: 0.6935\n",
            "Epoch 97/1000\n",
            "4/4 [==============================] - 2s 496ms/step - loss: 0.2392 - accuracy: 0.7258 - val_loss: 0.3214 - val_accuracy: 0.6891\n",
            "Epoch 98/1000\n",
            "4/4 [==============================] - 2s 502ms/step - loss: 0.2371 - accuracy: 0.7270 - val_loss: 0.3179 - val_accuracy: 0.6969\n",
            "Epoch 99/1000\n",
            "4/4 [==============================] - 2s 483ms/step - loss: 0.2360 - accuracy: 0.7287 - val_loss: 0.3160 - val_accuracy: 0.6970\n",
            "Epoch 100/1000\n",
            "4/4 [==============================] - 2s 493ms/step - loss: 0.2333 - accuracy: 0.7321 - val_loss: 0.3153 - val_accuracy: 0.6958\n",
            "Epoch 101/1000\n",
            "4/4 [==============================] - 2s 492ms/step - loss: 0.2322 - accuracy: 0.7307 - val_loss: 0.3128 - val_accuracy: 0.6986\n",
            "Epoch 102/1000\n",
            "4/4 [==============================] - 2s 461ms/step - loss: 0.2306 - accuracy: 0.7353 - val_loss: 0.3108 - val_accuracy: 0.7034\n",
            "Epoch 103/1000\n",
            "4/4 [==============================] - 2s 471ms/step - loss: 0.2285 - accuracy: 0.7382 - val_loss: 0.3094 - val_accuracy: 0.7009\n",
            "Epoch 104/1000\n",
            "4/4 [==============================] - 2s 429ms/step - loss: 0.2272 - accuracy: 0.7401 - val_loss: 0.3065 - val_accuracy: 0.7051\n",
            "Epoch 105/1000\n",
            "4/4 [==============================] - 2s 516ms/step - loss: 0.2254 - accuracy: 0.7389 - val_loss: 0.3060 - val_accuracy: 0.7060\n",
            "Epoch 106/1000\n",
            "4/4 [==============================] - 2s 442ms/step - loss: 0.2235 - accuracy: 0.7447 - val_loss: 0.3053 - val_accuracy: 0.7044\n",
            "Epoch 107/1000\n",
            "4/4 [==============================] - 2s 504ms/step - loss: 0.2225 - accuracy: 0.7434 - val_loss: 0.3018 - val_accuracy: 0.7104\n",
            "Epoch 108/1000\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 0.2202 - accuracy: 0.7454 - val_loss: 0.3010 - val_accuracy: 0.7112\n",
            "Epoch 109/1000\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 0.2189 - accuracy: 0.7485 - val_loss: 0.2992 - val_accuracy: 0.7123\n",
            "Epoch 110/1000\n",
            "4/4 [==============================] - 2s 491ms/step - loss: 0.2175 - accuracy: 0.7529 - val_loss: 0.2974 - val_accuracy: 0.7145\n",
            "Epoch 111/1000\n",
            "4/4 [==============================] - 2s 436ms/step - loss: 0.2159 - accuracy: 0.7542 - val_loss: 0.2959 - val_accuracy: 0.7156\n",
            "Epoch 112/1000\n",
            "4/4 [==============================] - 2s 502ms/step - loss: 0.2145 - accuracy: 0.7536 - val_loss: 0.2946 - val_accuracy: 0.7160\n",
            "Epoch 113/1000\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 0.2130 - accuracy: 0.7567 - val_loss: 0.2939 - val_accuracy: 0.7164\n",
            "Epoch 114/1000\n",
            "4/4 [==============================] - 2s 452ms/step - loss: 0.2119 - accuracy: 0.7567 - val_loss: 0.2924 - val_accuracy: 0.7179\n",
            "Epoch 115/1000\n",
            "4/4 [==============================] - 2s 520ms/step - loss: 0.2094 - accuracy: 0.7592 - val_loss: 0.2903 - val_accuracy: 0.7197\n",
            "Epoch 116/1000\n",
            "4/4 [==============================] - 2s 467ms/step - loss: 0.2089 - accuracy: 0.7601 - val_loss: 0.2900 - val_accuracy: 0.7203\n",
            "Epoch 117/1000\n",
            "4/4 [==============================] - 2s 492ms/step - loss: 0.2068 - accuracy: 0.7627 - val_loss: 0.2889 - val_accuracy: 0.7227\n",
            "Epoch 118/1000\n",
            "4/4 [==============================] - 2s 429ms/step - loss: 0.2064 - accuracy: 0.7645 - val_loss: 0.2864 - val_accuracy: 0.7221\n",
            "Epoch 119/1000\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 0.2053 - accuracy: 0.7634 - val_loss: 0.2868 - val_accuracy: 0.7233\n",
            "Epoch 120/1000\n",
            "4/4 [==============================] - 2s 462ms/step - loss: 0.2039 - accuracy: 0.7657 - val_loss: 0.2838 - val_accuracy: 0.7261\n",
            "Epoch 121/1000\n",
            "4/4 [==============================] - 2s 499ms/step - loss: 0.2023 - accuracy: 0.7677 - val_loss: 0.2841 - val_accuracy: 0.7246\n",
            "Epoch 122/1000\n",
            "4/4 [==============================] - 2s 492ms/step - loss: 0.2011 - accuracy: 0.7676 - val_loss: 0.2844 - val_accuracy: 0.7279\n",
            "Epoch 123/1000\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 0.1999 - accuracy: 0.7715 - val_loss: 0.2794 - val_accuracy: 0.7293\n",
            "Epoch 124/1000\n",
            "4/4 [==============================] - 2s 481ms/step - loss: 0.1980 - accuracy: 0.7712 - val_loss: 0.2805 - val_accuracy: 0.7274\n",
            "Epoch 125/1000\n",
            "4/4 [==============================] - 2s 446ms/step - loss: 0.1988 - accuracy: 0.7703 - val_loss: 0.2802 - val_accuracy: 0.7308\n",
            "Epoch 126/1000\n",
            "4/4 [==============================] - 2s 489ms/step - loss: 0.1968 - accuracy: 0.7752 - val_loss: 0.2776 - val_accuracy: 0.7304\n",
            "Epoch 127/1000\n",
            "4/4 [==============================] - 2s 470ms/step - loss: 0.1948 - accuracy: 0.7761 - val_loss: 0.2764 - val_accuracy: 0.7337\n",
            "Epoch 128/1000\n",
            "4/4 [==============================] - 2s 462ms/step - loss: 0.1928 - accuracy: 0.7785 - val_loss: 0.2730 - val_accuracy: 0.7345\n",
            "Epoch 129/1000\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.1918 - accuracy: 0.7792 - val_loss: 0.2721 - val_accuracy: 0.7374\n",
            "Epoch 130/1000\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 0.1904 - accuracy: 0.7813 - val_loss: 0.2724 - val_accuracy: 0.7367\n",
            "Epoch 131/1000\n",
            "4/4 [==============================] - 2s 462ms/step - loss: 0.1901 - accuracy: 0.7809 - val_loss: 0.2731 - val_accuracy: 0.7333\n",
            "Epoch 132/1000\n",
            "4/4 [==============================] - 2s 511ms/step - loss: 0.1889 - accuracy: 0.7817 - val_loss: 0.2698 - val_accuracy: 0.7392\n",
            "Epoch 133/1000\n",
            "4/4 [==============================] - 2s 451ms/step - loss: 0.1870 - accuracy: 0.7866 - val_loss: 0.2680 - val_accuracy: 0.7387\n",
            "Epoch 134/1000\n",
            "4/4 [==============================] - 2s 521ms/step - loss: 0.1861 - accuracy: 0.7858 - val_loss: 0.2675 - val_accuracy: 0.7391\n",
            "Epoch 135/1000\n",
            "4/4 [==============================] - 2s 438ms/step - loss: 0.1848 - accuracy: 0.7867 - val_loss: 0.2674 - val_accuracy: 0.7410\n",
            "Epoch 136/1000\n",
            "4/4 [==============================] - 2s 431ms/step - loss: 0.1837 - accuracy: 0.7883 - val_loss: 0.2658 - val_accuracy: 0.7398\n",
            "Epoch 137/1000\n",
            "4/4 [==============================] - 2s 462ms/step - loss: 0.1831 - accuracy: 0.7876 - val_loss: 0.2647 - val_accuracy: 0.7428\n",
            "Epoch 138/1000\n",
            "4/4 [==============================] - 2s 405ms/step - loss: 0.1815 - accuracy: 0.7900 - val_loss: 0.2636 - val_accuracy: 0.7444\n",
            "Epoch 139/1000\n",
            "4/4 [==============================] - 2s 497ms/step - loss: 0.1802 - accuracy: 0.7930 - val_loss: 0.2622 - val_accuracy: 0.7450\n",
            "Epoch 140/1000\n",
            "4/4 [==============================] - 2s 517ms/step - loss: 0.1797 - accuracy: 0.7932 - val_loss: 0.2620 - val_accuracy: 0.7448\n",
            "Epoch 141/1000\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 0.1785 - accuracy: 0.7943 - val_loss: 0.2606 - val_accuracy: 0.7467\n",
            "Epoch 142/1000\n",
            "4/4 [==============================] - 2s 483ms/step - loss: 0.1776 - accuracy: 0.7950 - val_loss: 0.2600 - val_accuracy: 0.7471\n",
            "Epoch 143/1000\n",
            "4/4 [==============================] - 2s 505ms/step - loss: 0.1763 - accuracy: 0.7986 - val_loss: 0.2590 - val_accuracy: 0.7483\n",
            "Epoch 144/1000\n",
            "4/4 [==============================] - 2s 398ms/step - loss: 0.1750 - accuracy: 0.8004 - val_loss: 0.2581 - val_accuracy: 0.7484\n",
            "Epoch 145/1000\n",
            "4/4 [==============================] - 2s 520ms/step - loss: 0.1742 - accuracy: 0.7988 - val_loss: 0.2567 - val_accuracy: 0.7505\n",
            "Epoch 146/1000\n",
            "4/4 [==============================] - 2s 392ms/step - loss: 0.1731 - accuracy: 0.8010 - val_loss: 0.2567 - val_accuracy: 0.7509\n",
            "Epoch 147/1000\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 0.1718 - accuracy: 0.8046 - val_loss: 0.2556 - val_accuracy: 0.7504\n",
            "Epoch 148/1000\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.1711 - accuracy: 0.8034 - val_loss: 0.2559 - val_accuracy: 0.7515\n",
            "Epoch 149/1000\n",
            "4/4 [==============================] - 2s 499ms/step - loss: 0.1705 - accuracy: 0.8051 - val_loss: 0.2546 - val_accuracy: 0.7519\n",
            "Epoch 150/1000\n",
            "4/4 [==============================] - 2s 497ms/step - loss: 0.1696 - accuracy: 0.8053 - val_loss: 0.2538 - val_accuracy: 0.7527\n",
            "Epoch 151/1000\n",
            "4/4 [==============================] - 2s 471ms/step - loss: 0.1686 - accuracy: 0.8062 - val_loss: 0.2526 - val_accuracy: 0.7539\n",
            "Epoch 152/1000\n",
            "4/4 [==============================] - 2s 507ms/step - loss: 0.1674 - accuracy: 0.8073 - val_loss: 0.2519 - val_accuracy: 0.7547\n",
            "Epoch 153/1000\n",
            "4/4 [==============================] - 2s 490ms/step - loss: 0.1668 - accuracy: 0.8086 - val_loss: 0.2511 - val_accuracy: 0.7547\n",
            "Epoch 154/1000\n",
            "4/4 [==============================] - 2s 490ms/step - loss: 0.1658 - accuracy: 0.8086 - val_loss: 0.2495 - val_accuracy: 0.7573\n",
            "Epoch 155/1000\n",
            "4/4 [==============================] - 2s 471ms/step - loss: 0.1645 - accuracy: 0.8105 - val_loss: 0.2490 - val_accuracy: 0.7570\n",
            "Epoch 156/1000\n",
            "4/4 [==============================] - 2s 505ms/step - loss: 0.1639 - accuracy: 0.8128 - val_loss: 0.2482 - val_accuracy: 0.7579\n",
            "Epoch 157/1000\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.1623 - accuracy: 0.8126 - val_loss: 0.2472 - val_accuracy: 0.7585\n",
            "Epoch 158/1000\n",
            "4/4 [==============================] - 2s 461ms/step - loss: 0.1625 - accuracy: 0.8120 - val_loss: 0.2498 - val_accuracy: 0.7579\n",
            "Epoch 159/1000\n",
            "4/4 [==============================] - 2s 454ms/step - loss: 0.1619 - accuracy: 0.8142 - val_loss: 0.2486 - val_accuracy: 0.7584\n",
            "Epoch 160/1000\n",
            "4/4 [==============================] - 2s 511ms/step - loss: 0.1627 - accuracy: 0.8123 - val_loss: 0.2490 - val_accuracy: 0.7563\n",
            "Epoch 161/1000\n",
            "4/4 [==============================] - 2s 438ms/step - loss: 0.1610 - accuracy: 0.8121 - val_loss: 0.2520 - val_accuracy: 0.7570\n",
            "Epoch 162/1000\n",
            "4/4 [==============================] - 2s 477ms/step - loss: 0.1610 - accuracy: 0.8137 - val_loss: 0.2559 - val_accuracy: 0.7479\n",
            "Epoch 163/1000\n",
            "4/4 [==============================] - 2s 464ms/step - loss: 0.1616 - accuracy: 0.8091 - val_loss: 0.2597 - val_accuracy: 0.7494\n",
            "Epoch 164/1000\n",
            "4/4 [==============================] - 2s 467ms/step - loss: 0.1641 - accuracy: 0.8112 - val_loss: 0.2554 - val_accuracy: 0.7477\n",
            "Epoch 165/1000\n",
            "4/4 [==============================] - 2s 480ms/step - loss: 0.1631 - accuracy: 0.8085 - val_loss: 0.2486 - val_accuracy: 0.7581\n",
            "Epoch 166/1000\n",
            "4/4 [==============================] - 2s 494ms/step - loss: 0.1602 - accuracy: 0.8152 - val_loss: 0.2434 - val_accuracy: 0.7604\n",
            "Epoch 167/1000\n",
            "4/4 [==============================] - 2s 490ms/step - loss: 0.1591 - accuracy: 0.8140 - val_loss: 0.2423 - val_accuracy: 0.7632\n",
            "Epoch 168/1000\n",
            "4/4 [==============================] - 2s 522ms/step - loss: 0.1576 - accuracy: 0.8185 - val_loss: 0.2378 - val_accuracy: 0.7671\n",
            "Epoch 169/1000\n",
            "4/4 [==============================] - 2s 470ms/step - loss: 0.1540 - accuracy: 0.8213 - val_loss: 0.2380 - val_accuracy: 0.7671\n",
            "Epoch 170/1000\n",
            "4/4 [==============================] - 2s 473ms/step - loss: 0.1521 - accuracy: 0.8255 - val_loss: 0.2385 - val_accuracy: 0.7662\n",
            "Epoch 171/1000\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 0.1512 - accuracy: 0.8280 - val_loss: 0.2360 - val_accuracy: 0.7682\n",
            "Epoch 172/1000\n",
            "4/4 [==============================] - 2s 497ms/step - loss: 0.1504 - accuracy: 0.8286 - val_loss: 0.2363 - val_accuracy: 0.7674\n",
            "Epoch 173/1000\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 0.1493 - accuracy: 0.8287 - val_loss: 0.2352 - val_accuracy: 0.7690\n",
            "Epoch 174/1000\n",
            "4/4 [==============================] - 2s 487ms/step - loss: 0.1472 - accuracy: 0.8312 - val_loss: 0.2348 - val_accuracy: 0.7684\n",
            "Epoch 175/1000\n",
            "4/4 [==============================] - 2s 490ms/step - loss: 0.1468 - accuracy: 0.8320 - val_loss: 0.2335 - val_accuracy: 0.7706\n",
            "Epoch 176/1000\n",
            "4/4 [==============================] - 2s 491ms/step - loss: 0.1465 - accuracy: 0.8303 - val_loss: 0.2340 - val_accuracy: 0.7698\n",
            "Epoch 177/1000\n",
            "4/4 [==============================] - 2s 457ms/step - loss: 0.1452 - accuracy: 0.8339 - val_loss: 0.2333 - val_accuracy: 0.7697\n",
            "Epoch 178/1000\n",
            "4/4 [==============================] - 2s 457ms/step - loss: 0.1444 - accuracy: 0.8361 - val_loss: 0.2323 - val_accuracy: 0.7710\n",
            "Epoch 179/1000\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 0.1438 - accuracy: 0.8360 - val_loss: 0.2316 - val_accuracy: 0.7717\n",
            "Epoch 180/1000\n",
            "4/4 [==============================] - 2s 521ms/step - loss: 0.1425 - accuracy: 0.8363 - val_loss: 0.2313 - val_accuracy: 0.7722\n",
            "Epoch 181/1000\n",
            "4/4 [==============================] - 2s 425ms/step - loss: 0.1423 - accuracy: 0.8361 - val_loss: 0.2304 - val_accuracy: 0.7733\n",
            "Epoch 182/1000\n",
            "4/4 [==============================] - 2s 499ms/step - loss: 0.1415 - accuracy: 0.8377 - val_loss: 0.2304 - val_accuracy: 0.7731\n",
            "Epoch 183/1000\n",
            "4/4 [==============================] - 2s 430ms/step - loss: 0.1404 - accuracy: 0.8397 - val_loss: 0.2295 - val_accuracy: 0.7744\n",
            "Epoch 184/1000\n",
            "4/4 [==============================] - 2s 466ms/step - loss: 0.1398 - accuracy: 0.8391 - val_loss: 0.2294 - val_accuracy: 0.7749\n",
            "Epoch 185/1000\n",
            "4/4 [==============================] - 2s 523ms/step - loss: 0.1391 - accuracy: 0.8418 - val_loss: 0.2285 - val_accuracy: 0.7756\n",
            "Epoch 186/1000\n",
            "4/4 [==============================] - 2s 503ms/step - loss: 0.1382 - accuracy: 0.8418 - val_loss: 0.2300 - val_accuracy: 0.7751\n",
            "Epoch 187/1000\n",
            "4/4 [==============================] - 2s 444ms/step - loss: 0.1379 - accuracy: 0.8401 - val_loss: 0.2272 - val_accuracy: 0.7772\n",
            "Epoch 188/1000\n",
            "4/4 [==============================] - 2s 455ms/step - loss: 0.1369 - accuracy: 0.8430 - val_loss: 0.2268 - val_accuracy: 0.7774\n",
            "Epoch 189/1000\n",
            "4/4 [==============================] - 2s 467ms/step - loss: 0.1355 - accuracy: 0.8448 - val_loss: 0.2260 - val_accuracy: 0.7789\n",
            "Epoch 190/1000\n",
            "4/4 [==============================] - 2s 423ms/step - loss: 0.1348 - accuracy: 0.8468 - val_loss: 0.2253 - val_accuracy: 0.7794\n",
            "Epoch 191/1000\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 0.1344 - accuracy: 0.8474 - val_loss: 0.2252 - val_accuracy: 0.7797\n",
            "Epoch 192/1000\n",
            "4/4 [==============================] - 2s 495ms/step - loss: 0.1339 - accuracy: 0.8472 - val_loss: 0.2256 - val_accuracy: 0.7794\n",
            "Epoch 193/1000\n",
            "4/4 [==============================] - 2s 402ms/step - loss: 0.1333 - accuracy: 0.8477 - val_loss: 0.2246 - val_accuracy: 0.7794\n",
            "Epoch 194/1000\n",
            "4/4 [==============================] - 2s 457ms/step - loss: 0.1323 - accuracy: 0.8481 - val_loss: 0.2248 - val_accuracy: 0.7795\n",
            "Epoch 195/1000\n",
            "4/4 [==============================] - 2s 487ms/step - loss: 0.1319 - accuracy: 0.8502 - val_loss: 0.2239 - val_accuracy: 0.7808\n",
            "Epoch 196/1000\n",
            "4/4 [==============================] - 2s 516ms/step - loss: 0.1311 - accuracy: 0.8511 - val_loss: 0.2233 - val_accuracy: 0.7810\n",
            "Epoch 197/1000\n",
            "4/4 [==============================] - 2s 493ms/step - loss: 0.1305 - accuracy: 0.8503 - val_loss: 0.2232 - val_accuracy: 0.7808\n",
            "Epoch 198/1000\n",
            "4/4 [==============================] - 2s 492ms/step - loss: 0.1291 - accuracy: 0.8535 - val_loss: 0.2219 - val_accuracy: 0.7830\n",
            "Epoch 199/1000\n",
            "4/4 [==============================] - 2s 479ms/step - loss: 0.1287 - accuracy: 0.8528 - val_loss: 0.2219 - val_accuracy: 0.7832\n",
            "Epoch 200/1000\n",
            "4/4 [==============================] - 2s 441ms/step - loss: 0.1280 - accuracy: 0.8550 - val_loss: 0.2215 - val_accuracy: 0.7838\n",
            "Epoch 201/1000\n",
            "4/4 [==============================] - 2s 441ms/step - loss: 0.1273 - accuracy: 0.8551 - val_loss: 0.2232 - val_accuracy: 0.7817\n",
            "Epoch 202/1000\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 0.1269 - accuracy: 0.8561 - val_loss: 0.2204 - val_accuracy: 0.7842\n",
            "Epoch 203/1000\n",
            "4/4 [==============================] - 2s 495ms/step - loss: 0.1270 - accuracy: 0.8568 - val_loss: 0.2203 - val_accuracy: 0.7848\n",
            "Epoch 204/1000\n",
            "4/4 [==============================] - 2s 460ms/step - loss: 0.1263 - accuracy: 0.8547 - val_loss: 0.2218 - val_accuracy: 0.7842\n",
            "Epoch 205/1000\n",
            "4/4 [==============================] - 2s 507ms/step - loss: 0.1253 - accuracy: 0.8579 - val_loss: 0.2197 - val_accuracy: 0.7853\n",
            "Epoch 206/1000\n",
            "4/4 [==============================] - 2s 480ms/step - loss: 0.1251 - accuracy: 0.8570 - val_loss: 0.2208 - val_accuracy: 0.7854\n",
            "Epoch 207/1000\n",
            "4/4 [==============================] - 2s 430ms/step - loss: 0.1235 - accuracy: 0.8602 - val_loss: 0.2187 - val_accuracy: 0.7869\n",
            "Epoch 208/1000\n",
            "4/4 [==============================] - 2s 485ms/step - loss: 0.1227 - accuracy: 0.8601 - val_loss: 0.2185 - val_accuracy: 0.7870\n",
            "Epoch 209/1000\n",
            "4/4 [==============================] - 2s 475ms/step - loss: 0.1222 - accuracy: 0.8614 - val_loss: 0.2176 - val_accuracy: 0.7869\n",
            "Epoch 210/1000\n",
            "4/4 [==============================] - 2s 512ms/step - loss: 0.1218 - accuracy: 0.8612 - val_loss: 0.2171 - val_accuracy: 0.7871\n",
            "Epoch 211/1000\n",
            "4/4 [==============================] - 2s 484ms/step - loss: 0.1208 - accuracy: 0.8621 - val_loss: 0.2167 - val_accuracy: 0.7883\n",
            "Epoch 212/1000\n",
            "4/4 [==============================] - 2s 470ms/step - loss: 0.1199 - accuracy: 0.8651 - val_loss: 0.2162 - val_accuracy: 0.7892\n",
            "Epoch 213/1000\n",
            "4/4 [==============================] - 2s 514ms/step - loss: 0.1193 - accuracy: 0.8653 - val_loss: 0.2176 - val_accuracy: 0.7888\n",
            "Epoch 214/1000\n",
            "4/4 [==============================] - 2s 492ms/step - loss: 0.1190 - accuracy: 0.8662 - val_loss: 0.2158 - val_accuracy: 0.7898\n",
            "Epoch 215/1000\n",
            "4/4 [==============================] - 2s 416ms/step - loss: 0.1183 - accuracy: 0.8650 - val_loss: 0.2162 - val_accuracy: 0.7898\n",
            "Epoch 216/1000\n",
            "4/4 [==============================] - 2s 435ms/step - loss: 0.1177 - accuracy: 0.8668 - val_loss: 0.2157 - val_accuracy: 0.7901\n",
            "Epoch 217/1000\n",
            "4/4 [==============================] - 2s 471ms/step - loss: 0.1171 - accuracy: 0.8674 - val_loss: 0.2167 - val_accuracy: 0.7900\n",
            "Epoch 218/1000\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 0.1168 - accuracy: 0.8672 - val_loss: 0.2150 - val_accuracy: 0.7916\n",
            "Epoch 219/1000\n",
            "4/4 [==============================] - 2s 513ms/step - loss: 0.1161 - accuracy: 0.8671 - val_loss: 0.2153 - val_accuracy: 0.7902\n",
            "Epoch 220/1000\n",
            "4/4 [==============================] - 2s 447ms/step - loss: 0.1158 - accuracy: 0.8684 - val_loss: 0.2155 - val_accuracy: 0.7916\n",
            "Epoch 221/1000\n",
            "4/4 [==============================] - 2s 418ms/step - loss: 0.1150 - accuracy: 0.8687 - val_loss: 0.2147 - val_accuracy: 0.7924\n",
            "Epoch 222/1000\n",
            "4/4 [==============================] - 2s 469ms/step - loss: 0.1143 - accuracy: 0.8697 - val_loss: 0.2158 - val_accuracy: 0.7909\n",
            "Epoch 223/1000\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 0.1137 - accuracy: 0.8712 - val_loss: 0.2128 - val_accuracy: 0.7930\n",
            "Epoch 224/1000\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 0.1135 - accuracy: 0.8719 - val_loss: 0.2123 - val_accuracy: 0.7935\n",
            "Epoch 225/1000\n",
            "4/4 [==============================] - 2s 395ms/step - loss: 0.1127 - accuracy: 0.8727 - val_loss: 0.2134 - val_accuracy: 0.7930\n",
            "Epoch 226/1000\n",
            "4/4 [==============================] - 2s 432ms/step - loss: 0.1126 - accuracy: 0.8718 - val_loss: 0.2117 - val_accuracy: 0.7948\n",
            "Epoch 227/1000\n",
            "4/4 [==============================] - 2s 450ms/step - loss: 0.1114 - accuracy: 0.8760 - val_loss: 0.2118 - val_accuracy: 0.7943\n",
            "Epoch 228/1000\n",
            "4/4 [==============================] - 2s 523ms/step - loss: 0.1104 - accuracy: 0.8755 - val_loss: 0.2126 - val_accuracy: 0.7934\n",
            "Epoch 229/1000\n",
            "4/4 [==============================] - 2s 483ms/step - loss: 0.1106 - accuracy: 0.8751 - val_loss: 0.2109 - val_accuracy: 0.7960\n",
            "Epoch 230/1000\n",
            "4/4 [==============================] - 2s 456ms/step - loss: 0.1100 - accuracy: 0.8746 - val_loss: 0.2110 - val_accuracy: 0.7963\n",
            "Epoch 231/1000\n",
            "4/4 [==============================] - 2s 488ms/step - loss: 0.1093 - accuracy: 0.8772 - val_loss: 0.2109 - val_accuracy: 0.7966\n",
            "Epoch 232/1000\n",
            "4/4 [==============================] - 2s 463ms/step - loss: 0.1082 - accuracy: 0.8779 - val_loss: 0.2107 - val_accuracy: 0.7963\n",
            "Epoch 233/1000\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.1076 - accuracy: 0.8791 - val_loss: 0.2101 - val_accuracy: 0.7974\n",
            "Epoch 234/1000\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 0.1075 - accuracy: 0.8782 - val_loss: 0.2103 - val_accuracy: 0.7970\n",
            "Epoch 235/1000\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 0.1068 - accuracy: 0.8787 - val_loss: 0.2107 - val_accuracy: 0.7970\n",
            "Epoch 236/1000\n",
            "4/4 [==============================] - 2s 486ms/step - loss: 0.1069 - accuracy: 0.8785 - val_loss: 0.2100 - val_accuracy: 0.7962\n",
            "Epoch 237/1000\n",
            "4/4 [==============================] - 2s 505ms/step - loss: 0.1058 - accuracy: 0.8796 - val_loss: 0.2095 - val_accuracy: 0.7971\n",
            "Epoch 238/1000\n",
            "4/4 [==============================] - 2s 491ms/step - loss: 0.1056 - accuracy: 0.8789 - val_loss: 0.2095 - val_accuracy: 0.7979\n",
            "Epoch 239/1000\n",
            "4/4 [==============================] - 2s 464ms/step - loss: 0.1049 - accuracy: 0.8812 - val_loss: 0.2095 - val_accuracy: 0.7974\n",
            "Epoch 240/1000\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 0.1045 - accuracy: 0.8813 - val_loss: 0.2095 - val_accuracy: 0.7980\n",
            "Epoch 241/1000\n",
            "4/4 [==============================] - 2s 506ms/step - loss: 0.1034 - accuracy: 0.8831 - val_loss: 0.2093 - val_accuracy: 0.7976\n",
            "Epoch 242/1000\n",
            "4/4 [==============================] - 2s 446ms/step - loss: 0.1028 - accuracy: 0.8826 - val_loss: 0.2093 - val_accuracy: 0.7976\n",
            "Epoch 243/1000\n",
            "4/4 [==============================] - 2s 489ms/step - loss: 0.1033 - accuracy: 0.8821 - val_loss: 0.2085 - val_accuracy: 0.7977\n",
            "Epoch 244/1000\n",
            "4/4 [==============================] - 2s 507ms/step - loss: 0.1018 - accuracy: 0.8864 - val_loss: 0.2085 - val_accuracy: 0.7989\n",
            "Epoch 245/1000\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.1015 - accuracy: 0.8847 - val_loss: 0.2089 - val_accuracy: 0.7984\n",
            "Epoch 246/1000\n",
            "4/4 [==============================] - 2s 425ms/step - loss: 0.1008 - accuracy: 0.8867 - val_loss: 0.2079 - val_accuracy: 0.8001\n",
            "Epoch 247/1000\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 0.0997 - accuracy: 0.8868 - val_loss: 0.2074 - val_accuracy: 0.7999\n",
            "Epoch 248/1000\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.0996 - accuracy: 0.8876 - val_loss: 0.2092 - val_accuracy: 0.7986\n",
            "Epoch 249/1000\n",
            "4/4 [==============================] - 2s 448ms/step - loss: 0.0988 - accuracy: 0.8905 - val_loss: 0.2075 - val_accuracy: 0.7994\n",
            "Epoch 250/1000\n",
            "4/4 [==============================] - 2s 449ms/step - loss: 0.0984 - accuracy: 0.8886 - val_loss: 0.2065 - val_accuracy: 0.8011\n",
            "Epoch 251/1000\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 0.0990 - accuracy: 0.8869 - val_loss: 0.2101 - val_accuracy: 0.7986\n",
            "Epoch 252/1000\n",
            "4/4 [==============================] - 2s 512ms/step - loss: 0.0998 - accuracy: 0.8860 - val_loss: 0.2069 - val_accuracy: 0.8002\n",
            "Epoch 253/1000\n",
            "4/4 [==============================] - 2s 474ms/step - loss: 0.0976 - accuracy: 0.8897 - val_loss: 0.2066 - val_accuracy: 0.8005\n",
            "Epoch 254/1000\n",
            "4/4 [==============================] - 2s 442ms/step - loss: 0.0975 - accuracy: 0.8876 - val_loss: 0.2088 - val_accuracy: 0.8005\n",
            "Epoch 255/1000\n",
            "4/4 [==============================] - 2s 502ms/step - loss: 0.0963 - accuracy: 0.8904 - val_loss: 0.2079 - val_accuracy: 0.8000\n",
            "Epoch 256/1000\n",
            "4/4 [==============================] - 2s 521ms/step - loss: 0.0961 - accuracy: 0.8909 - val_loss: 0.2060 - val_accuracy: 0.8027\n",
            "Epoch 257/1000\n",
            "4/4 [==============================] - 2s 490ms/step - loss: 0.0963 - accuracy: 0.8887 - val_loss: 0.2077 - val_accuracy: 0.8015\n",
            "Epoch 258/1000\n",
            "4/4 [==============================] - 2s 468ms/step - loss: 0.0944 - accuracy: 0.8936 - val_loss: 0.2072 - val_accuracy: 0.8005\n",
            "Epoch 259/1000\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.0942 - accuracy: 0.8917 - val_loss: 0.2069 - val_accuracy: 0.8019\n",
            "Epoch 260/1000\n",
            "4/4 [==============================] - 2s 469ms/step - loss: 0.0943 - accuracy: 0.8941 - val_loss: 0.2055 - val_accuracy: 0.8035\n",
            "Epoch 261/1000\n",
            "4/4 [==============================] - 2s 491ms/step - loss: 0.0941 - accuracy: 0.8919 - val_loss: 0.2049 - val_accuracy: 0.8034\n",
            "Epoch 262/1000\n",
            "4/4 [==============================] - 2s 486ms/step - loss: 0.0931 - accuracy: 0.8937 - val_loss: 0.2049 - val_accuracy: 0.8030\n",
            "Epoch 263/1000\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 0.0920 - accuracy: 0.8953 - val_loss: 0.2043 - val_accuracy: 0.8032\n",
            "Epoch 264/1000\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 0.0915 - accuracy: 0.8983 - val_loss: 0.2048 - val_accuracy: 0.8032\n",
            "Epoch 265/1000\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 0.0916 - accuracy: 0.8964 - val_loss: 0.2048 - val_accuracy: 0.8037\n",
            "Epoch 266/1000\n",
            "4/4 [==============================] - 2s 481ms/step - loss: 0.0904 - accuracy: 0.8977 - val_loss: 0.2046 - val_accuracy: 0.8041\n",
            "Epoch 267/1000\n",
            "4/4 [==============================] - 2s 525ms/step - loss: 0.0894 - accuracy: 0.8991 - val_loss: 0.2034 - val_accuracy: 0.8051\n",
            "Epoch 268/1000\n",
            "4/4 [==============================] - 2s 421ms/step - loss: 0.0895 - accuracy: 0.8990 - val_loss: 0.2051 - val_accuracy: 0.8045\n",
            "Epoch 269/1000\n",
            "4/4 [==============================] - 2s 471ms/step - loss: 0.0890 - accuracy: 0.8993 - val_loss: 0.2037 - val_accuracy: 0.8049\n",
            "Epoch 270/1000\n",
            "4/4 [==============================] - 2s 498ms/step - loss: 0.0886 - accuracy: 0.9006 - val_loss: 0.2027 - val_accuracy: 0.8068\n",
            "Epoch 271/1000\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.0885 - accuracy: 0.8996 - val_loss: 0.2039 - val_accuracy: 0.8046\n",
            "Epoch 272/1000\n",
            "4/4 [==============================] - 2s 504ms/step - loss: 0.0869 - accuracy: 0.9038 - val_loss: 0.2038 - val_accuracy: 0.8050\n",
            "Epoch 273/1000\n",
            "4/4 [==============================] - 2s 506ms/step - loss: 0.0873 - accuracy: 0.9013 - val_loss: 0.2031 - val_accuracy: 0.8063\n",
            "Epoch 274/1000\n",
            "4/4 [==============================] - 2s 454ms/step - loss: 0.0869 - accuracy: 0.9010 - val_loss: 0.2048 - val_accuracy: 0.8049\n",
            "Epoch 275/1000\n",
            "4/4 [==============================] - 2s 407ms/step - loss: 0.0863 - accuracy: 0.9026 - val_loss: 0.2035 - val_accuracy: 0.8064\n",
            "Epoch 276/1000\n",
            "4/4 [==============================] - 2s 499ms/step - loss: 0.0861 - accuracy: 0.9029 - val_loss: 0.2043 - val_accuracy: 0.8065\n",
            "Epoch 277/1000\n",
            "4/4 [==============================] - 2s 458ms/step - loss: 0.0850 - accuracy: 0.9039 - val_loss: 0.2037 - val_accuracy: 0.8066\n",
            "Epoch 278/1000\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 0.0854 - accuracy: 0.9027 - val_loss: 0.2031 - val_accuracy: 0.8056\n",
            "Epoch 279/1000\n",
            "4/4 [==============================] - 2s 491ms/step - loss: 0.0855 - accuracy: 0.9021 - val_loss: 0.2072 - val_accuracy: 0.8052\n",
            "Epoch 280/1000\n",
            "4/4 [==============================] - 2s 489ms/step - loss: 0.0852 - accuracy: 0.9043 - val_loss: 0.2036 - val_accuracy: 0.8066\n",
            "Epoch 281/1000\n",
            "4/4 [==============================] - 2s 587ms/step - loss: 0.0845 - accuracy: 0.9045 - val_loss: 0.2028 - val_accuracy: 0.8078\n",
            "Epoch 282/1000\n",
            "4/4 [==============================] - 2s 508ms/step - loss: 0.0835 - accuracy: 0.9064 - val_loss: 0.2026 - val_accuracy: 0.8082\n",
            "Epoch 283/1000\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 0.0831 - accuracy: 0.9059 - val_loss: 0.2019 - val_accuracy: 0.8079\n",
            "Epoch 284/1000\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.0822 - accuracy: 0.9053 - val_loss: 0.2023 - val_accuracy: 0.8082\n",
            "Epoch 285/1000\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.0820 - accuracy: 0.9081 - val_loss: 0.2026 - val_accuracy: 0.8077\n",
            "Epoch 286/1000\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 0.0816 - accuracy: 0.9084 - val_loss: 0.2025 - val_accuracy: 0.8084\n",
            "Epoch 287/1000\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 0.0811 - accuracy: 0.9067 - val_loss: 0.2020 - val_accuracy: 0.8075\n",
            "Epoch 288/1000\n",
            "4/4 [==============================] - 2s 458ms/step - loss: 0.0809 - accuracy: 0.9089 - val_loss: 0.2030 - val_accuracy: 0.8083\n",
            "Epoch 289/1000\n",
            "4/4 [==============================] - 2s 431ms/step - loss: 0.0803 - accuracy: 0.9099 - val_loss: 0.2012 - val_accuracy: 0.8104\n",
            "Epoch 290/1000\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.0800 - accuracy: 0.9090 - val_loss: 0.2019 - val_accuracy: 0.8093\n",
            "Epoch 291/1000\n",
            "4/4 [==============================] - 2s 505ms/step - loss: 0.0794 - accuracy: 0.9107 - val_loss: 0.2022 - val_accuracy: 0.8097\n",
            "Epoch 292/1000\n",
            "4/4 [==============================] - 2s 433ms/step - loss: 0.0789 - accuracy: 0.9122 - val_loss: 0.2021 - val_accuracy: 0.8097\n",
            "Epoch 293/1000\n",
            "4/4 [==============================] - 2s 419ms/step - loss: 0.0784 - accuracy: 0.9106 - val_loss: 0.2018 - val_accuracy: 0.8102\n",
            "Epoch 294/1000\n",
            "4/4 [==============================] - 2s 426ms/step - loss: 0.0777 - accuracy: 0.9132 - val_loss: 0.2025 - val_accuracy: 0.8091\n",
            "Epoch 295/1000\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.0780 - accuracy: 0.9118 - val_loss: 0.2031 - val_accuracy: 0.8106\n",
            "Epoch 296/1000\n",
            "4/4 [==============================] - 2s 458ms/step - loss: 0.0778 - accuracy: 0.9111 - val_loss: 0.2022 - val_accuracy: 0.8102\n",
            "Epoch 297/1000\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 0.0769 - accuracy: 0.9112 - val_loss: 0.2041 - val_accuracy: 0.8094\n",
            "Epoch 298/1000\n",
            "4/4 [==============================] - 2s 470ms/step - loss: 0.0771 - accuracy: 0.9125 - val_loss: 0.2012 - val_accuracy: 0.8099\n",
            "Epoch 299/1000\n",
            "4/4 [==============================] - 2s 479ms/step - loss: 0.0762 - accuracy: 0.9141 - val_loss: 0.2014 - val_accuracy: 0.8099\n",
            "Epoch 300/1000\n",
            "4/4 [==============================] - 2s 490ms/step - loss: 0.0761 - accuracy: 0.9137 - val_loss: 0.2019 - val_accuracy: 0.8101\n",
            "Epoch 301/1000\n",
            "4/4 [==============================] - 2s 472ms/step - loss: 0.0765 - accuracy: 0.9143 - val_loss: 0.2014 - val_accuracy: 0.8112\n",
            "Epoch 302/1000\n",
            "4/4 [==============================] - 2s 421ms/step - loss: 0.0758 - accuracy: 0.9144 - val_loss: 0.2013 - val_accuracy: 0.8100\n",
            "Epoch 303/1000\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 0.0754 - accuracy: 0.9141 - val_loss: 0.2017 - val_accuracy: 0.8111\n",
            "Epoch 304/1000\n",
            "4/4 [==============================] - 2s 480ms/step - loss: 0.0749 - accuracy: 0.9146 - val_loss: 0.2044 - val_accuracy: 0.8096\n",
            "Epoch 305/1000\n",
            "4/4 [==============================] - 2s 525ms/step - loss: 0.0748 - accuracy: 0.9157 - val_loss: 0.2029 - val_accuracy: 0.8103\n",
            "Epoch 306/1000\n",
            "4/4 [==============================] - 2s 437ms/step - loss: 0.0743 - accuracy: 0.9149 - val_loss: 0.2056 - val_accuracy: 0.8078\n",
            "Epoch 307/1000\n",
            "4/4 [==============================] - 2s 476ms/step - loss: 0.0741 - accuracy: 0.9157 - val_loss: 0.2010 - val_accuracy: 0.8115\n",
            "Epoch 308/1000\n",
            "4/4 [==============================] - 2s 520ms/step - loss: 0.0747 - accuracy: 0.9137 - val_loss: 0.2008 - val_accuracy: 0.8130\n",
            "Epoch 309/1000\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.0737 - accuracy: 0.9149 - val_loss: 0.2031 - val_accuracy: 0.8109\n",
            "Epoch 310/1000\n",
            "4/4 [==============================] - 2s 465ms/step - loss: 0.0728 - accuracy: 0.9174 - val_loss: 0.2013 - val_accuracy: 0.8124\n",
            "Epoch 311/1000\n",
            "4/4 [==============================] - 2s 451ms/step - loss: 0.0728 - accuracy: 0.9171 - val_loss: 0.2041 - val_accuracy: 0.8110\n",
            "Epoch 312/1000\n",
            "4/4 [==============================] - 2s 490ms/step - loss: 0.0723 - accuracy: 0.9184 - val_loss: 0.2014 - val_accuracy: 0.8130\n",
            "Epoch 313/1000\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.0722 - accuracy: 0.9183 - val_loss: 0.2007 - val_accuracy: 0.8135\n",
            "Epoch 314/1000\n",
            "4/4 [==============================] - 2s 476ms/step - loss: 0.0714 - accuracy: 0.9199 - val_loss: 0.2019 - val_accuracy: 0.8125\n",
            "Epoch 315/1000\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 0.0709 - accuracy: 0.9205 - val_loss: 0.2009 - val_accuracy: 0.8135\n",
            "Epoch 316/1000\n",
            "4/4 [==============================] - 2s 525ms/step - loss: 0.0707 - accuracy: 0.9197 - val_loss: 0.2021 - val_accuracy: 0.8126\n",
            "Epoch 317/1000\n",
            "4/4 [==============================] - 2s 487ms/step - loss: 0.0702 - accuracy: 0.9208 - val_loss: 0.2012 - val_accuracy: 0.8136\n",
            "Epoch 318/1000\n",
            "4/4 [==============================] - 2s 506ms/step - loss: 0.0697 - accuracy: 0.9223 - val_loss: 0.2008 - val_accuracy: 0.8138\n",
            "Epoch 319/1000\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 0.0700 - accuracy: 0.9198 - val_loss: 0.2021 - val_accuracy: 0.8147\n",
            "Epoch 320/1000\n",
            "4/4 [==============================] - 2s 512ms/step - loss: 0.0688 - accuracy: 0.9235 - val_loss: 0.2012 - val_accuracy: 0.8141\n",
            "Epoch 321/1000\n",
            "4/4 [==============================] - 2s 486ms/step - loss: 0.0684 - accuracy: 0.9232 - val_loss: 0.2013 - val_accuracy: 0.8143\n",
            "Epoch 322/1000\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.0684 - accuracy: 0.9228 - val_loss: 0.2009 - val_accuracy: 0.8137\n",
            "Epoch 323/1000\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 0.0682 - accuracy: 0.9231 - val_loss: 0.2016 - val_accuracy: 0.8141\n",
            "Epoch 324/1000\n",
            "4/4 [==============================] - 2s 491ms/step - loss: 0.0679 - accuracy: 0.9227 - val_loss: 0.2017 - val_accuracy: 0.8142\n",
            "Epoch 325/1000\n",
            "4/4 [==============================] - 2s 476ms/step - loss: 0.0674 - accuracy: 0.9233 - val_loss: 0.2020 - val_accuracy: 0.8132\n",
            "Epoch 326/1000\n",
            "4/4 [==============================] - 2s 479ms/step - loss: 0.0673 - accuracy: 0.9241 - val_loss: 0.2020 - val_accuracy: 0.8138\n",
            "Epoch 327/1000\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.0666 - accuracy: 0.9247 - val_loss: 0.2012 - val_accuracy: 0.8145\n",
            "Epoch 328/1000\n",
            "4/4 [==============================] - 2s 448ms/step - loss: 0.0666 - accuracy: 0.9263 - val_loss: 0.2028 - val_accuracy: 0.8125\n",
            "Training completed! Showing history...\n",
            "Displaying the following history keys:  dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwtgi6tR5EUX"
      },
      "source": [
        "##Additional Dense Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Compile"
      ],
      "metadata": {
        "id": "mndFQGIABtUD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmziU_5l5ZuP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8400fc1-66a2-4cb1-ac51-46f45d17c966"
      },
      "source": [
        "two_dense = Sequential()\n",
        "\n",
        "# Embedding layer\n",
        "two_dense.add(Embedding(input_dim = vocab_size,\n",
        "              input_length = max_seq_length,\n",
        "              output_dim=embedding_dimension,\n",
        "              weights = embedding_matrix if embedding_matrix is None else [embedding_matrix],\n",
        "              trainable=False,\n",
        "              mask_zero=True))\n",
        "\n",
        "# Bidirectional layer\n",
        "two_dense.add(Bidirectional(LSTM(32, return_sequences=True \n",
        "               ,dropout=0.1\n",
        "               )))             \n",
        "\n",
        "# Dense layer\n",
        "two_dense.add(TimeDistributed(Dense(128,\n",
        "            activation= 'relu')))\n",
        "\n",
        "# Output\n",
        "two_dense.add(TimeDistributed(Dense(num_classes,\n",
        "            activation= 'softmax')))\n",
        "\n",
        "# Compile the model\n",
        "two_dense.compile(\n",
        "    optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "two_dense.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 1897, 200)         2189800   \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 1897, 64)         59648     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDis  (None, 1897, 128)        8320      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDis  (None, 1897, 46)         5934      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,263,702\n",
            "Trainable params: 73,902\n",
            "Non-trainable params: 2,189,800\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lM7aaxF8ZzS"
      },
      "source": [
        "###Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9ze3K-R8e7T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8d9b02b-a7dd-49f5-a933-8f3270eb1e9a"
      },
      "source": [
        "# Training\n",
        "\n",
        "training_info = {\n",
        "    'verbose': 1,\n",
        "    'epochs': 1000,\n",
        "    'batch_size': 32,\n",
        "    'callbacks': [keras.callbacks.EarlyStopping(monitor='val_loss', \n",
        "                                                patience=15,\n",
        "                                                restore_best_weights=True)]\n",
        "}\n",
        "two_dense = train_model(model=two_dense, x_train=x_train, y_train=y_train,\n",
        "                    x_val=x_val, y_val=y_val, training_info=training_info)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training! \n",
            "Parameters: {'verbose': 1, 'epochs': 1000, 'batch_size': 32, 'callbacks': [<keras.callbacks.EarlyStopping object at 0x000001DD2C624C10>]}\n",
            "Train size: 100\n",
            "Val size: 50\n",
            "Epoch 1/1000\n",
            "4/4 [==============================] - 8s 912ms/step - loss: 0.9293 - accuracy: 0.0336 - val_loss: 1.1153 - val_accuracy: 0.0563\n",
            "Epoch 2/1000\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 0.8948 - accuracy: 0.0629 - val_loss: 1.0705 - val_accuracy: 0.0646\n",
            "Epoch 3/1000\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.8554 - accuracy: 0.0668 - val_loss: 1.0171 - val_accuracy: 0.0667\n",
            "Epoch 4/1000\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.8089 - accuracy: 0.0764 - val_loss: 0.9630 - val_accuracy: 0.1125\n",
            "Epoch 5/1000\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 0.7677 - accuracy: 0.1439 - val_loss: 0.9201 - val_accuracy: 0.1254\n",
            "Epoch 6/1000\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 0.7332 - accuracy: 0.1505 - val_loss: 0.8890 - val_accuracy: 0.1464\n",
            "Epoch 7/1000\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.7116 - accuracy: 0.1952 - val_loss: 0.8657 - val_accuracy: 0.2659\n",
            "Epoch 8/1000\n",
            "4/4 [==============================] - 1s 293ms/step - loss: 0.6951 - accuracy: 0.2552 - val_loss: 0.8451 - val_accuracy: 0.2596\n",
            "Epoch 9/1000\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.6783 - accuracy: 0.2546 - val_loss: 0.8226 - val_accuracy: 0.2976\n",
            "Epoch 10/1000\n",
            "4/4 [==============================] - 1s 264ms/step - loss: 0.6590 - accuracy: 0.3076 - val_loss: 0.8005 - val_accuracy: 0.3228\n",
            "Epoch 11/1000\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.6391 - accuracy: 0.3287 - val_loss: 0.7773 - val_accuracy: 0.3281\n",
            "Epoch 12/1000\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.6203 - accuracy: 0.3307 - val_loss: 0.7546 - val_accuracy: 0.3361\n",
            "Epoch 13/1000\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 0.6021 - accuracy: 0.3405 - val_loss: 0.7321 - val_accuracy: 0.3686\n",
            "Epoch 14/1000\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.5842 - accuracy: 0.3718 - val_loss: 0.7113 - val_accuracy: 0.3969\n",
            "Epoch 15/1000\n",
            "4/4 [==============================] - 1s 260ms/step - loss: 0.5660 - accuracy: 0.4013 - val_loss: 0.6907 - val_accuracy: 0.4049\n",
            "Epoch 16/1000\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.5490 - accuracy: 0.4087 - val_loss: 0.6699 - val_accuracy: 0.4171\n",
            "Epoch 17/1000\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.5311 - accuracy: 0.4205 - val_loss: 0.6503 - val_accuracy: 0.4283\n",
            "Epoch 18/1000\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.5149 - accuracy: 0.4322 - val_loss: 0.6326 - val_accuracy: 0.4337\n",
            "Epoch 19/1000\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 0.5015 - accuracy: 0.4396 - val_loss: 0.6157 - val_accuracy: 0.4399\n",
            "Epoch 20/1000\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 0.4877 - accuracy: 0.4473 - val_loss: 0.6005 - val_accuracy: 0.4519\n",
            "Epoch 21/1000\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 0.4758 - accuracy: 0.4628 - val_loss: 0.5871 - val_accuracy: 0.4645\n",
            "Epoch 22/1000\n",
            "4/4 [==============================] - 1s 288ms/step - loss: 0.4637 - accuracy: 0.4777 - val_loss: 0.5740 - val_accuracy: 0.4698\n",
            "Epoch 23/1000\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.4533 - accuracy: 0.4841 - val_loss: 0.5616 - val_accuracy: 0.4764\n",
            "Epoch 24/1000\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.4433 - accuracy: 0.4942 - val_loss: 0.5506 - val_accuracy: 0.4864\n",
            "Epoch 25/1000\n",
            "4/4 [==============================] - 1s 260ms/step - loss: 0.4337 - accuracy: 0.5063 - val_loss: 0.5387 - val_accuracy: 0.4924\n",
            "Epoch 26/1000\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.4238 - accuracy: 0.5096 - val_loss: 0.5286 - val_accuracy: 0.4959\n",
            "Epoch 27/1000\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.4153 - accuracy: 0.5148 - val_loss: 0.5199 - val_accuracy: 0.4979\n",
            "Epoch 28/1000\n",
            "4/4 [==============================] - 1s 290ms/step - loss: 0.4077 - accuracy: 0.5194 - val_loss: 0.5098 - val_accuracy: 0.5109\n",
            "Epoch 29/1000\n",
            "4/4 [==============================] - 1s 273ms/step - loss: 0.3995 - accuracy: 0.5305 - val_loss: 0.5009 - val_accuracy: 0.5208\n",
            "Epoch 30/1000\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.3924 - accuracy: 0.5408 - val_loss: 0.4925 - val_accuracy: 0.5348\n",
            "Epoch 31/1000\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 0.3848 - accuracy: 0.5522 - val_loss: 0.4834 - val_accuracy: 0.5453\n",
            "Epoch 32/1000\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 0.3783 - accuracy: 0.5578 - val_loss: 0.4770 - val_accuracy: 0.5500\n",
            "Epoch 33/1000\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.3722 - accuracy: 0.5662 - val_loss: 0.4681 - val_accuracy: 0.5611\n",
            "Epoch 34/1000\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 0.3658 - accuracy: 0.5745 - val_loss: 0.4607 - val_accuracy: 0.5681\n",
            "Epoch 35/1000\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.3601 - accuracy: 0.5810 - val_loss: 0.4552 - val_accuracy: 0.5703\n",
            "Epoch 36/1000\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.3542 - accuracy: 0.5860 - val_loss: 0.4489 - val_accuracy: 0.5757\n",
            "Epoch 37/1000\n",
            "4/4 [==============================] - 1s 282ms/step - loss: 0.3491 - accuracy: 0.5919 - val_loss: 0.4428 - val_accuracy: 0.5829\n",
            "Epoch 38/1000\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.3443 - accuracy: 0.5998 - val_loss: 0.4381 - val_accuracy: 0.5876\n",
            "Epoch 39/1000\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 0.3394 - accuracy: 0.6038 - val_loss: 0.4312 - val_accuracy: 0.5921\n",
            "Epoch 40/1000\n",
            "4/4 [==============================] - 1s 285ms/step - loss: 0.3345 - accuracy: 0.6083 - val_loss: 0.4256 - val_accuracy: 0.5964\n",
            "Epoch 41/1000\n",
            "4/4 [==============================] - 1s 282ms/step - loss: 0.3299 - accuracy: 0.6128 - val_loss: 0.4201 - val_accuracy: 0.6011\n",
            "Epoch 42/1000\n",
            "4/4 [==============================] - 1s 287ms/step - loss: 0.3256 - accuracy: 0.6186 - val_loss: 0.4160 - val_accuracy: 0.6049\n",
            "Epoch 43/1000\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.3209 - accuracy: 0.6253 - val_loss: 0.4117 - val_accuracy: 0.6069\n",
            "Epoch 44/1000\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.3168 - accuracy: 0.6254 - val_loss: 0.4051 - val_accuracy: 0.6101\n",
            "Epoch 45/1000\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.3127 - accuracy: 0.6276 - val_loss: 0.4003 - val_accuracy: 0.6145\n",
            "Epoch 46/1000\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 0.3088 - accuracy: 0.6361 - val_loss: 0.3959 - val_accuracy: 0.6204\n",
            "Epoch 47/1000\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.3045 - accuracy: 0.6405 - val_loss: 0.3923 - val_accuracy: 0.6217\n",
            "Epoch 48/1000\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 0.3008 - accuracy: 0.6431 - val_loss: 0.3885 - val_accuracy: 0.6215\n",
            "Epoch 49/1000\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.2977 - accuracy: 0.6421 - val_loss: 0.3838 - val_accuracy: 0.6243\n",
            "Epoch 50/1000\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.2942 - accuracy: 0.6474 - val_loss: 0.3810 - val_accuracy: 0.6295\n",
            "Epoch 51/1000\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 0.2916 - accuracy: 0.6515 - val_loss: 0.3770 - val_accuracy: 0.6313\n",
            "Epoch 52/1000\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 0.2881 - accuracy: 0.6549 - val_loss: 0.3740 - val_accuracy: 0.6319\n",
            "Epoch 53/1000\n",
            "4/4 [==============================] - 1s 260ms/step - loss: 0.2851 - accuracy: 0.6552 - val_loss: 0.3721 - val_accuracy: 0.6322\n",
            "Epoch 54/1000\n",
            "4/4 [==============================] - 1s 268ms/step - loss: 0.2828 - accuracy: 0.6569 - val_loss: 0.3682 - val_accuracy: 0.6375\n",
            "Epoch 55/1000\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.2805 - accuracy: 0.6594 - val_loss: 0.3656 - val_accuracy: 0.6380\n",
            "Epoch 56/1000\n",
            "4/4 [==============================] - 1s 233ms/step - loss: 0.2777 - accuracy: 0.6623 - val_loss: 0.3624 - val_accuracy: 0.6416\n",
            "Epoch 57/1000\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.2743 - accuracy: 0.6650 - val_loss: 0.3588 - val_accuracy: 0.6438\n",
            "Epoch 58/1000\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.2718 - accuracy: 0.6690 - val_loss: 0.3575 - val_accuracy: 0.6468\n",
            "Epoch 59/1000\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.2693 - accuracy: 0.6713 - val_loss: 0.3548 - val_accuracy: 0.6489\n",
            "Epoch 60/1000\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.2672 - accuracy: 0.6755 - val_loss: 0.3516 - val_accuracy: 0.6519\n",
            "Epoch 61/1000\n",
            "4/4 [==============================] - 1s 269ms/step - loss: 0.2648 - accuracy: 0.6782 - val_loss: 0.3480 - val_accuracy: 0.6533\n",
            "Epoch 62/1000\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.2620 - accuracy: 0.6819 - val_loss: 0.3456 - val_accuracy: 0.6581\n",
            "Epoch 63/1000\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.2598 - accuracy: 0.6846 - val_loss: 0.3440 - val_accuracy: 0.6592\n",
            "Epoch 64/1000\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.2572 - accuracy: 0.6868 - val_loss: 0.3397 - val_accuracy: 0.6608\n",
            "Epoch 65/1000\n",
            "4/4 [==============================] - 1s 272ms/step - loss: 0.2556 - accuracy: 0.6882 - val_loss: 0.3377 - val_accuracy: 0.6642\n",
            "Epoch 66/1000\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 0.2528 - accuracy: 0.6939 - val_loss: 0.3351 - val_accuracy: 0.6658\n",
            "Epoch 67/1000\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 0.2503 - accuracy: 0.6946 - val_loss: 0.3326 - val_accuracy: 0.6678\n",
            "Epoch 68/1000\n",
            "4/4 [==============================] - 1s 275ms/step - loss: 0.2482 - accuracy: 0.6977 - val_loss: 0.3301 - val_accuracy: 0.6706\n",
            "Epoch 69/1000\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 0.2462 - accuracy: 0.7011 - val_loss: 0.3291 - val_accuracy: 0.6719\n",
            "Epoch 70/1000\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.2451 - accuracy: 0.6994 - val_loss: 0.3267 - val_accuracy: 0.6752\n",
            "Epoch 71/1000\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 0.2419 - accuracy: 0.7052 - val_loss: 0.3250 - val_accuracy: 0.6766\n",
            "Epoch 72/1000\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 0.2410 - accuracy: 0.7055 - val_loss: 0.3225 - val_accuracy: 0.6773\n",
            "Epoch 73/1000\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 0.2392 - accuracy: 0.7067 - val_loss: 0.3212 - val_accuracy: 0.6804\n",
            "Epoch 74/1000\n",
            "4/4 [==============================] - 1s 260ms/step - loss: 0.2373 - accuracy: 0.7109 - val_loss: 0.3200 - val_accuracy: 0.6830\n",
            "Epoch 75/1000\n",
            "4/4 [==============================] - 1s 274ms/step - loss: 0.2355 - accuracy: 0.7135 - val_loss: 0.3171 - val_accuracy: 0.6846\n",
            "Epoch 76/1000\n",
            "4/4 [==============================] - 1s 279ms/step - loss: 0.2340 - accuracy: 0.7147 - val_loss: 0.3160 - val_accuracy: 0.6844\n",
            "Epoch 77/1000\n",
            "4/4 [==============================] - 1s 298ms/step - loss: 0.2327 - accuracy: 0.7148 - val_loss: 0.3141 - val_accuracy: 0.6875\n",
            "Epoch 78/1000\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 0.2305 - accuracy: 0.7189 - val_loss: 0.3140 - val_accuracy: 0.6869\n",
            "Epoch 79/1000\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 0.2295 - accuracy: 0.7193 - val_loss: 0.3116 - val_accuracy: 0.6899\n",
            "Epoch 80/1000\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.2268 - accuracy: 0.7227 - val_loss: 0.3090 - val_accuracy: 0.6921\n",
            "Epoch 81/1000\n",
            "4/4 [==============================] - 1s 262ms/step - loss: 0.2257 - accuracy: 0.7241 - val_loss: 0.3080 - val_accuracy: 0.6936\n",
            "Epoch 82/1000\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 0.2238 - accuracy: 0.7271 - val_loss: 0.3065 - val_accuracy: 0.6939\n",
            "Epoch 83/1000\n",
            "4/4 [==============================] - 1s 275ms/step - loss: 0.2221 - accuracy: 0.7281 - val_loss: 0.3054 - val_accuracy: 0.6930\n",
            "Epoch 84/1000\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 0.2217 - accuracy: 0.7274 - val_loss: 0.3028 - val_accuracy: 0.6968\n",
            "Epoch 85/1000\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.2195 - accuracy: 0.7321 - val_loss: 0.3022 - val_accuracy: 0.6982\n",
            "Epoch 86/1000\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.2178 - accuracy: 0.7358 - val_loss: 0.3003 - val_accuracy: 0.6994\n",
            "Epoch 87/1000\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 0.2162 - accuracy: 0.7360 - val_loss: 0.2984 - val_accuracy: 0.7008\n",
            "Epoch 88/1000\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 0.2152 - accuracy: 0.7352 - val_loss: 0.2978 - val_accuracy: 0.7010\n",
            "Epoch 89/1000\n",
            "4/4 [==============================] - 1s 267ms/step - loss: 0.2134 - accuracy: 0.7376 - val_loss: 0.2967 - val_accuracy: 0.7038\n",
            "Epoch 90/1000\n",
            "4/4 [==============================] - 1s 267ms/step - loss: 0.2128 - accuracy: 0.7388 - val_loss: 0.2956 - val_accuracy: 0.7037\n",
            "Epoch 91/1000\n",
            "4/4 [==============================] - 1s 283ms/step - loss: 0.2115 - accuracy: 0.7408 - val_loss: 0.2939 - val_accuracy: 0.7059\n",
            "Epoch 92/1000\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.2099 - accuracy: 0.7446 - val_loss: 0.2927 - val_accuracy: 0.7079\n",
            "Epoch 93/1000\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 0.2078 - accuracy: 0.7478 - val_loss: 0.2909 - val_accuracy: 0.7083\n",
            "Epoch 94/1000\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 0.2071 - accuracy: 0.7460 - val_loss: 0.2896 - val_accuracy: 0.7101\n",
            "Epoch 95/1000\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.2056 - accuracy: 0.7478 - val_loss: 0.2889 - val_accuracy: 0.7111\n",
            "Epoch 96/1000\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.2038 - accuracy: 0.7510 - val_loss: 0.2876 - val_accuracy: 0.7137\n",
            "Epoch 97/1000\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 0.2027 - accuracy: 0.7511 - val_loss: 0.2862 - val_accuracy: 0.7128\n",
            "Epoch 98/1000\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.2023 - accuracy: 0.7514 - val_loss: 0.2849 - val_accuracy: 0.7158\n",
            "Epoch 99/1000\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 0.2004 - accuracy: 0.7546 - val_loss: 0.2841 - val_accuracy: 0.7175\n",
            "Epoch 100/1000\n",
            "4/4 [==============================] - 1s 269ms/step - loss: 0.1992 - accuracy: 0.7544 - val_loss: 0.2823 - val_accuracy: 0.7190\n",
            "Epoch 101/1000\n",
            "4/4 [==============================] - 1s 266ms/step - loss: 0.1979 - accuracy: 0.7588 - val_loss: 0.2809 - val_accuracy: 0.7187\n",
            "Epoch 102/1000\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.1974 - accuracy: 0.7585 - val_loss: 0.2803 - val_accuracy: 0.7203\n",
            "Epoch 103/1000\n",
            "4/4 [==============================] - 1s 267ms/step - loss: 0.1957 - accuracy: 0.7600 - val_loss: 0.2801 - val_accuracy: 0.7212\n",
            "Epoch 104/1000\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 0.1950 - accuracy: 0.7606 - val_loss: 0.2778 - val_accuracy: 0.7221\n",
            "Epoch 105/1000\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.1930 - accuracy: 0.7633 - val_loss: 0.2766 - val_accuracy: 0.7235\n",
            "Epoch 106/1000\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.1918 - accuracy: 0.7655 - val_loss: 0.2775 - val_accuracy: 0.7212\n",
            "Epoch 107/1000\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 0.1912 - accuracy: 0.7649 - val_loss: 0.2759 - val_accuracy: 0.7252\n",
            "Epoch 108/1000\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.1899 - accuracy: 0.7677 - val_loss: 0.2738 - val_accuracy: 0.7275\n",
            "Epoch 109/1000\n",
            "4/4 [==============================] - 1s 271ms/step - loss: 0.1878 - accuracy: 0.7708 - val_loss: 0.2730 - val_accuracy: 0.7264\n",
            "Epoch 110/1000\n",
            "4/4 [==============================] - 1s 285ms/step - loss: 0.1871 - accuracy: 0.7681 - val_loss: 0.2717 - val_accuracy: 0.7285\n",
            "Epoch 111/1000\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.1864 - accuracy: 0.7704 - val_loss: 0.2707 - val_accuracy: 0.7277\n",
            "Epoch 112/1000\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 0.1849 - accuracy: 0.7728 - val_loss: 0.2700 - val_accuracy: 0.7295\n",
            "Epoch 113/1000\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 0.1832 - accuracy: 0.7747 - val_loss: 0.2689 - val_accuracy: 0.7308\n",
            "Epoch 114/1000\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.1827 - accuracy: 0.7760 - val_loss: 0.2673 - val_accuracy: 0.7338\n",
            "Epoch 115/1000\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 0.1814 - accuracy: 0.7777 - val_loss: 0.2661 - val_accuracy: 0.7352\n",
            "Epoch 116/1000\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 0.1800 - accuracy: 0.7797 - val_loss: 0.2652 - val_accuracy: 0.7337\n",
            "Epoch 117/1000\n",
            "4/4 [==============================] - 1s 282ms/step - loss: 0.1790 - accuracy: 0.7808 - val_loss: 0.2641 - val_accuracy: 0.7360\n",
            "Epoch 118/1000\n",
            "4/4 [==============================] - 1s 279ms/step - loss: 0.1783 - accuracy: 0.7812 - val_loss: 0.2644 - val_accuracy: 0.7357\n",
            "Epoch 119/1000\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 0.1778 - accuracy: 0.7834 - val_loss: 0.2638 - val_accuracy: 0.7360\n",
            "Epoch 120/1000\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 0.1773 - accuracy: 0.7819 - val_loss: 0.2628 - val_accuracy: 0.7375\n",
            "Epoch 121/1000\n",
            "4/4 [==============================] - 1s 275ms/step - loss: 0.1755 - accuracy: 0.7852 - val_loss: 0.2609 - val_accuracy: 0.7396\n",
            "Epoch 122/1000\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 0.1739 - accuracy: 0.7860 - val_loss: 0.2612 - val_accuracy: 0.7386\n",
            "Epoch 123/1000\n",
            "4/4 [==============================] - 1s 270ms/step - loss: 0.1733 - accuracy: 0.7864 - val_loss: 0.2592 - val_accuracy: 0.7398\n",
            "Epoch 124/1000\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.1717 - accuracy: 0.7910 - val_loss: 0.2585 - val_accuracy: 0.7418\n",
            "Epoch 125/1000\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.1713 - accuracy: 0.7903 - val_loss: 0.2572 - val_accuracy: 0.7421\n",
            "Epoch 126/1000\n",
            "4/4 [==============================] - 1s 262ms/step - loss: 0.1698 - accuracy: 0.7930 - val_loss: 0.2568 - val_accuracy: 0.7427\n",
            "Epoch 127/1000\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.1689 - accuracy: 0.7929 - val_loss: 0.2564 - val_accuracy: 0.7422\n",
            "Epoch 128/1000\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.1681 - accuracy: 0.7925 - val_loss: 0.2561 - val_accuracy: 0.7438\n",
            "Epoch 129/1000\n",
            "4/4 [==============================] - 1s 260ms/step - loss: 0.1681 - accuracy: 0.7927 - val_loss: 0.2552 - val_accuracy: 0.7456\n",
            "Epoch 130/1000\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 0.1667 - accuracy: 0.7944 - val_loss: 0.2536 - val_accuracy: 0.7460\n",
            "Epoch 131/1000\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.1656 - accuracy: 0.7962 - val_loss: 0.2522 - val_accuracy: 0.7485\n",
            "Epoch 132/1000\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.1650 - accuracy: 0.7988 - val_loss: 0.2512 - val_accuracy: 0.7492\n",
            "Epoch 133/1000\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.1639 - accuracy: 0.7993 - val_loss: 0.2514 - val_accuracy: 0.7488\n",
            "Epoch 134/1000\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 0.1634 - accuracy: 0.7985 - val_loss: 0.2504 - val_accuracy: 0.7497\n",
            "Epoch 135/1000\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 0.1616 - accuracy: 0.8015 - val_loss: 0.2491 - val_accuracy: 0.7513\n",
            "Epoch 136/1000\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 0.1610 - accuracy: 0.8009 - val_loss: 0.2485 - val_accuracy: 0.7508\n",
            "Epoch 137/1000\n",
            "4/4 [==============================] - 1s 263ms/step - loss: 0.1604 - accuracy: 0.8019 - val_loss: 0.2493 - val_accuracy: 0.7507\n",
            "Epoch 138/1000\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 0.1596 - accuracy: 0.8053 - val_loss: 0.2476 - val_accuracy: 0.7526\n",
            "Epoch 139/1000\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 0.1585 - accuracy: 0.8065 - val_loss: 0.2462 - val_accuracy: 0.7528\n",
            "Epoch 140/1000\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.1576 - accuracy: 0.8057 - val_loss: 0.2465 - val_accuracy: 0.7548\n",
            "Epoch 141/1000\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 0.1570 - accuracy: 0.8073 - val_loss: 0.2456 - val_accuracy: 0.7541\n",
            "Epoch 142/1000\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.1565 - accuracy: 0.8065 - val_loss: 0.2449 - val_accuracy: 0.7560\n",
            "Epoch 143/1000\n",
            "4/4 [==============================] - 1s 269ms/step - loss: 0.1554 - accuracy: 0.8096 - val_loss: 0.2434 - val_accuracy: 0.7565\n",
            "Epoch 144/1000\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.1541 - accuracy: 0.8093 - val_loss: 0.2429 - val_accuracy: 0.7573\n",
            "Epoch 145/1000\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 0.1530 - accuracy: 0.8119 - val_loss: 0.2429 - val_accuracy: 0.7572\n",
            "Epoch 146/1000\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 0.1527 - accuracy: 0.8133 - val_loss: 0.2423 - val_accuracy: 0.7579\n",
            "Epoch 147/1000\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 0.1522 - accuracy: 0.8142 - val_loss: 0.2414 - val_accuracy: 0.7584\n",
            "Epoch 148/1000\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 0.1512 - accuracy: 0.8149 - val_loss: 0.2414 - val_accuracy: 0.7597\n",
            "Epoch 149/1000\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.1512 - accuracy: 0.8136 - val_loss: 0.2411 - val_accuracy: 0.7591\n",
            "Epoch 150/1000\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 0.1503 - accuracy: 0.8141 - val_loss: 0.2417 - val_accuracy: 0.7602\n",
            "Epoch 151/1000\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.1493 - accuracy: 0.8189 - val_loss: 0.2400 - val_accuracy: 0.7602\n",
            "Epoch 152/1000\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 0.1487 - accuracy: 0.8168 - val_loss: 0.2406 - val_accuracy: 0.7613\n",
            "Epoch 153/1000\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 0.1479 - accuracy: 0.8184 - val_loss: 0.2384 - val_accuracy: 0.7606\n",
            "Epoch 154/1000\n",
            "4/4 [==============================] - 1s 266ms/step - loss: 0.1470 - accuracy: 0.8185 - val_loss: 0.2377 - val_accuracy: 0.7623\n",
            "Epoch 155/1000\n",
            "4/4 [==============================] - 1s 266ms/step - loss: 0.1461 - accuracy: 0.8193 - val_loss: 0.2381 - val_accuracy: 0.7628\n",
            "Epoch 156/1000\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 0.1458 - accuracy: 0.8206 - val_loss: 0.2380 - val_accuracy: 0.7633\n",
            "Epoch 157/1000\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.1449 - accuracy: 0.8220 - val_loss: 0.2367 - val_accuracy: 0.7640\n",
            "Epoch 158/1000\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 0.1445 - accuracy: 0.8234 - val_loss: 0.2348 - val_accuracy: 0.7647\n",
            "Epoch 159/1000\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.1435 - accuracy: 0.8240 - val_loss: 0.2362 - val_accuracy: 0.7652\n",
            "Epoch 160/1000\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 0.1427 - accuracy: 0.8231 - val_loss: 0.2355 - val_accuracy: 0.7653\n",
            "Epoch 161/1000\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 0.1415 - accuracy: 0.8256 - val_loss: 0.2341 - val_accuracy: 0.7668\n",
            "Epoch 162/1000\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 0.1410 - accuracy: 0.8267 - val_loss: 0.2337 - val_accuracy: 0.7675\n",
            "Epoch 163/1000\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.1397 - accuracy: 0.8276 - val_loss: 0.2340 - val_accuracy: 0.7675\n",
            "Epoch 164/1000\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.1395 - accuracy: 0.8275 - val_loss: 0.2339 - val_accuracy: 0.7683\n",
            "Epoch 165/1000\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.1385 - accuracy: 0.8296 - val_loss: 0.2326 - val_accuracy: 0.7685\n",
            "Epoch 166/1000\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 0.1377 - accuracy: 0.8293 - val_loss: 0.2323 - val_accuracy: 0.7681\n",
            "Epoch 167/1000\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 0.1372 - accuracy: 0.8305 - val_loss: 0.2318 - val_accuracy: 0.7693\n",
            "Epoch 168/1000\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 0.1372 - accuracy: 0.8313 - val_loss: 0.2308 - val_accuracy: 0.7706\n",
            "Epoch 169/1000\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 0.1366 - accuracy: 0.8328 - val_loss: 0.2303 - val_accuracy: 0.7703\n",
            "Epoch 170/1000\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 0.1354 - accuracy: 0.8318 - val_loss: 0.2307 - val_accuracy: 0.7721\n",
            "Epoch 171/1000\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.1347 - accuracy: 0.8345 - val_loss: 0.2299 - val_accuracy: 0.7705\n",
            "Epoch 172/1000\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.1340 - accuracy: 0.8360 - val_loss: 0.2309 - val_accuracy: 0.7723\n",
            "Epoch 173/1000\n",
            "4/4 [==============================] - 1s 287ms/step - loss: 0.1338 - accuracy: 0.8363 - val_loss: 0.2297 - val_accuracy: 0.7714\n",
            "Epoch 174/1000\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.1331 - accuracy: 0.8338 - val_loss: 0.2292 - val_accuracy: 0.7730\n",
            "Epoch 175/1000\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 0.1327 - accuracy: 0.8366 - val_loss: 0.2276 - val_accuracy: 0.7734\n",
            "Epoch 176/1000\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.1320 - accuracy: 0.8383 - val_loss: 0.2286 - val_accuracy: 0.7734\n",
            "Epoch 177/1000\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 0.1317 - accuracy: 0.8373 - val_loss: 0.2287 - val_accuracy: 0.7722\n",
            "Epoch 178/1000\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 0.1307 - accuracy: 0.8375 - val_loss: 0.2280 - val_accuracy: 0.7747\n",
            "Epoch 179/1000\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.1303 - accuracy: 0.8403 - val_loss: 0.2267 - val_accuracy: 0.7743\n",
            "Epoch 180/1000\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.1291 - accuracy: 0.8398 - val_loss: 0.2271 - val_accuracy: 0.7753\n",
            "Epoch 181/1000\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.1287 - accuracy: 0.8410 - val_loss: 0.2271 - val_accuracy: 0.7755\n",
            "Epoch 182/1000\n",
            "4/4 [==============================] - 1s 282ms/step - loss: 0.1286 - accuracy: 0.8418 - val_loss: 0.2268 - val_accuracy: 0.7743\n",
            "Epoch 183/1000\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 0.1282 - accuracy: 0.8414 - val_loss: 0.2279 - val_accuracy: 0.7751\n",
            "Epoch 184/1000\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.1268 - accuracy: 0.8426 - val_loss: 0.2263 - val_accuracy: 0.7759\n",
            "Epoch 185/1000\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 0.1262 - accuracy: 0.8445 - val_loss: 0.2262 - val_accuracy: 0.7774\n",
            "Epoch 186/1000\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.1265 - accuracy: 0.8440 - val_loss: 0.2259 - val_accuracy: 0.7774\n",
            "Epoch 187/1000\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 0.1252 - accuracy: 0.8446 - val_loss: 0.2256 - val_accuracy: 0.7787\n",
            "Epoch 188/1000\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.1247 - accuracy: 0.8461 - val_loss: 0.2238 - val_accuracy: 0.7784\n",
            "Epoch 189/1000\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.1245 - accuracy: 0.8477 - val_loss: 0.2247 - val_accuracy: 0.7792\n",
            "Epoch 190/1000\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.1237 - accuracy: 0.8489 - val_loss: 0.2241 - val_accuracy: 0.7786\n",
            "Epoch 191/1000\n",
            "4/4 [==============================] - 1s 272ms/step - loss: 0.1240 - accuracy: 0.8489 - val_loss: 0.2240 - val_accuracy: 0.7804\n",
            "Epoch 192/1000\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.1234 - accuracy: 0.8463 - val_loss: 0.2258 - val_accuracy: 0.7773\n",
            "Epoch 193/1000\n",
            "4/4 [==============================] - 1s 272ms/step - loss: 0.1228 - accuracy: 0.8486 - val_loss: 0.2248 - val_accuracy: 0.7806\n",
            "Epoch 194/1000\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 0.1213 - accuracy: 0.8503 - val_loss: 0.2229 - val_accuracy: 0.7800\n",
            "Epoch 195/1000\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 0.1210 - accuracy: 0.8502 - val_loss: 0.2237 - val_accuracy: 0.7810\n",
            "Epoch 196/1000\n",
            "4/4 [==============================] - 1s 273ms/step - loss: 0.1215 - accuracy: 0.8507 - val_loss: 0.2229 - val_accuracy: 0.7805\n",
            "Epoch 197/1000\n",
            "4/4 [==============================] - 1s 264ms/step - loss: 0.1207 - accuracy: 0.8486 - val_loss: 0.2221 - val_accuracy: 0.7816\n",
            "Epoch 198/1000\n",
            "4/4 [==============================] - 1s 233ms/step - loss: 0.1193 - accuracy: 0.8540 - val_loss: 0.2214 - val_accuracy: 0.7820\n",
            "Epoch 199/1000\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 0.1192 - accuracy: 0.8514 - val_loss: 0.2217 - val_accuracy: 0.7825\n",
            "Epoch 200/1000\n",
            "4/4 [==============================] - 1s 262ms/step - loss: 0.1178 - accuracy: 0.8542 - val_loss: 0.2204 - val_accuracy: 0.7824\n",
            "Epoch 201/1000\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.1173 - accuracy: 0.8550 - val_loss: 0.2206 - val_accuracy: 0.7824\n",
            "Epoch 202/1000\n",
            "4/4 [==============================] - 1s 267ms/step - loss: 0.1173 - accuracy: 0.8541 - val_loss: 0.2200 - val_accuracy: 0.7846\n",
            "Epoch 203/1000\n",
            "4/4 [==============================] - 1s 287ms/step - loss: 0.1171 - accuracy: 0.8544 - val_loss: 0.2194 - val_accuracy: 0.7843\n",
            "Epoch 204/1000\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 0.1162 - accuracy: 0.8556 - val_loss: 0.2215 - val_accuracy: 0.7838\n",
            "Epoch 205/1000\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.1160 - accuracy: 0.8564 - val_loss: 0.2202 - val_accuracy: 0.7846\n",
            "Epoch 206/1000\n",
            "4/4 [==============================] - 1s 269ms/step - loss: 0.1147 - accuracy: 0.8582 - val_loss: 0.2196 - val_accuracy: 0.7855\n",
            "Epoch 207/1000\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.1156 - accuracy: 0.8580 - val_loss: 0.2192 - val_accuracy: 0.7851\n",
            "Epoch 208/1000\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 0.1139 - accuracy: 0.8572 - val_loss: 0.2217 - val_accuracy: 0.7847\n",
            "Epoch 209/1000\n",
            "4/4 [==============================] - 1s 233ms/step - loss: 0.1140 - accuracy: 0.8588 - val_loss: 0.2188 - val_accuracy: 0.7838\n",
            "Epoch 210/1000\n",
            "4/4 [==============================] - 1s 278ms/step - loss: 0.1127 - accuracy: 0.8602 - val_loss: 0.2200 - val_accuracy: 0.7856\n",
            "Epoch 211/1000\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 0.1124 - accuracy: 0.8600 - val_loss: 0.2189 - val_accuracy: 0.7846\n",
            "Epoch 212/1000\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.1121 - accuracy: 0.8615 - val_loss: 0.2182 - val_accuracy: 0.7861\n",
            "Epoch 213/1000\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.1116 - accuracy: 0.8623 - val_loss: 0.2187 - val_accuracy: 0.7865\n",
            "Epoch 214/1000\n",
            "4/4 [==============================] - 1s 232ms/step - loss: 0.1114 - accuracy: 0.8614 - val_loss: 0.2184 - val_accuracy: 0.7867\n",
            "Epoch 215/1000\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 0.1119 - accuracy: 0.8603 - val_loss: 0.2202 - val_accuracy: 0.7873\n",
            "Epoch 216/1000\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.1108 - accuracy: 0.8631 - val_loss: 0.2190 - val_accuracy: 0.7864\n",
            "Epoch 217/1000\n",
            "4/4 [==============================] - 1s 292ms/step - loss: 0.1101 - accuracy: 0.8624 - val_loss: 0.2195 - val_accuracy: 0.7877\n",
            "Epoch 218/1000\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.1094 - accuracy: 0.8647 - val_loss: 0.2180 - val_accuracy: 0.7875\n",
            "Epoch 219/1000\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 0.1094 - accuracy: 0.8630 - val_loss: 0.2186 - val_accuracy: 0.7895\n",
            "Epoch 220/1000\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 0.1088 - accuracy: 0.8656 - val_loss: 0.2184 - val_accuracy: 0.7879\n",
            "Epoch 221/1000\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 0.1086 - accuracy: 0.8651 - val_loss: 0.2184 - val_accuracy: 0.7888\n",
            "Epoch 222/1000\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 0.1076 - accuracy: 0.8669 - val_loss: 0.2167 - val_accuracy: 0.7898\n",
            "Epoch 223/1000\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.1075 - accuracy: 0.8671 - val_loss: 0.2165 - val_accuracy: 0.7898\n",
            "Epoch 224/1000\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 0.1058 - accuracy: 0.8701 - val_loss: 0.2162 - val_accuracy: 0.7896\n",
            "Epoch 225/1000\n",
            "4/4 [==============================] - 1s 268ms/step - loss: 0.1056 - accuracy: 0.8708 - val_loss: 0.2171 - val_accuracy: 0.7902\n",
            "Epoch 226/1000\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 0.1051 - accuracy: 0.8715 - val_loss: 0.2162 - val_accuracy: 0.7907\n",
            "Epoch 227/1000\n",
            "4/4 [==============================] - 1s 266ms/step - loss: 0.1052 - accuracy: 0.8709 - val_loss: 0.2168 - val_accuracy: 0.7907\n",
            "Epoch 228/1000\n",
            "4/4 [==============================] - 1s 287ms/step - loss: 0.1050 - accuracy: 0.8712 - val_loss: 0.2154 - val_accuracy: 0.7907\n",
            "Epoch 229/1000\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 0.1042 - accuracy: 0.8709 - val_loss: 0.2156 - val_accuracy: 0.7908\n",
            "Epoch 230/1000\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.1041 - accuracy: 0.8724 - val_loss: 0.2155 - val_accuracy: 0.7911\n",
            "Epoch 231/1000\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 0.1035 - accuracy: 0.8726 - val_loss: 0.2152 - val_accuracy: 0.7908\n",
            "Epoch 232/1000\n",
            "4/4 [==============================] - 1s 272ms/step - loss: 0.1031 - accuracy: 0.8705 - val_loss: 0.2151 - val_accuracy: 0.7922\n",
            "Epoch 233/1000\n",
            "4/4 [==============================] - 1s 269ms/step - loss: 0.1018 - accuracy: 0.8746 - val_loss: 0.2152 - val_accuracy: 0.7922\n",
            "Epoch 234/1000\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.1021 - accuracy: 0.8733 - val_loss: 0.2152 - val_accuracy: 0.7939\n",
            "Epoch 235/1000\n",
            "4/4 [==============================] - 1s 278ms/step - loss: 0.1018 - accuracy: 0.8727 - val_loss: 0.2166 - val_accuracy: 0.7921\n",
            "Epoch 236/1000\n",
            "4/4 [==============================] - 1s 288ms/step - loss: 0.1022 - accuracy: 0.8730 - val_loss: 0.2143 - val_accuracy: 0.7935\n",
            "Epoch 237/1000\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.1017 - accuracy: 0.8721 - val_loss: 0.2156 - val_accuracy: 0.7944\n",
            "Epoch 238/1000\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 0.1007 - accuracy: 0.8753 - val_loss: 0.2145 - val_accuracy: 0.7932\n",
            "Epoch 239/1000\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.1002 - accuracy: 0.8762 - val_loss: 0.2143 - val_accuracy: 0.7946\n",
            "Epoch 240/1000\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 0.1005 - accuracy: 0.8744 - val_loss: 0.2134 - val_accuracy: 0.7954\n",
            "Epoch 241/1000\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.0994 - accuracy: 0.8775 - val_loss: 0.2135 - val_accuracy: 0.7948\n",
            "Epoch 242/1000\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.0984 - accuracy: 0.8786 - val_loss: 0.2139 - val_accuracy: 0.7949\n",
            "Epoch 243/1000\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 0.0984 - accuracy: 0.8785 - val_loss: 0.2131 - val_accuracy: 0.7951\n",
            "Epoch 244/1000\n",
            "4/4 [==============================] - 1s 279ms/step - loss: 0.0976 - accuracy: 0.8785 - val_loss: 0.2138 - val_accuracy: 0.7949\n",
            "Epoch 245/1000\n",
            "4/4 [==============================] - 1s 266ms/step - loss: 0.0980 - accuracy: 0.8770 - val_loss: 0.2138 - val_accuracy: 0.7953\n",
            "Epoch 246/1000\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 0.0971 - accuracy: 0.8798 - val_loss: 0.2141 - val_accuracy: 0.7957\n",
            "Epoch 247/1000\n",
            "4/4 [==============================] - 1s 276ms/step - loss: 0.0972 - accuracy: 0.8789 - val_loss: 0.2137 - val_accuracy: 0.7969\n",
            "Epoch 248/1000\n",
            "4/4 [==============================] - 1s 233ms/step - loss: 0.0972 - accuracy: 0.8783 - val_loss: 0.2136 - val_accuracy: 0.7959\n",
            "Epoch 249/1000\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.0960 - accuracy: 0.8808 - val_loss: 0.2129 - val_accuracy: 0.7967\n",
            "Epoch 250/1000\n",
            "4/4 [==============================] - 1s 264ms/step - loss: 0.0958 - accuracy: 0.8801 - val_loss: 0.2133 - val_accuracy: 0.7970\n",
            "Epoch 251/1000\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.0952 - accuracy: 0.8821 - val_loss: 0.2136 - val_accuracy: 0.7958\n",
            "Epoch 252/1000\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.0951 - accuracy: 0.8811 - val_loss: 0.2141 - val_accuracy: 0.7946\n",
            "Epoch 253/1000\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.0946 - accuracy: 0.8824 - val_loss: 0.2134 - val_accuracy: 0.7961\n",
            "Epoch 254/1000\n",
            "4/4 [==============================] - 1s 264ms/step - loss: 0.0948 - accuracy: 0.8820 - val_loss: 0.2142 - val_accuracy: 0.7953\n",
            "Epoch 255/1000\n",
            "4/4 [==============================] - 1s 233ms/step - loss: 0.0945 - accuracy: 0.8846 - val_loss: 0.2134 - val_accuracy: 0.7966\n",
            "Epoch 256/1000\n",
            "4/4 [==============================] - 1s 271ms/step - loss: 0.0943 - accuracy: 0.8817 - val_loss: 0.2154 - val_accuracy: 0.7959\n",
            "Epoch 257/1000\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.0934 - accuracy: 0.8831 - val_loss: 0.2131 - val_accuracy: 0.7960\n",
            "Epoch 258/1000\n",
            "4/4 [==============================] - 1s 277ms/step - loss: 0.0937 - accuracy: 0.8820 - val_loss: 0.2139 - val_accuracy: 0.7972\n",
            "Epoch 259/1000\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 0.0937 - accuracy: 0.8829 - val_loss: 0.2160 - val_accuracy: 0.7934\n",
            "Epoch 260/1000\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.0942 - accuracy: 0.8814 - val_loss: 0.2190 - val_accuracy: 0.7955\n",
            "Epoch 261/1000\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.0929 - accuracy: 0.8827 - val_loss: 0.2125 - val_accuracy: 0.7983\n",
            "Epoch 262/1000\n",
            "4/4 [==============================] - 1s 287ms/step - loss: 0.0918 - accuracy: 0.8850 - val_loss: 0.2134 - val_accuracy: 0.7975\n",
            "Epoch 263/1000\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.0913 - accuracy: 0.8857 - val_loss: 0.2125 - val_accuracy: 0.7984\n",
            "Epoch 264/1000\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 0.0911 - accuracy: 0.8862 - val_loss: 0.2132 - val_accuracy: 0.7990\n",
            "Epoch 265/1000\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.0908 - accuracy: 0.8870 - val_loss: 0.2125 - val_accuracy: 0.7992\n",
            "Epoch 266/1000\n",
            "4/4 [==============================] - 1s 233ms/step - loss: 0.0896 - accuracy: 0.8881 - val_loss: 0.2126 - val_accuracy: 0.7982\n",
            "Epoch 267/1000\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 0.0899 - accuracy: 0.8880 - val_loss: 0.2120 - val_accuracy: 0.7987\n",
            "Epoch 268/1000\n",
            "4/4 [==============================] - 1s 292ms/step - loss: 0.0894 - accuracy: 0.8896 - val_loss: 0.2126 - val_accuracy: 0.7997\n",
            "Epoch 269/1000\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.0892 - accuracy: 0.8877 - val_loss: 0.2128 - val_accuracy: 0.7998\n",
            "Epoch 270/1000\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.0892 - accuracy: 0.8899 - val_loss: 0.2127 - val_accuracy: 0.8008\n",
            "Epoch 271/1000\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.0890 - accuracy: 0.8881 - val_loss: 0.2131 - val_accuracy: 0.8002\n",
            "Epoch 272/1000\n",
            "4/4 [==============================] - 1s 263ms/step - loss: 0.0885 - accuracy: 0.8903 - val_loss: 0.2138 - val_accuracy: 0.7982\n",
            "Epoch 273/1000\n",
            "4/4 [==============================] - 1s 195ms/step - loss: 0.0881 - accuracy: 0.8904 - val_loss: 0.2129 - val_accuracy: 0.7986\n",
            "Epoch 274/1000\n",
            "4/4 [==============================] - 1s 268ms/step - loss: 0.0882 - accuracy: 0.8902 - val_loss: 0.2130 - val_accuracy: 0.7989\n",
            "Epoch 275/1000\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.0879 - accuracy: 0.8915 - val_loss: 0.2131 - val_accuracy: 0.8008\n",
            "Epoch 276/1000\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.0877 - accuracy: 0.8914 - val_loss: 0.2124 - val_accuracy: 0.8002\n",
            "Epoch 277/1000\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 0.0876 - accuracy: 0.8907 - val_loss: 0.2145 - val_accuracy: 0.7995\n",
            "Epoch 278/1000\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.0867 - accuracy: 0.8908 - val_loss: 0.2127 - val_accuracy: 0.8001\n",
            "Epoch 279/1000\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.0856 - accuracy: 0.8924 - val_loss: 0.2125 - val_accuracy: 0.8011\n",
            "Epoch 280/1000\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 0.0864 - accuracy: 0.8912 - val_loss: 0.2123 - val_accuracy: 0.8006\n",
            "Epoch 281/1000\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 0.0850 - accuracy: 0.8932 - val_loss: 0.2142 - val_accuracy: 0.8003\n",
            "Epoch 282/1000\n",
            "4/4 [==============================] - 1s 231ms/step - loss: 0.0848 - accuracy: 0.8945 - val_loss: 0.2119 - val_accuracy: 0.8022\n",
            "Epoch 283/1000\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.0849 - accuracy: 0.8932 - val_loss: 0.2122 - val_accuracy: 0.8006\n",
            "Epoch 284/1000\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 0.0852 - accuracy: 0.8935 - val_loss: 0.2120 - val_accuracy: 0.8021\n",
            "Epoch 285/1000\n",
            "4/4 [==============================] - 1s 281ms/step - loss: 0.0838 - accuracy: 0.8942 - val_loss: 0.2114 - val_accuracy: 0.8033\n",
            "Epoch 286/1000\n",
            "4/4 [==============================] - 1s 268ms/step - loss: 0.0833 - accuracy: 0.8947 - val_loss: 0.2125 - val_accuracy: 0.8023\n",
            "Epoch 287/1000\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 0.0841 - accuracy: 0.8947 - val_loss: 0.2134 - val_accuracy: 0.8007\n",
            "Epoch 288/1000\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.0834 - accuracy: 0.8964 - val_loss: 0.2123 - val_accuracy: 0.8028\n",
            "Epoch 289/1000\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.0827 - accuracy: 0.8947 - val_loss: 0.2133 - val_accuracy: 0.8009\n",
            "Epoch 290/1000\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.0831 - accuracy: 0.8960 - val_loss: 0.2125 - val_accuracy: 0.8025\n",
            "Epoch 291/1000\n",
            "4/4 [==============================] - 1s 296ms/step - loss: 0.0822 - accuracy: 0.8966 - val_loss: 0.2131 - val_accuracy: 0.8024\n",
            "Epoch 292/1000\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 0.0824 - accuracy: 0.8961 - val_loss: 0.2139 - val_accuracy: 0.8034\n",
            "Epoch 293/1000\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.0816 - accuracy: 0.8986 - val_loss: 0.2124 - val_accuracy: 0.8034\n",
            "Epoch 294/1000\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 0.0809 - accuracy: 0.8994 - val_loss: 0.2139 - val_accuracy: 0.8030\n",
            "Epoch 295/1000\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.0817 - accuracy: 0.8975 - val_loss: 0.2126 - val_accuracy: 0.8035\n",
            "Epoch 296/1000\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.0812 - accuracy: 0.8981 - val_loss: 0.2131 - val_accuracy: 0.8035\n",
            "Epoch 297/1000\n",
            "4/4 [==============================] - 1s 292ms/step - loss: 0.0803 - accuracy: 0.8987 - val_loss: 0.2122 - val_accuracy: 0.8034\n",
            "Epoch 298/1000\n",
            "4/4 [==============================] - 1s 275ms/step - loss: 0.0801 - accuracy: 0.8995 - val_loss: 0.2138 - val_accuracy: 0.8032\n",
            "Epoch 299/1000\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.0795 - accuracy: 0.8996 - val_loss: 0.2148 - val_accuracy: 0.8020\n",
            "Epoch 300/1000\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.0800 - accuracy: 0.8989 - val_loss: 0.2157 - val_accuracy: 0.8012\n",
            "Training completed! Showing history...\n",
            "Displaying the following history keys:  dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Inference"
      ],
      "metadata": {
        "id": "rovA8jb3S04s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sometimes colab assigns the name zip to a variable leading to errors when zip() is called\n",
        "del zip"
      ],
      "metadata": {
        "id": "tmoaSeNUkgQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Baseline model Evaluation"
      ],
      "metadata": {
        "id": "fVWAOxBhYRu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict\n",
        "\n",
        "prediction_info = {\n",
        "    'batch_size': 32,\n",
        "    'verbose': 1\n",
        "}\n",
        "test_predictions_base = predict_data(model=baseline, x=x_test,\n",
        "                                      prediction_info=prediction_info)\n",
        "\n",
        "# Retrieving labels from raw predictions\n",
        "test_predictions_base = np.argmax(test_predictions_base, axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBJWV0riYRvW",
        "outputId": "7f1ada1e-ff2f-42de-d66d-5ab525126a7c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting prediction: \n",
            "{'batch_size': 32, 'verbose': 1}\n",
            "Predicting on 49 samples\n",
            "2/2 [==============================] - 2s 129ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the evaluations, we remove the padding from the predictions and the y_test so they do not affect the scores. We then flatten them since our model input was documents (multiple arrays) instead of one single array."
      ],
      "metadata": {
        "id": "6eUF6KZak98_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove padding from labels\n",
        "i=0\n",
        "test_predictions_base = list(test_predictions_base)\n",
        "y_test = list(y_test)\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    test_predictions_base[i]= test_predictions_base[i][ : y_test_lens[i]]\n",
        "    y_test[i]= y_test[i][ : y_test_lens[i]]"
      ],
      "metadata": {
        "id": "PnfVZWHGYRvY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flatten predictions to apply the metrics on all words\n",
        "flat_preds_base = [item for sublist in test_predictions_base for item in sublist]\n",
        "flat_y_base = [item for sublist in y_test for item in sublist]\n",
        "\n",
        "# save tags of test set only\n",
        "test_tags_base = set(flat_y_base)"
      ],
      "metadata": {
        "id": "soDnZKzeYRvY"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get list of tags without punctuation\n",
        "eval_tag_ids_base = copy.copy(tag_ids)\n",
        "eval_tags_base = copy.copy(tags)\n",
        "i=len(eval_tag_ids_base)-1\n",
        "while i > 0:\n",
        "    if eval_tag_ids_base[i] in [7,8,23,24,25,26,40] or eval_tag_ids_base[i] not in test_tags_base:\n",
        "        del eval_tag_ids_base[i]\n",
        "        del eval_tags_base[i]\n",
        "    i-=1"
      ],
      "metadata": {
        "id": "pt0hoYWHYRvZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_base_f1=f1_score(flat_y_base,flat_preds_base,labels=eval_tag_ids_base,average='macro')\n",
        "print('macro F1-score of Baseline: {:.2f}'.format(sample_base_f1))\n",
        "acc_base = accuracy_score(flat_y_base,flat_preds_base)\n",
        "print('Accuracy of Baseline: {:.2f}'.format(acc_base))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXJ37_2YYRva",
        "outputId": "b2adcf73-9387-4f81-e60b-4724cc64a963"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "macro F1-score of Baseline: 0.73\n",
            "Accuracy of Baseline: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class-specific F1 scores\n",
        "\n",
        "sample_base_f1=f1_score(flat_y_base,flat_preds_base,labels=eval_tag_ids_base,average=None,zero_division=0)\n",
        "\n",
        "print('tag_id\\ttag\\tf1\\n--------------------------------')\n",
        "for i,el in enumerate(sample_base_f1):\n",
        "    print('{}\\t{}\\t{:.2f}'.format(i+1,eval_tags_base[i],el))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLgwk-MLYRva",
        "outputId": "bbed585d-f696-4214-dfbf-b1a8e4edd06e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tag_id\ttag\tf1\n",
            "--------------------------------\n",
            "1\tnn\t0.72\n",
            "2\tin\t0.95\n",
            "3\tnnp\t0.63\n",
            "4\tdt\t0.99\n",
            "5\tnns\t0.62\n",
            "6\tjj\t0.57\n",
            "7\tcd\t0.82\n",
            "8\tvbd\t0.80\n",
            "9\trb\t0.64\n",
            "10\tvb\t0.84\n",
            "11\tcc\t0.99\n",
            "12\tto\t1.00\n",
            "13\tvbn\t0.63\n",
            "14\tvbz\t0.80\n",
            "15\tprp\t0.98\n",
            "16\tvbg\t0.49\n",
            "17\tvbp\t0.72\n",
            "18\tmd\t0.98\n",
            "19\tpos\t0.99\n",
            "20\tprp$\t0.99\n",
            "21\twdt\t0.88\n",
            "22\tjjr\t0.67\n",
            "23\tnnps\t0.00\n",
            "24\twp\t0.98\n",
            "25\trp\t0.71\n",
            "26\tjjs\t0.68\n",
            "27\twrb\t0.96\n",
            "28\trbr\t0.28\n",
            "29\t-rrb-\t0.97\n",
            "30\t-lrb-\t0.94\n",
            "31\tex\t0.91\n",
            "32\trbs\t0.00\n",
            "33\tpdt\t0.00\n",
            "34\twp$\t0.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display some results of baseline model\n",
        "preds_base = copy.deepcopy(test_predictions_base)\n",
        "converted_base=tags_tokenizer.convert_ids_to_tokens(preds_base)\n",
        "for tag in converted_base[0].split(' '):\n",
        "    print(tag.upper())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bv7t52BYRvb",
        "outputId": "dc42e48e-f7c4-4250-b403-3eb1c6d75c5e"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NNP\n",
            "NNP\n",
            "NNP\n",
            ",\n",
            "NNP\n",
            "NNP\n",
            ",\n",
            "NNP\n",
            ",\n",
            "VBD\n",
            "PRP\n",
            "VBD\n",
            "NN\n",
            "CD\n",
            "NNS\n",
            ",\n",
            "CC\n",
            "RB\n",
            "CD\n",
            "NN\n",
            ",\n",
            "IN\n",
            "PRP$\n",
            "JJ\n",
            "NN\n",
            "IN\n",
            "DT\n",
            "VBG\n",
            "NN\n",
            "IN\n",
            "$\n",
            "CD\n",
            "DT\n",
            "NN\n",
            ",\n",
            "CC\n",
            "$\n",
            "CD\n",
            "CD\n",
            ".\n",
            "DT\n",
            "NN\n",
            "VBD\n",
            "NNP\n",
            "NN\n",
            "NNP\n",
            "NNP\n",
            "POS\n",
            "CD\n",
            "TO\n",
            "CD\n",
            "NN\n",
            "IN\n",
            "CD\n",
            "NN\n",
            "CC\n",
            "MD\n",
            "VB\n",
            "VB\n",
            "JJ\n",
            "NNS\n",
            "IN\n",
            "VBG\n",
            "DT\n",
            "NN\n",
            "IN\n",
            "DT\n",
            "NN\n",
            "NN\n",
            ".\n",
            "NNP\n",
            "NNP\n",
            "RB\n",
            "VBZ\n",
            "VBG\n",
            "TO\n",
            "VB\n",
            "NNP\n",
            "NNP\n",
            "IN\n",
            "NN\n",
            "IN\n",
            "NNP\n",
            "NNP\n",
            ",\n",
            "DT\n",
            "JJ\n",
            "NN\n",
            ".\n",
            "DT\n",
            "NN\n",
            "NN\n",
            "IN\n",
            "CD\n",
            "NN\n",
            "DT\n",
            "NN\n",
            "VBN\n",
            "IN\n",
            "PRP\n",
            "MD\n",
            "VB\n",
            "DT\n",
            "NN\n",
            "NN\n",
            "TO\n",
            "VB\n",
            "NNS\n",
            "``\n",
            "TO\n",
            "VB\n",
            "JJ\n",
            "NN\n",
            ",\n",
            "''\n",
            "VBG\n",
            "DT\n",
            "JJ\n",
            "NN\n",
            "IN\n",
            "DT\n",
            "NN\n",
            ".\n",
            "IN\n",
            "NNP\n",
            "NNP\n",
            "NNP\n",
            "NNP\n",
            "JJ\n",
            "NN\n",
            "NN\n",
            ",\n",
            "JJ\n",
            "NNS\n",
            "VBD\n",
            "JJ\n",
            "NNS\n",
            "TO\n",
            "VB\n",
            "IN\n",
            "$\n",
            "CD\n",
            ".\n",
            "NNP\n",
            "VBD\n",
            "VBD\n",
            "TO\n",
            "VB\n",
            "WP\n",
            "VBD\n",
            "DT\n",
            "JJ\n",
            "NNS\n",
            ",\n",
            "VBG\n",
            "PRP\n",
            "VBP\n",
            "VBG\n",
            "RB\n",
            "TO\n",
            "NNP\n",
            "NNS\n",
            "WRB\n",
            "``\n",
            "DT\n",
            "NN\n",
            "VBZ\n",
            "IN\n",
            "DT\n",
            "NN\n",
            ".\n",
            "''\n",
            "PRP\n",
            "VBD\n",
            ",\n",
            "``\n",
            "DT\n",
            "VBZ\n",
            "VBN\n",
            "TO\n",
            "VB\n",
            "IN\n",
            "JJ\n",
            "NNS\n",
            "CC\n",
            "PRP\n",
            "VBZ\n",
            "RB\n",
            "NN\n",
            ",\n",
            "RB\n",
            ",\n",
            "TO\n",
            "VB\n",
            "DT\n",
            "NN\n",
            "NN\n",
            ".\n",
            "''\n",
            "CC\n",
            "NNP\n",
            "NNP\n",
            "VBD\n",
            "DT\n",
            "NN\n",
            ",\n",
            "CC\n",
            "DT\n",
            "NN\n",
            "NN\n",
            "VBN\n",
            ",\n",
            "NN\n",
            "IN\n",
            "NNP\n",
            "NNP\n",
            "VBZ\n",
            "VBG\n",
            "NNS\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2 LSTM model Evaluation"
      ],
      "metadata": {
        "id": "tiVVuk3_CtyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict\n",
        "\n",
        "prediction_info = {\n",
        "    'batch_size': 32,\n",
        "    'verbose': 1\n",
        "}\n",
        "test_predictions_2LSTM = predict_data(model=two_LSTM, x=x_test,\n",
        "                                      prediction_info=prediction_info)\n",
        "\n",
        "# Retrieving labels from raw predictions\n",
        "test_predictions_2LSTM = np.argmax(test_predictions_2LSTM, axis=-1)"
      ],
      "metadata": {
        "id": "4Jg-xAV4JUeC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "304facfc-a0f9-415a-bf1f-25e4d9126f39"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting prediction: \n",
            "{'batch_size': 32, 'verbose': 1}\n",
            "Predicting on 49 samples\n",
            "2/2 [==============================] - 4s 153ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove padding from labels\n",
        "i=0\n",
        "test_predictions_2LSTM = list(test_predictions_2LSTM)\n",
        "y_test = list(y_test)\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    test_predictions_2LSTM[i]= test_predictions_2LSTM[i][ : y_test_lens[i]]\n",
        "    y_test[i]= y_test[i][ : y_test_lens[i]]"
      ],
      "metadata": {
        "id": "9pJTkhVL5OI8"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flatten predictions to apply metrics on all predictions\n",
        "flat_preds_2LSTM = [item for sublist in test_predictions_2LSTM for item in sublist]\n",
        "flat_y_2LSTM = [item for sublist in y_test for item in sublist]\n",
        "\n",
        "# save tags of test set only\n",
        "test_tags_2LSTM = set(flat_y_2LSTM)"
      ],
      "metadata": {
        "id": "W3nPz34S_mM3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get list of tags without punctuation\n",
        "eval_tag_ids_2LSTM = copy.copy(tag_ids)\n",
        "eval_tags_2LSTM = copy.copy(tags)\n",
        "i=len(eval_tag_ids_2LSTM)-1\n",
        "while i > 0:\n",
        "    if eval_tag_ids_2LSTM[i] in [7,8,23,24,25,26,40] or eval_tag_ids_2LSTM[i] not in test_tags_2LSTM:\n",
        "        del eval_tag_ids_2LSTM[i]\n",
        "        del eval_tags_2LSTM[i]\n",
        "    i-=1"
      ],
      "metadata": {
        "id": "GSZQbovFQMqB"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_2LSTM_f1=f1_score(flat_y_2LSTM,flat_preds_2LSTM,labels=eval_tag_ids_2LSTM,average='macro')\n",
        "print('macro F1-score of 2 LSTM: {:.2f}'.format(sample_2LSTM_f1))\n",
        "acc_2LSTM = accuracy_score(flat_y_2LSTM,flat_preds_2LSTM)\n",
        "print('Accuracy of 2 LSTM: {:.2f}'.format(acc_2LSTM))"
      ],
      "metadata": {
        "id": "JxdxGVPX_jls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1370c284-e43d-47b5-8f92-5d1c61282dd2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "macro F1-score of 2 LSTM: 0.69\n",
            "Accuracy of 2 LSTM: 0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class-specific F1 scores\n",
        "\n",
        "sample_2LSTM_f1=f1_score(flat_y_2LSTM,flat_preds_2LSTM,labels=eval_tag_ids_2LSTM,average=None,zero_division=0)\n",
        "\n",
        "tuples = []\n",
        "print('tag_id\\ttag\\tf1\\n--------------------------------')\n",
        "for i,el in enumerate(sample_2LSTM_f1):\n",
        "    tuples.append((eval_tags_2LSTM[i],np.round(el,2)))\n",
        "    print('{}\\t{}\\t{:.2f}'.format(i+1,eval_tags_2LSTM[i],el))"
      ],
      "metadata": {
        "id": "_aZTSSrdmFBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dec85219-d86c-44e0-df8d-5b8ab7e5b526"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tag_id\ttag\tf1\n",
            "--------------------------------\n",
            "1\tnn\t0.76\n",
            "2\tin\t0.97\n",
            "3\tnnp\t0.70\n",
            "4\tdt\t0.99\n",
            "5\tnns\t0.65\n",
            "6\tjj\t0.62\n",
            "7\tcd\t0.85\n",
            "8\tvbd\t0.81\n",
            "9\trb\t0.66\n",
            "10\tvb\t0.85\n",
            "11\tcc\t0.99\n",
            "12\tto\t1.00\n",
            "13\tvbn\t0.64\n",
            "14\tvbz\t0.81\n",
            "15\tprp\t0.97\n",
            "16\tvbg\t0.47\n",
            "17\tvbp\t0.75\n",
            "18\tmd\t0.98\n",
            "19\tpos\t0.99\n",
            "20\tprp$\t1.00\n",
            "21\twdt\t0.88\n",
            "22\tjjr\t0.59\n",
            "23\tnnps\t0.00\n",
            "24\twp\t0.98\n",
            "25\trp\t0.56\n",
            "26\tjjs\t0.18\n",
            "27\twrb\t0.91\n",
            "28\trbr\t0.19\n",
            "29\t-rrb-\t0.91\n",
            "30\t-lrb-\t0.94\n",
            "31\tex\t0.91\n",
            "32\trbs\t0.00\n",
            "33\tpdt\t0.00\n",
            "34\twp$\t0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display some results of 2 LSTM model\n",
        "preds_2LSTM = copy.deepcopy(test_predictions_2LSTM)\n",
        "converted_2LSTM=tags_tokenizer.convert_ids_to_tokens(preds_2LSTM)\n",
        "for tag in converted_2LSTM[0].split(' '):\n",
        "    print(tag.upper())"
      ],
      "metadata": {
        "id": "Sr-XvYTkGIul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7e7f291-0b93-4916-ef40-ca49c87f7a33"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NNP\n",
            "NNP\n",
            "NNP\n",
            ",\n",
            "NNP\n",
            "NNP\n",
            ",\n",
            "NNP\n",
            ",\n",
            "VBD\n",
            "PRP\n",
            "VBD\n",
            "CD\n",
            "CD\n",
            "NNS\n",
            ",\n",
            "CC\n",
            "RB\n",
            "CD\n",
            "NN\n",
            ",\n",
            "IN\n",
            "PRP$\n",
            "JJ\n",
            "NN\n",
            "IN\n",
            "DT\n",
            "JJ\n",
            "NN\n",
            "IN\n",
            "$\n",
            "CD\n",
            "DT\n",
            "NN\n",
            ",\n",
            "CC\n",
            "$\n",
            "CD\n",
            "CD\n",
            ".\n",
            "DT\n",
            "NN\n",
            "VBD\n",
            "RB\n",
            "NN\n",
            "NNP\n",
            "NNP\n",
            "POS\n",
            "NN\n",
            "TO\n",
            "CD\n",
            "NN\n",
            "IN\n",
            "CD\n",
            "NN\n",
            "CC\n",
            "MD\n",
            "VB\n",
            "VBN\n",
            "CD\n",
            "NNS\n",
            "IN\n",
            "VBG\n",
            "DT\n",
            "NN\n",
            "IN\n",
            "DT\n",
            "NN\n",
            "NN\n",
            ".\n",
            "NNP\n",
            "NNP\n",
            "RB\n",
            "VBZ\n",
            "VBG\n",
            "TO\n",
            "VB\n",
            "NNP\n",
            "NNP\n",
            "IN\n",
            "NN\n",
            "IN\n",
            "NNP\n",
            "NNP\n",
            ",\n",
            "DT\n",
            "JJ\n",
            "NN\n",
            ".\n",
            "DT\n",
            "NN\n",
            "VBN\n",
            "IN\n",
            "CD\n",
            "NN\n",
            "DT\n",
            "NN\n",
            "NN\n",
            "IN\n",
            "PRP\n",
            "MD\n",
            "VB\n",
            "DT\n",
            "NN\n",
            "NN\n",
            "TO\n",
            "VB\n",
            "VB\n",
            "``\n",
            "TO\n",
            "VB\n",
            "NN\n",
            "NN\n",
            ",\n",
            "''\n",
            "VBG\n",
            "DT\n",
            "JJ\n",
            "NN\n",
            "IN\n",
            "DT\n",
            "NN\n",
            ".\n",
            "IN\n",
            "NNP\n",
            "NNP\n",
            "NNP\n",
            "NNP\n",
            "JJ\n",
            "NN\n",
            "NN\n",
            ",\n",
            "NNP\n",
            "NNS\n",
            "VBD\n",
            "VBN\n",
            "NNS\n",
            "TO\n",
            "VB\n",
            "IN\n",
            "$\n",
            "CD\n",
            ".\n",
            "NNP\n",
            "NNP\n",
            "VBD\n",
            "TO\n",
            "VB\n",
            "WP\n",
            "VBD\n",
            "DT\n",
            "JJ\n",
            "NN\n",
            ",\n",
            "VBG\n",
            "PRP\n",
            "VBP\n",
            "VBG\n",
            "RB\n",
            "TO\n",
            "VB\n",
            "NNS\n",
            "WRB\n",
            "``\n",
            "DT\n",
            "NN\n",
            "VBZ\n",
            "IN\n",
            "DT\n",
            "NN\n",
            ".\n",
            "''\n",
            "PRP\n",
            "VBD\n",
            ",\n",
            "``\n",
            "DT\n",
            "VBZ\n",
            "VBN\n",
            "TO\n",
            "VB\n",
            "IN\n",
            "JJ\n",
            "NNS\n",
            "CC\n",
            "PRP\n",
            "VBZ\n",
            "RB\n",
            "JJ\n",
            ",\n",
            "RB\n",
            ",\n",
            "TO\n",
            "VB\n",
            "DT\n",
            "NN\n",
            "JJ\n",
            ".\n",
            "''\n",
            "CC\n",
            "NNP\n",
            "NNP\n",
            "VBD\n",
            "DT\n",
            "NN\n",
            ",\n",
            "CC\n",
            "DT\n",
            "JJ\n",
            "NN\n",
            "NN\n",
            ",\n",
            "NN\n",
            "IN\n",
            "NNP\n",
            "NNP\n",
            "VBZ\n",
            "JJ\n",
            "NN\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2 Dense model Evaluation"
      ],
      "metadata": {
        "id": "42mLsMZlD_3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict\n",
        "\n",
        "prediction_info = {\n",
        "    'batch_size': 32,\n",
        "    'verbose': 1\n",
        "}\n",
        "test_predictions_2Dense = predict_data(model=two_dense, x=x_test,\n",
        "                                      prediction_info=prediction_info)\n",
        "\n",
        "# Retrieving labels from raw predictions\n",
        "test_predictions_2Dense = np.argmax(test_predictions_2Dense, axis=-1)"
      ],
      "metadata": {
        "id": "E9H8gR0CD_35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fad95dd-f9f5-4037-e864-70e572616221"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting prediction: \n",
            "{'batch_size': 32, 'verbose': 1}\n",
            "Predicting on 49 samples\n",
            "2/2 [==============================] - 2s 107ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove padding from labels\n",
        "i=0\n",
        "test_predictions_2Dense = list(test_predictions_2Dense)\n",
        "y_test = list(y_test)\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    test_predictions_2Dense[i]= test_predictions_2Dense[i][ : y_test_lens[i]]\n",
        "    y_test[i]= y_test[i][ : y_test_lens[i]]"
      ],
      "metadata": {
        "id": "7hNgZcmJD_36"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flatten predictions to apply metrics on all predictions\n",
        "flat_preds_2Dense = [item for sublist in test_predictions_2Dense for item in sublist]\n",
        "flat_y_2Dense = [item for sublist in y_test for item in sublist]\n",
        "\n",
        "# save tags of test set only\n",
        "test_tags_2Dense = set(flat_y_2Dense)"
      ],
      "metadata": {
        "id": "z4-fOt7HD_36"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get list of tags without punctuation\n",
        "eval_tag_ids_2Dense = copy.copy(tag_ids)\n",
        "eval_tags_2Dense = copy.copy(tags)\n",
        "i=len(eval_tag_ids_2Dense)-1\n",
        "while i > 0:\n",
        "    if eval_tag_ids_2Dense[i] in [7,8,23,24,25,26,40] or eval_tag_ids_2Dense[i] not in test_tags_2Dense:\n",
        "        del eval_tag_ids_2Dense[i]\n",
        "        del eval_tags_2Dense[i]\n",
        "    i-=1"
      ],
      "metadata": {
        "id": "ZKezeAxoD_37"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_2Dense_f1=f1_score(flat_y_2Dense,flat_preds_2Dense,labels=eval_tag_ids_2Dense,average='macro')\n",
        "print('macro F1-score of 2 Dense:{:.2f}'.format(sample_2Dense_f1))\n",
        "acc_2Dense = accuracy_score(flat_y_2Dense,flat_preds_2Dense)\n",
        "print('Accuracy of 2 Dense: {:.2f}'.format(acc_2Dense))"
      ],
      "metadata": {
        "id": "xV5TMzSLD_37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13d361e0-754d-47ba-9783-024460d1e95a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "macro F1-score of 2 Dense:0.71\n",
            "Accuracy of 2 Dense: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class-specific F1 scores\n",
        "\n",
        "sample_2Dense_f1=f1_score(flat_y_2Dense,flat_preds_2Dense,labels=eval_tag_ids_2Dense,average=None,zero_division=0)\n",
        "\n",
        "print('tag_id\\ttag\\tf1\\n--------------------------------')\n",
        "for i,el in enumerate(sample_2Dense_f1):\n",
        "    print('{}\\t{}\\t{:.2f}'.format(i+1,eval_tags_2Dense[i],el))"
      ],
      "metadata": {
        "id": "wxJyaiOgD_37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "490b7fc1-10ca-4152-9dd1-e8a2205914b4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tag_id\ttag\tf1\n",
            "--------------------------------\n",
            "1\tnn\t0.73\n",
            "2\tin\t0.97\n",
            "3\tnnp\t0.65\n",
            "4\tdt\t0.99\n",
            "5\tnns\t0.63\n",
            "6\tjj\t0.62\n",
            "7\tcd\t0.82\n",
            "8\tvbd\t0.80\n",
            "9\trb\t0.65\n",
            "10\tvb\t0.82\n",
            "11\tcc\t0.99\n",
            "12\tto\t1.00\n",
            "13\tvbn\t0.63\n",
            "14\tvbz\t0.81\n",
            "15\tprp\t0.98\n",
            "16\tvbg\t0.48\n",
            "17\tvbp\t0.73\n",
            "18\tmd\t0.98\n",
            "19\tpos\t0.99\n",
            "20\tprp$\t0.99\n",
            "21\twdt\t0.89\n",
            "22\tjjr\t0.67\n",
            "23\tnnps\t0.00\n",
            "24\twp\t1.00\n",
            "25\trp\t0.58\n",
            "26\tjjs\t0.48\n",
            "27\twrb\t0.93\n",
            "28\trbr\t0.25\n",
            "29\t-rrb-\t1.00\n",
            "30\t-lrb-\t1.00\n",
            "31\tex\t0.91\n",
            "32\trbs\t0.00\n",
            "33\tpdt\t0.00\n",
            "34\twp$\t0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display some results of 2 Dense model\n",
        "preds_2Dense = copy.deepcopy(test_predictions_2Dense)\n",
        "converted_2Dense=tags_tokenizer.convert_ids_to_tokens(preds_2Dense)\n",
        "for tag in converted_2Dense[0].split(' '):\n",
        "    print(tag.upper())"
      ],
      "metadata": {
        "id": "qnv1CeXY8rT-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "450138e8-0d99-404c-c0c2-72fa35aaad5c"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NNP\n",
            "NNP\n",
            "NNP\n",
            ",\n",
            "NNP\n",
            "NNP\n",
            ",\n",
            "NNP\n",
            ",\n",
            "VBD\n",
            "PRP\n",
            "VBD\n",
            "CD\n",
            "CD\n",
            "NNS\n",
            ",\n",
            "CC\n",
            "IN\n",
            "CD\n",
            "NN\n",
            ",\n",
            "IN\n",
            "PRP$\n",
            "JJ\n",
            "NN\n",
            "IN\n",
            "DT\n",
            "JJ\n",
            "NN\n",
            "IN\n",
            "$\n",
            "CD\n",
            "DT\n",
            "NN\n",
            ",\n",
            "CC\n",
            "$\n",
            "CD\n",
            "CD\n",
            ".\n",
            "DT\n",
            "NN\n",
            "NN\n",
            "NNP\n",
            "NNP\n",
            "NNP\n",
            "NNP\n",
            "POS\n",
            "NNP\n",
            "TO\n",
            "CD\n",
            "NN\n",
            "IN\n",
            "CD\n",
            "NN\n",
            "CC\n",
            "MD\n",
            "VB\n",
            "JJ\n",
            "NNP\n",
            "NNS\n",
            "IN\n",
            "VBG\n",
            "DT\n",
            "NN\n",
            "IN\n",
            "DT\n",
            "NN\n",
            "NN\n",
            ".\n",
            "NNP\n",
            "NNP\n",
            "RB\n",
            "VBZ\n",
            "VBG\n",
            "TO\n",
            "VB\n",
            "NNP\n",
            "NNP\n",
            "IN\n",
            "NN\n",
            "IN\n",
            "NNP\n",
            "NNP\n",
            ",\n",
            "DT\n",
            "JJ\n",
            "NN\n",
            ".\n",
            "DT\n",
            "NN\n",
            "VBD\n",
            "IN\n",
            "CD\n",
            "NN\n",
            "DT\n",
            "JJ\n",
            "NN\n",
            "IN\n",
            "PRP\n",
            "MD\n",
            "VB\n",
            "DT\n",
            "NN\n",
            "NN\n",
            "TO\n",
            "NNP\n",
            "RB\n",
            "``\n",
            "TO\n",
            "VB\n",
            "RB\n",
            "NN\n",
            ",\n",
            "''\n",
            "VBG\n",
            "DT\n",
            "NN\n",
            "NN\n",
            "IN\n",
            "DT\n",
            "NN\n",
            ".\n",
            "IN\n",
            "NNP\n",
            "NNP\n",
            "NNP\n",
            "NNP\n",
            "JJ\n",
            "NN\n",
            "NN\n",
            ",\n",
            "JJ\n",
            "NNS\n",
            "VBD\n",
            "JJ\n",
            "NNS\n",
            "TO\n",
            "VB\n",
            "IN\n",
            "$\n",
            "CD\n",
            ".\n",
            "NNP\n",
            "NNP\n",
            "VBD\n",
            "TO\n",
            "VB\n",
            "WP\n",
            "NNS\n",
            "DT\n",
            "JJ\n",
            "NN\n",
            ",\n",
            "VBG\n",
            "PRP\n",
            "VBP\n",
            "VBN\n",
            "RB\n",
            "TO\n",
            "CD\n",
            "NNS\n",
            "WRB\n",
            "``\n",
            "DT\n",
            "NN\n",
            "VBZ\n",
            "IN\n",
            "DT\n",
            "NN\n",
            ".\n",
            "''\n",
            "PRP\n",
            "VBD\n",
            ",\n",
            "``\n",
            "DT\n",
            "VBZ\n",
            "VBN\n",
            "TO\n",
            "VB\n",
            "IN\n",
            "JJ\n",
            "NNS\n",
            "CC\n",
            "PRP\n",
            "VBZ\n",
            "RB\n",
            "VBN\n",
            ",\n",
            "RB\n",
            ",\n",
            "TO\n",
            "VB\n",
            "DT\n",
            "NN\n",
            "JJ\n",
            ".\n",
            "''\n",
            "CC\n",
            "NNP\n",
            "NNP\n",
            "VBD\n",
            "DT\n",
            "NN\n",
            ",\n",
            "CC\n",
            "DT\n",
            "JJ\n",
            "NN\n",
            "VBN\n",
            ",\n",
            "NN\n",
            "IN\n",
            "NNP\n",
            "NNP\n",
            "VBZ\n",
            "RB\n",
            "VBN\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3- Data visualization and Error Analysis"
      ],
      "metadata": {
        "id": "L6YHFU3HdMRX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we plot the frequency of each class, we notice that there is a **huge class imbalance** which is inherent to language (for example, determinants -DT- are more frequent than plural proper nouns -NNPS-). This can negatively affect the learning process of the model since it is not provided the same quantity of each class to learn from. This, along with the proper difficulty of a specific class decide how difficult it is to learn. This might explain the discrepancy between the test accuracy score and F1 scores.  "
      ],
      "metadata": {
        "id": "x45J7BNadehb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# plot frequency of each class for the whole dataset\n",
        "data = df['tags'].values\n",
        "all_tags = []\n",
        "for l in data:\n",
        "    for e in l:\n",
        "        all_tags.append(e)\n",
        "freqs = Counter(all_tags).most_common()\n",
        "x=[]\n",
        "y=[]\n",
        "for (tag,freq) in freqs:\n",
        "    x.append(tag)\n",
        "    y.append(freq)\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (22,7)\n",
        "plt.bar(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "ytun_yWBb6HK",
        "outputId": "80e41a73-f04b-4ba7-a8fc-0b67a6af23f5"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 45 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1584x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# plot frequency of each class for the training split\n",
        "data = df[df['split'] == 'test']\n",
        "data = data['tags'].values\n",
        "\n",
        "print(data.shape)\n",
        "\n",
        "all_tags = []\n",
        "for l in data:\n",
        "    for e in l:\n",
        "        all_tags.append(e)\n",
        "freqs = Counter(all_tags).most_common()\n",
        "x=[]\n",
        "y=[]\n",
        "for (tag,freq) in freqs:\n",
        "    x.append(tag)\n",
        "    y.append(freq)\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (22,7)\n",
        "plt.bar(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "QZTq-uVigm_C",
        "outputId": "bc1c66af-e831-43be-a4c4-4d7e687fe7c0"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(49,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 40 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1584x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print sorted class-specific F1 scores \n",
        "sorted_scores = sorted(tuples, key=lambda x: x[1],reverse=True)\n",
        "print('tag\\tscore\\n-------------')\n",
        "for tag, score in sorted_scores:\n",
        "    print('{}\\t{}'.format(tag,score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Mme3JZpcFlz",
        "outputId": "f096b9f0-7288-4e5e-f0b2-46eed13c3257"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tag\tscore\n",
            "-------------\n",
            "to\t1.0\n",
            "prp$\t1.0\n",
            "dt\t0.99\n",
            "cc\t0.99\n",
            "pos\t0.99\n",
            "md\t0.98\n",
            "wp\t0.98\n",
            "in\t0.97\n",
            "prp\t0.97\n",
            "-lrb-\t0.94\n",
            "wrb\t0.91\n",
            "-rrb-\t0.91\n",
            "ex\t0.91\n",
            "wdt\t0.88\n",
            "cd\t0.85\n",
            "vb\t0.85\n",
            "vbd\t0.81\n",
            "vbz\t0.81\n",
            "nn\t0.76\n",
            "vbp\t0.75\n",
            "nnp\t0.7\n",
            "rb\t0.66\n",
            "nns\t0.65\n",
            "vbn\t0.64\n",
            "jj\t0.62\n",
            "jjr\t0.59\n",
            "rp\t0.56\n",
            "vbg\t0.47\n",
            "rbr\t0.19\n",
            "jjs\t0.18\n",
            "nnps\t0.0\n",
            "rbs\t0.0\n",
            "pdt\t0.0\n",
            "wp$\t0.0\n"
          ]
        }
      ]
    }
  ]
}